diff -urN trac-trunk/build/lib/trac/About.py aw-trac/build/lib/trac/About.py
--- trac-trunk/build/lib/trac/About.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/About.py	2006-01-02 06:33:26.000000000 -0800
@@ -0,0 +1,249 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2006 Edgewall Software
+# Copyright (C) 2004-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2004-2005 Daniel Lundin <daniel@edgewall.com>
+# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import re
+
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.web import IRequestHandler
+from trac.util import Markup
+from trac.web.chrome import add_stylesheet, INavigationContributor
+
+
+class AboutModule(Component):
+    """Provides various about pages."""
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler)
+
+    about_cs = """
+<?cs include "header.cs"?>
+<div id="ctxtnav" class="nav">
+ <h2>About Navigation</h2>
+ <ul>
+  <li class="first<?cs if:!about.config_href ?> last<?cs /if ?>"><a href="<?cs
+    var:trac.href.about ?>">Overview</a></li><?cs
+  if:about.config_href ?>
+   <li><a href="<?cs var:about.config_href ?>">Configuration</a></li><?cs
+  /if ?><?cs
+  if:about.plugins_href ?>
+   <li class="last"><a href="<?cs var:about.plugins_href ?>">Plugins</a></li><?cs
+  /if ?>
+ </ul>
+</div>
+<div id="content" class="about<?cs if:about.page ?>_<?cs var:about.page ?><?cs /if ?>">
+
+ <?cs if:about.page == "config"?>
+  <h1>Configuration</h1>
+  <table><thead><tr><th class="section">Section</th>
+   <th class="name">Name</th><th class="value">Value</th></tr></thead><?cs
+  each:section = about.config ?><?cs
+   if:len(section.options) ?>
+    <tr><th rowspan="<?cs var:len(section.options) ?>"><?cs var:section.name ?></th><?cs
+    each:option = section.options ?><?cs if:name(option) != 0 ?><tr><?cs /if ?>
+     <td><?cs var:option.name ?></td>
+     <td><?cs var:option.value ?></td>
+    </tr><?cs
+    /each ?><?cs
+   /if ?><?cs
+  /each ?></table>
+  <div id="help">
+   See <a href="<?cs var:trac.href.wiki ?>/TracIni">TracIni</a> for information about
+   the configuration.
+  </div>
+
+ <?cs elif:about.page == "plugins" ?>
+  <h1>Plugins</h1>
+  <dl id="plugins"><?cs
+   each:plugin = about.plugins ?>
+    <h2 id="<?cs var:plugin.module ?>.<?cs var:plugin.name ?>"><?cs var:plugin.name ?></h2>
+    <table>
+     <tr>
+      <th class="module" scope="row">Module</th>
+      <td class="module"><?cs var:plugin.module ?><br />
+      <span class="path"><?cs var:plugin.path ?></span></td>
+     </tr><?cs
+     if:plugin.description ?><tr>
+      <th class="description" scope="row">Description</th>
+      <td class="description"><?cs var:plugin.description ?></td>
+     </tr><?cs /if ?><?cs
+     if:len(plugin.extension_points) ?><tr>
+      <th class="xtnpts" rowspan="<?cs var:len(plugin.extension_points) ?>">
+       Extension points:</th><?cs
+       each:extension_point = plugin.extension_points ?><?cs
+        if:name(extension_point) != 0 ?><tr><?cs /if ?>
+        <td class="xtnpts">        
+         <code><?cs var:extension_point.module ?>.<?cs var:extension_point.interface ?></code><?cs
+          if:len(extension_point.extensions) ?> (<?cs
+           var:len(extension_point.extensions) ?> extensions)<ul><?cs
+           each:extension = extension_point.extensions ?>
+            <li><a href="#<?cs var:extension.module ?>.<?cs
+              var:extension.name ?>"><?cs var:extension.name ?></a></li><?cs
+           /each ?></ul><?cs
+          /if ?>
+          <div class="description"><?cs var:extension_point.description ?></div>
+        </td></tr><?cs
+       /each ?><?cs
+     /if ?>
+    </table><?cs
+   /each ?>
+  </dl>
+
+ <?cs else ?>
+  <a href="http://trac.edgewall.com" style="border: none; float: right; margin-left: 2em">
+   <img style="display: block" src="<?cs var:chrome.href ?>/common/trac_banner.png"
+     alt="Trac: Integrated SCM &amp; Project Management"/>
+  </a>
+<h1>About Trac <?cs var:trac.version ?></h1>
+<p>
+Trac is a web-based software project management and bug/issue
+tracking system emphasizing ease of use and low ceremony. 
+It provides an interface to the Subversion revision control systems, integrated Wiki and convenient report facilities. 
+</p>
+  <p>Trac is distributed under the modified BSD License.<br />
+  The complete text of the license can be found in the COPYING file
+  included in the distribution.</p>
+  <p>Please visit the Trac open source project: 
+  <a href="http://projects.edgewall.com/trac/">http://projects.edgewall.com/trac/</a></p>
+  <p>Trac is a product of <a href="http://www.edgewall.com/">Edgewall
+  Software</a>, provider of professional Linux and software development
+  services.</p>
+  <p>Copyright &copy; 2003-2006 <a href="http://www.edgewall.com/">Edgewall
+  Software</a></p>
+  <a href="http://www.edgewall.com/">
+   <img style="display: block; margin: 30px" src="<?cs var:chrome.href ?>/common/edgewall.png"
+     alt="Edgewall Software"/></a>
+ <?cs /if ?>
+</div>
+<?cs include "footer.cs"?>
+""" # about_cs
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'about'
+
+    def get_navigation_items(self, req):
+        yield ('metanav', 'about',
+               Markup('<a href="%s">About Trac</a>', self.env.href.about()))
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        return ['CONFIG_VIEW']
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        match = re.match(r'/about(?:_trac)?(?:/(.*))?$', req.path_info)
+        if match:
+            if match.group(1):
+                req.args['page'] = match.group(1)
+            return 1
+
+    def process_request(self, req):
+        page = req.args.get('page', 'default')
+        req.hdf['title'] = 'About Trac'
+        if req.perm.has_permission('CONFIG_VIEW'):
+            req.hdf['about.config_href'] = self.env.href.about('config')
+            req.hdf['about.plugins_href'] = self.env.href.about('plugins')
+        if page == 'config':
+            self._render_config(req)
+        elif page == 'plugins':
+            self._render_plugins(req)
+
+        add_stylesheet(req, 'common/css/about.css')
+        template = req.hdf.parse(self.about_cs)
+        return template, None
+
+    # Internal methods
+
+    def _render_config(self, req):
+        req.perm.assert_permission('CONFIG_VIEW')
+        req.hdf['about.page'] = 'config'
+        # Export the config table to hdf
+        sections = []
+        for section in self.config.sections():
+            options = []
+            for name,value in self.config.options(section):
+                options.append({'name': name, 'value': value})
+            options.sort(lambda x,y: cmp(x['name'], y['name']))
+            sections.append({'name': section, 'options': options})
+        sections.sort(lambda x,y: cmp(x['name'], y['name']))
+        req.hdf['about.config'] = sections
+        # TODO:
+        # We should probably export more info here like:
+        # permissions, components...
+
+    def _render_plugins(self, req):
+        try:
+            from trac.wiki.formatter import wiki_to_html
+            import inspect
+            def getdoc(obj):
+                return wiki_to_html(inspect.getdoc(obj), self.env, req)
+        except:
+            def getdoc(obj):
+                return obj.__doc__
+        req.perm.assert_permission('CONFIG_VIEW')
+        import sys
+        req.hdf['about.page'] = 'plugins'
+        from trac.core import ComponentMeta
+        plugins = []
+        for component in ComponentMeta._components:
+            if not self.env.is_component_enabled(component):
+                continue
+            plugin = {'name': component.__name__}
+            if component.__doc__:
+                plugin['description'] = getdoc(component)
+
+            module = sys.modules[component.__module__]
+            plugin['module'] = module.__name__
+            if hasattr(module, '__file__'):
+                plugin['path'] = module.__file__
+
+            xtnpts = []
+            for name, xtnpt in [(attr, getattr(component, attr)) for attr
+                                in dir(component)]:
+                if not isinstance(xtnpt, ExtensionPoint):
+                    continue
+                xtnpts.append({'name': name,
+                               'interface': xtnpt.interface.__name__,
+                               'module': xtnpt.interface.__module__})
+                if xtnpt.interface.__doc__:
+                    xtnpts[-1]['description'] = getdoc(xtnpt.interface)
+                extensions = []
+                for extension in ComponentMeta._registry.get(xtnpt.interface, []):
+                    if self.env.is_component_enabled(extension):
+                        extensions.append({'name': extension.__name__,
+                                           'module': extension.__module__})
+                xtnpts[-1]['extensions'] = extensions
+            xtnpts.sort(lambda x,y: cmp(x['name'], y['name']))
+            plugin['extension_points'] = xtnpts
+
+            plugins.append(plugin)
+
+        def plugincmp(x, y):
+            c = cmp(len(x['module'].split('.')), len(y['module'].split('.')))
+            if c == 0:
+                c = cmp(x['module'].lower(), y['module'].lower())
+                if c == 0:
+                    c = cmp(x['name'].lower(), y['name'].lower())
+            return c
+        plugins.sort(plugincmp)
+
+        req.hdf['about.plugins'] = plugins
diff -urN trac-trunk/build/lib/trac/Search.py aw-trac/build/lib/trac/Search.py
--- trac-trunk/build/lib/trac/Search.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/Search.py	2006-02-27 08:56:20.000000000 -0800
@@ -0,0 +1,269 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2004 Edgewall Software
+# Copyright (C) 2003-2004 Jonas Borgström <jonas@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+import re
+import time
+
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.util import TracError, escape, format_datetime, Markup
+from trac.web import IRequestHandler
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.wiki import IWikiSyntaxProvider
+
+
+class ISearchSource(Interface):
+    """
+    Extension point interface for adding search sources to the Trac
+    Search system.
+    """
+
+    def get_search_filters(self, req):
+        """
+        Return a list of filters that this search source supports. Each
+        filter must be a (name, label) tuple, where `name` is the internal
+        name, and `label` is a human-readable name for display.
+        """
+
+    def get_search_results(self, req, terms, filters):
+        """
+        Return a list of search results matching each search term in `terms`.
+        The `filters` parameters is a list of the enabled
+        filters, each item being the name of the tuples returned by
+        `get_search_events`.
+
+        The events returned by this function must be tuples of the form
+        (href, title, date, author, excerpt).
+        """
+
+
+def search_terms(q):
+    """
+    Break apart a search query into its various search terms.  Terms are
+    grouped implicitly by word boundary, or explicitly by (single or double)
+    quotes.
+    """
+    results = []
+    for term in re.split('(".*?")|(\'.*?\')|(\s+)', q):
+        if term != None and term.strip() != '':
+            if term[0] == term[-1] == "'" or term[0] == term[-1] == '"':
+                term = term[1:-1]
+            results.append(term)
+    return results
+
+def search_to_sql(db, columns, terms):
+    """
+    Convert a search query into a SQL condition string and corresponding
+    parameters. The result is returned as a (string, params) tuple.
+    """
+    if len(columns) < 1 or len(terms) < 1:
+        raise TracError('Empty search attempt, this should really not happen.')
+
+    likes = [r"%s %s %%s ESCAPE '/'" % (i, db.like()) for i in columns]
+    c = ' OR '.join(likes)
+    sql = '(' + ') AND ('.join([c] * len(terms)) + ')'
+    args = []
+    escape_re = re.compile(r'([/_%])')
+    for t in terms:
+        t = escape_re.sub(r'/\1', t) # escape LIKE syntax
+        args.extend(['%'+t+'%'] * len(columns)) 
+    return sql, tuple(args)
+
+def shorten_result(text='', keywords=[], maxlen=240, fuzz=60):
+    if not text: text = ''
+    text_low = text.lower()
+    beg = -1
+    for k in keywords:
+        i = text_low.find(k.lower())
+        if (i > -1 and i < beg) or beg == -1:
+            beg = i
+    excerpt_beg = 0
+    if beg > fuzz:
+        for sep in ('.', ':', ';', '='):
+            eb = text.find(sep, beg - fuzz, beg - 1)
+            if eb > -1:
+                eb += 1
+                break
+        else:
+            eb = beg - fuzz
+        excerpt_beg = eb
+    if excerpt_beg < 0: excerpt_beg = 0
+    msg = text[excerpt_beg:beg+maxlen]
+    if beg > fuzz:
+        msg = '... ' + msg
+    if beg < len(text)-maxlen:
+        msg = msg + ' ...'
+    return msg
+    
+
+class SearchModule(Component):
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
+               IWikiSyntaxProvider)
+
+    search_sources = ExtensionPoint(ISearchSource)
+    
+    RESULTS_PER_PAGE = 10
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'search'
+
+    def get_navigation_items(self, req):
+        if not req.perm.has_permission('SEARCH_VIEW'):
+            return
+        yield ('mainnav', 'search',
+               Markup('<a href="%s" accesskey="4">Search</a>',
+                      self.env.href.search()))
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        return ['SEARCH_VIEW']
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        return re.match(r'/search/?', req.path_info) is not None
+
+    def process_request(self, req):
+        req.perm.assert_permission('SEARCH_VIEW')
+
+        available_filters = []
+        for source in self.search_sources:
+            available_filters += source.get_search_filters(req)
+            
+        filters = [f[0] for f in available_filters if req.args.has_key(f[0])]
+        if not filters:
+            filters = [f[0] for f in available_filters]
+                
+        req.hdf['search.filters'] = [
+            { 'name': filter[0],
+              'label': filter[1],
+              'active': filter[0] in filters
+            } for filter in available_filters]
+                
+        req.hdf['title'] = 'Search'
+
+        query = req.args.get('q')
+        if query:
+            page = int(req.args.get('page', '1'))
+            redir = self.quickjump(query)
+            if redir:
+                req.redirect(redir)
+            elif query.startswith('!'):
+                query = query[1:]
+            terms = search_terms(query)
+            # Refuse queries that obviously would result in a huge result set
+            if len(terms) == 1 and len(terms[0]) < 3:
+                raise TracError('Search query too short. '
+                                'Query must be at least 3 characters long.',
+                                'Search Error')
+            results = []
+            for source in self.search_sources:
+                results += list(source.get_search_results(req, terms, filters))
+            results.sort(lambda x,y: cmp(y[2], x[2]))
+            page_size = self.RESULTS_PER_PAGE
+            n = len(results)
+            n_pages = n / page_size + 1
+            results = results[(page-1) * page_size: page * page_size]
+
+            req.hdf['title'] = 'Search Results'
+            req.hdf['search.q'] = req.args.get('q')
+            req.hdf['search.page'] = page
+            req.hdf['search.n_hits'] = n
+            req.hdf['search.n_pages'] = n_pages
+            req.hdf['search.page_size'] = page_size
+            if page < n_pages:
+                next_href = self.env.href.search(zip(filters,
+                                                     ['on'] * len(filters)),
+                                                 q=req.args.get('q'),
+                                                 page=page + 1)
+                add_link(req, 'next', next_href, 'Next Page')
+            if page > 1:
+                prev_href = self.env.href.search(zip(filters,
+                                                     ['on'] * len(filters)),
+                                                 q=req.args.get('q'),
+                                                 page=page - 1)
+                add_link(req, 'prev', prev_href, 'Previous Page')
+            req.hdf['search.page_href'] = self.env.href.search(zip(filters,
+                                                                   ['on'] * len(filters)),
+                                                               q=req.args.get('q'))
+            req.hdf['search.result'] = [
+                { 'href': result[0],
+                  'title': result[1],
+                  'date': format_datetime(result[2]),
+                  'author': result[3],
+                  'excerpt': result[4]
+                } for result in results]
+
+        add_stylesheet(req, 'common/css/search.css')
+        return 'search.cs', None
+
+    def quickjump(self, kwd):
+        if len(kwd.split()) != 1:
+            return None
+        # Ticket quickjump
+        if kwd[0] == '#' and kwd[1:].isdigit():
+            return self.env.href.ticket(kwd[1:])
+        elif kwd[0:len('ticket:')] == 'ticket:' and kwd[len('ticket:'):].isdigit():
+            return self.env.href.ticket(kwd[len('ticket:'):])
+        elif kwd[0:len('bug:')] == 'bug:' and kwd[len('bug:'):].isdigit():
+            return self.env.href.ticket(kwd[len('bug:'):])
+        # Changeset quickjump
+        elif kwd[0] == '[' and kwd[-1] == ']' and kwd[1:-1].isdigit():
+            return self.env.href.changeset(kwd[1:-1])
+        elif kwd[0:len('changeset:')] == 'changeset:' and kwd[len('changeset:'):].isdigit():
+            return self.env.href.changeset(kwd[len('changeset:'):])
+        # Report quickjump
+        elif kwd[0] == '{' and kwd[-1] == '}' and kwd[1:-1].isdigit():
+            return self.env.href.report(kwd[1:-1])
+        elif kwd[0:len('report:')] == 'report:' and kwd[len('report:'):].isdigit():
+            return self.env.href.report(kwd[len('report:'):])
+        # Milestone quickjump
+        elif kwd[0:len('milestone:')] == 'milestone:':
+            return self.env.href.milestone(kwd[len('milestone:'):])
+        # Source quickjump
+        elif kwd[0] == '/':
+            return self.env.href.browser(kwd)
+        elif kwd[0:len('source:')] == 'source:':
+            return self.env.href.browser(kwd[len('source:'):])
+        # Wiki quickjump
+        elif kwd[0:len('wiki:')] == 'wiki:':
+            r = "((^|(?<=[^A-Za-z]))[!]?[A-Z][a-z/]+(?:[A-Z][a-z/]+)+)"
+            if re.match (r, kwd[len('wiki:'):]):
+                return self.env.href.wiki(kwd[len('wiki:'):])
+        elif len(kwd) > 1 and kwd[0].isupper() and kwd[1].islower():
+            r = "((^|(?<=[^A-Za-z]))[!]?[A-Z][a-z/]+(?:[A-Z][a-z/]+)+)"
+            if re.match (r, kwd):
+                return self.env.href.wiki(kwd)
+
+    # IWikiSyntaxProvider methods
+    
+    def get_wiki_syntax(self):
+        return []
+    
+    def get_link_resolvers(self):
+        yield ('search', self._format_link)
+
+    def _format_link(self, formatter, ns, query, label):
+        if query and query[0] == '?':
+            href = formatter.href.search() + query.replace(' ', '+')
+        else:
+            href = formatter.href.search(q=query)
+        return '<a class="search" href="%s">%s</a>' % (escape(href), label)
+
diff -urN trac-trunk/build/lib/trac/Settings.py aw-trac/build/lib/trac/Settings.py
--- trac-trunk/build/lib/trac/Settings.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/Settings.py	2005-12-30 09:12:00.000000000 -0800
@@ -0,0 +1,75 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2005 Edgewall Software
+# Copyright (C) 2004-2005 Daniel Lundin <daniel@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+
+from trac.core import *
+from trac.util import Markup
+from trac.web import IRequestHandler
+from trac.web.chrome import INavigationContributor
+
+
+class SettingsModule(Component):
+
+    implements(INavigationContributor, IRequestHandler)
+
+    _form_fields = ['newsid','name', 'email']
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'settings'
+
+    def get_navigation_items(self, req):
+        yield ('metanav', 'settings',
+               Markup('<a href="%s">Settings</a>', self.env.href.settings()))
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        return req.path_info == '/settings'
+
+    def process_request(self, req):
+        action = req.args.get('action')
+
+        if req.method == 'POST':
+            if action == 'save':
+                self._do_save(req)
+            elif action == 'load':
+                self._do_load(req)
+
+        req.hdf['title'] = 'Settings'
+        req.hdf['settings'] = req.session
+        if req.authname == 'anonymous':
+            req.hdf['settings.session_id'] = req.session.sid
+
+        return 'settings.cs', None
+
+    # Internal methods
+
+    def _do_save(self, req):
+        for field in self._form_fields:
+            val = req.args.get(field)
+            if val:
+                if field == 'newsid' and val:
+                    req.session.change_sid(val)
+                else:
+                    req.session[field] = val
+        req.redirect(self.env.href.settings())
+
+    def _do_load(self, req):
+        if req.authname == 'anonymous':
+            oldsid = req.args.get('loadsid')
+            req.session.get_session(oldsid)
+        req.redirect(self.env.href.settings())
diff -urN trac-trunk/build/lib/trac/Timeline.py aw-trac/build/lib/trac/Timeline.py
--- trac-trunk/build/lib/trac/Timeline.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/Timeline.py	2006-02-08 07:13:02.000000000 -0800
@@ -0,0 +1,215 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import re
+import time
+
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.util import format_date, format_time, http_date, Markup, rss_title
+from trac.web import IRequestHandler
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+
+
+class ITimelineEventProvider(Interface):
+    """
+    Extension point interface for adding sources for timed events to the
+    timeline.
+    """
+
+    def get_timeline_filters(self, req):
+        """Return a list of filters that this event provider supports.
+        
+        Each filter must be a (name, label) tuple, where `name` is the internal
+        name, and `label` is a human-readable name for display.
+
+        Optionally, the tuple can contain a third element, `checked`.
+        If `checked` is omitted or True, the filter is active by default,
+        otherwise it will be inactive.
+        """
+
+    def get_timeline_events(self, req, start, stop, filters):
+        """Return a list of events in the time range given by the `start` and
+        `stop` parameters.
+        
+        The `filters` parameters is a list of the enabled filters, each item
+        being the name of the tuples returned by `get_timeline_filters`.
+
+        The events returned by this function must be tuples of the form
+        (kind, href, title, date, author, message).
+        """
+
+
+class TimelineModule(Component):
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler)
+
+    event_providers = ExtensionPoint(ITimelineEventProvider)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'timeline'
+
+    def get_navigation_items(self, req):
+        if not req.perm.has_permission('TIMELINE_VIEW'):
+            return
+        yield ('mainnav', 'timeline',
+               Markup('<a href="%s" accesskey="2">Timeline</a>',
+                      self.env.href.timeline()))
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        return ['TIMELINE_VIEW']
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        return re.match(r'/timeline/?', req.path_info) is not None
+
+    def process_request(self, req):
+        req.perm.assert_permission('TIMELINE_VIEW')
+
+        format = req.args.get('format')
+        maxrows = int(req.args.get('max', 0))
+
+        # Parse the from date and adjust the timestamp to the last second of
+        # the day
+        t = time.localtime()
+        if req.args.has_key('from'):
+            try:
+                t = time.strptime(req.args.get('from'), '%x')
+            except:
+                pass
+
+        fromdate = time.mktime((t[0], t[1], t[2], 23, 59, 59, t[6], t[7], t[8]))
+        try:
+            daysback = max(0, int(req.args.get('daysback', '')))
+        except ValueError:
+            daysback = int(self.config.get('timeline', 'default_daysback'))
+        req.hdf['timeline.from'] = format_date(fromdate)
+        req.hdf['timeline.daysback'] = daysback
+
+        available_filters = []
+        for event_provider in self.event_providers:
+            available_filters += event_provider.get_timeline_filters(req)
+
+        filters = []
+        # check the request or session for enabled filters, or use default
+        for test in (lambda f: req.args.has_key(f[0]),
+                     lambda f: req.session.get('timeline.filter.%s' % f[0], '')\
+                               == '1',
+                     lambda f: len(f) == 2 or f[2]):
+            if filters:
+                break
+            filters = [f[0] for f in available_filters if test(f)]
+
+        # save the results of submitting the timeline form to the session
+        if req.args.has_key('update'):
+            for filter in available_filters:
+                key = 'timeline.filter.%s' % filter[0]
+                if req.args.has_key(filter[0]):
+                    req.session[key] = '1'
+                elif req.session.has_key(key):
+                    del req.session[key]
+
+        stop = fromdate
+        start = stop - (daysback + 1) * 86400
+
+        events = []
+        for event_provider in self.event_providers:
+            try:
+                events += event_provider.get_timeline_events(req, start, stop,
+                                                             filters)
+            except Exception, e: # cope with a failure of that provider
+                self._provider_failure(e, req, event_provider, filters,
+                                       [f[0] for f in available_filters])
+
+        events.sort(lambda x,y: cmp(y[3], x[3]))
+        if maxrows and len(events) > maxrows:
+            del events[maxrows:]
+
+        req.hdf['title'] = 'Timeline'
+
+        # Get the email addresses of all known users
+        email_map = {}
+        for username, name, email in self.env.get_known_users():
+            if email:
+                email_map[username] = email
+
+        idx = 0
+        for kind, href, title, date, author, message in events:
+            event = {'kind': kind, 'title': title, 'href': href,
+                     'author': author or 'anonymous',
+                     'date': format_date(date),
+                     'time': format_time(date, '%H:%M'),
+                     'message': message}
+
+            if format == 'rss':
+                # Strip/escape HTML markup
+                event['title'] = rss_title(title)
+                event['message'] = str(message)
+
+                if author:
+                    # For RSS, author must be an email address
+                    if author.find('@') != -1:
+                        event['author.email'] = author
+                    elif email_map.has_key(author):
+                        event['author.email'] = email_map[author]
+                event['date'] = http_date(date)
+
+            req.hdf['timeline.events.%s' % idx] = event
+            idx += 1
+
+        if format == 'rss':
+            return 'timeline_rss.cs', 'application/rss+xml'
+
+        add_stylesheet(req, 'common/css/timeline.css')
+        rss_href = self.env.href.timeline([(f, 'on') for f in filters],
+                                          daysback=90, max=50, format='rss')
+        add_link(req, 'alternate', rss_href, 'RSS Feed', 'application/rss+xml',
+                 'rss')
+        for idx,fltr in enumerate(available_filters):
+            req.hdf['timeline.filters.%d' % idx] = {'name': fltr[0],
+                'label': fltr[1], 'enabled': int(fltr[0] in filters)}
+
+        return 'timeline.cs', None
+
+    def _provider_failure(self, exc, req, ep, current_filters, all_filters):
+        """Raise a TracError exception explaining the failure of a provider.
+
+        At the same time, the message will contain a link to the timeline
+        without the filters corresponding to the guilty event provider `ep`.
+        """
+        guilty_filters = [f[0] for f in ep.get_timeline_filters(req)]
+        guilty_kinds = [f[1] for f in ep.get_timeline_filters(req)]
+        other_filters = [f for f in current_filters if not f in guilty_filters]
+        if not other_filters:
+            other_filters = [f for f in all_filters if not f in guilty_filters]
+        args = [(a, req.args.get(a)) for a in ('from', 'format', 'max',
+                                               'daysback')]
+        href = self.env.href.timeline(args+[(f, 'on') for f in other_filters])
+        raise TracError(Markup('%s event provider failed:<br /><br />'
+                               '%s: %s'
+                               '<p>You may want to see the other kind '
+                               'of events from the <a href="%s">'
+                               'Timeline</a></p>',
+                               ", ".join(guilty_kinds),
+                               exc.__class__.__name__, str(exc), href))
diff -urN trac-trunk/build/lib/trac/__init__.py aw-trac/build/lib/trac/__init__.py
--- trac-trunk/build/lib/trac/__init__.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/__init__.py	2006-01-19 05:39:35.000000000 -0800
@@ -0,0 +1,45 @@
+# -*- coding: iso-8859-1 -*-
+"""
+Trac
+Edgewall Software
+
+U{http://trac.edgewall.com/}
+
+@author: Jonas Borgström <jonas@edgewall.com>
+@author: Daniel Lundin <daniel@edgewall.com>
+"""
+__docformat__ = 'epytext en'
+
+__version__ = '0.10dev'
+__url__ = 'http://trac.edgewall.com/'
+__copyright__ = '(C) 2003-2006 Edgewall Software'
+__license__ = 'BSD'
+__license_long__ = """
+ Copyright (C) 2003-2006 Edgewall Software
+ All rights reserved.
+ 
+ Redistribution and use in source and binary forms, with or without
+ modification, are permitted provided that the following conditions
+ are met:
+ 
+  1. Redistributions of source code must retain the above copyright
+     notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+     notice, this list of conditions and the following disclaimer in
+     the documentation and/or other materials provided with the
+     distribution.
+  3. The name of the author may not be used to endorse or promote
+     products derived from this software without specific prior
+     written permission.
+ 
+ THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS
+ OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
+ GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
+ IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."""
diff -urN trac-trunk/build/lib/trac/attachment.py aw-trac/build/lib/trac/attachment.py
--- trac-trunk/build/lib/trac/attachment.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/attachment.py	2006-03-06 03:36:02.000000000 -0800
@@ -0,0 +1,473 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import os
+import re
+import shutil
+import time
+import unicodedata
+import urllib
+
+from trac import perm, util
+from trac.core import *
+from trac.env import IEnvironmentSetupParticipant
+from trac.mimeview import *
+from trac.web import HTTPBadRequest, IRequestHandler
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.wiki import IWikiSyntaxProvider
+
+
+class Attachment(object):
+
+    def __init__(self, env, parent_type, parent_id, filename=None, db=None):
+        self.env = env
+        self.parent_type = parent_type
+        self.parent_id = str(parent_id)
+        if filename:
+            self._fetch(filename, db)
+        else:
+            self.filename = None
+            self.description = None
+            self.size = None
+            self.time = None
+            self.author = None
+            self.ipnr = None
+
+    def _fetch(self, filename, db=None):
+        if not db:
+            db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT filename,description,size,time,author,ipnr "
+                       "FROM attachment WHERE type=%s AND id=%s "
+                       "AND filename=%s ORDER BY time",
+                       (self.parent_type, str(self.parent_id), filename))
+        row = cursor.fetchone()
+        cursor.close()
+        if not row:
+            self.filename = filename
+            raise TracError('Attachment %s does not exist.' % (self.title),
+                            'Invalid Attachment')
+        self.filename = row[0]
+        self.description = row[1]
+        self.size = row[2] and int(row[2]) or 0
+        self.time = row[3] and int(row[3]) or 0
+        self.author = row[4]
+        self.ipnr = row[5]
+
+    def _get_path(self):
+        path = os.path.join(self.env.path, 'attachments', self.parent_type,
+                            urllib.quote(self.parent_id))
+        if self.filename:
+            path = os.path.join(path, urllib.quote(self.filename))
+        return os.path.normpath(path)
+    path = property(_get_path)
+
+    def href(self,*args,**dict):
+        return self.env.href.attachment(self.parent_type, self.parent_id,
+                                        self.filename, *args, **dict)
+
+    def _get_title(self):
+        return '%s%s: %s' % (self.parent_type == 'ticket' and '#' or '',
+                             self.parent_id, self.filename)
+    title = property(_get_title)
+
+    def _get_parent_href(self):
+        return self.env.href(self.parent_type, self.parent_id)
+    parent_href = property(_get_parent_href)
+
+    def delete(self, db=None):
+        assert self.filename, 'Cannot delete non-existent attachment'
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        cursor.execute("DELETE FROM attachment WHERE type=%s AND id=%s "
+                       "AND filename=%s", (self.parent_type, self.parent_id,
+                       self.filename))
+        if os.path.isfile(self.path):
+            try:
+                os.unlink(self.path)
+            except OSError:
+                self.env.log.error('Failed to delete attachment file %s',
+                                   self.path, exc_info=True)
+                if handle_ta:
+                    db.rollback()
+                raise TracError, 'Could not delete attachment'
+
+        self.env.log.info('Attachment removed: %s' % self.title)
+        if handle_ta:
+            db.commit()
+
+    def insert(self, filename, fileobj, size, t=None, db=None):
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        # Maximum attachment size (in bytes)
+        max_size = int(self.env.config.get('attachment', 'max_size'))
+        if max_size >= 0 and size > max_size:
+            raise TracError('Maximum attachment size: %d bytes' % max_size,
+                            'Upload failed')
+        self.size = size
+        self.time = t or time.time()
+
+        # Make sure the path to the attachment is inside the environment
+        # attachments directory
+        attachments_dir = os.path.join(os.path.normpath(self.env.path),
+                                       'attachments')
+        commonprefix = os.path.commonprefix([attachments_dir, self.path])
+        assert commonprefix == attachments_dir
+
+        if not os.access(self.path, os.F_OK):
+            os.makedirs(self.path)
+        filename = urllib.quote(filename)
+        path, targetfile = util.create_unique_file(os.path.join(self.path,
+                                                                filename))
+        try:
+            filename = urllib.unquote(os.path.basename(path))
+
+            cursor = db.cursor()
+            cursor.execute("INSERT INTO attachment "
+                           "VALUES (%s,%s,%s,%s,%s,%s,%s,%s)",
+                           (self.parent_type, self.parent_id, filename,
+                            self.size, self.time, self.description, self.author,
+                            self.ipnr))
+            shutil.copyfileobj(fileobj, targetfile)
+            self.filename = filename
+
+            self.env.log.info('New attachment: %s by %s', self.title,
+                              self.author)
+            if handle_ta:
+                db.commit()
+        finally:
+            targetfile.close()
+
+    def select(cls, env, parent_type, parent_id, db=None):
+        if not db:
+            db = env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT filename,description,size,time,author,ipnr "
+                       "FROM attachment WHERE type=%s AND id=%s ORDER BY time",
+                       (parent_type, str(parent_id)))
+        for filename,description,size,time,author,ipnr in cursor:
+            attachment = Attachment(env, parent_type, parent_id)
+            attachment.filename = filename
+            attachment.description = description
+            attachment.size = size
+            attachment.time = time
+            attachment.author = author
+            attachment.ipnr = ipnr
+            yield attachment
+
+    select = classmethod(select)
+
+    def open(self):
+        self.env.log.debug('Trying to open attachment at %s', self.path)
+        try:
+            fd = open(self.path, 'rb')
+        except IOError:
+            raise TracError('Attachment %s not found' % self.filename)
+        return fd
+
+
+def attachment_to_hdf(env, db, req, attachment):
+    from trac.wiki import wiki_to_oneliner
+    if not db:
+        db = env.get_db_cnx()
+    hdf = {
+        'filename': attachment.filename,
+        'description': wiki_to_oneliner(attachment.description, env, db),
+        'author': attachment.author,
+        'ipnr': attachment.ipnr,
+        'size': util.pretty_size(attachment.size),
+        'time': util.format_datetime(attachment.time),
+        'href': attachment.href()
+    }
+    return hdf
+
+
+class AttachmentModule(Component):
+
+    implements(IEnvironmentSetupParticipant, IRequestHandler,
+               INavigationContributor, IWikiSyntaxProvider)
+
+    CHUNK_SIZE = 4096
+
+    # IEnvironmentSetupParticipant methods
+
+    def environment_created(self):
+        """Create the attachments directory."""
+        if self.env.path:
+            os.mkdir(os.path.join(self.env.path, 'attachments'))
+
+    def environment_needs_upgrade(self, db):
+        return False
+
+    def upgrade_environment(self, db):
+        pass
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return req.args.get('type')
+
+    def get_navigation_items(self, req):
+        return []
+
+    # IReqestHandler methods
+
+    def match_request(self, req):
+        match = re.match(r'^/attachment/(ticket|wiki)(?:/(.*))?$', req.path_info)
+        if match:
+            req.args['type'] = match.group(1)
+            req.args['path'] = match.group(2)
+            return 1
+
+    def process_request(self, req):
+        parent_type = req.args.get('type')
+        path = req.args.get('path')
+        if not parent_type or not path:
+            raise HTTPBadRequest('Bad request')
+        if not parent_type in ['ticket', 'wiki']:
+            raise HTTPBadRequest('Unknown attachment type')
+
+        action = req.args.get('action', 'view')
+        if action == 'new':
+            attachment = Attachment(self.env, parent_type, path)
+        else:
+            segments = path.split('/')
+            parent_id = '/'.join(segments[:-1])
+            filename = segments[-1]
+            if len(segments) == 1 or not filename:
+                raise HTTPBadRequest('Bad request')
+            attachment = Attachment(self.env, parent_type, parent_id, filename)
+
+        if req.method == 'POST':
+            if action == 'new':
+                self._do_save(req, attachment)
+            elif action == 'delete':
+                self._do_delete(req, attachment)
+        elif action == 'delete':
+            self._render_confirm(req, attachment)
+        elif action == 'new':
+            self._render_form(req, attachment)
+        else:
+            self._render_view(req, attachment)
+
+        add_stylesheet(req, 'common/css/code.css')
+        return 'attachment.cs', None
+
+    # IWikiSyntaxProvider methods
+    
+    def get_wiki_syntax(self):
+        return []
+
+    def get_link_resolvers(self):
+        yield ('attachment', self._format_link)
+
+    # Internal methods
+
+    def _do_save(self, req, attachment):
+        perm_map = {'ticket': 'TICKET_APPEND', 'wiki': 'WIKI_MODIFY'}
+        req.perm.assert_permission(perm_map[attachment.parent_type])
+
+        if req.args.has_key('cancel'):
+            req.redirect(attachment.parent_href)
+
+        upload = req.args['attachment']
+        if not hasattr(upload, 'filename') or not upload.filename:
+            raise TracError('No file uploaded')
+        if hasattr(upload.file, 'fileno'):
+            size = os.fstat(upload.file.fileno())[6]
+        else:
+            size = upload.file.len
+        if size == 0:
+            raise TracError('No file uploaded')
+
+        filename = upload.filename.replace('\\', '/').replace(':', '/')
+        filename = os.path.basename(filename)
+        if not filename:
+            raise TracError('No file uploaded')
+
+        # We try to normalize the filename to utf-8 NFC if we can.
+        # Files uploaded from OS X might be in NFD.
+        filename = unicodedata.normalize('NFC',
+                                         unicode(filename, 'utf-8')).encode('utf-8')
+
+        attachment.description = req.args.get('description', '')
+        attachment.author = req.args.get('author', '')
+        attachment.ipnr = req.remote_addr
+        if req.args.get('replace'):
+            try:
+                old_attachment = Attachment(self.env, attachment.parent_type,
+                                            attachment.parent_id, filename)
+                if not (old_attachment.author and req.authname \
+                        and old_attachment.author == req.authname):
+                    perm_map = {'ticket': 'TICKET_ADMIN', 'wiki': 'WIKI_DELETE'}
+                    req.perm.assert_permission(perm_map[old_attachment.parent_type])
+                old_attachment.delete()
+            except TracError:
+                pass # don't worry if there's nothing to replace
+            attachment.filename = None
+        attachment.insert(filename, upload.file, size)
+
+        # Redirect the user to the newly created attachment
+        req.redirect(attachment.href())
+
+    def _do_delete(self, req, attachment):
+        perm_map = {'ticket': 'TICKET_ADMIN', 'wiki': 'WIKI_DELETE'}
+        req.perm.assert_permission(perm_map[attachment.parent_type])
+
+        if req.args.has_key('cancel'):
+            req.redirect(attachment.href())
+
+        attachment.delete()
+
+        # Redirect the user to the attachment parent page
+        req.redirect(attachment.parent_href)
+
+    def _get_parent_link(self, attachment):
+        if attachment.parent_type == 'ticket':
+            return ('Ticket #' + attachment.parent_id, attachment.parent_href)
+        elif attachment.parent_type == 'wiki':
+            return (attachment.parent_id, attachment.parent_href)
+        return (None, None)
+
+    def _render_confirm(self, req, attachment):
+        perm_map = {'ticket': 'TICKET_ADMIN', 'wiki': 'WIKI_DELETE'}
+        req.perm.assert_permission(perm_map[attachment.parent_type])
+
+        req.hdf['title'] = '%s (delete)' % attachment.title
+        text, link = self._get_parent_link(attachment)
+        req.hdf['attachment'] = {
+            'filename': attachment.filename,
+            'mode': 'delete',
+            'parent': {'type': attachment.parent_type,
+                       'id': attachment.parent_id, 'name': text, 'href': link}
+        }
+
+    def _render_form(self, req, attachment):
+        perm_map = {'ticket': 'TICKET_APPEND', 'wiki': 'WIKI_MODIFY'}
+        req.perm.assert_permission(perm_map[attachment.parent_type])
+
+        text, link = self._get_parent_link(attachment)
+        req.hdf['attachment'] = {
+            'mode': 'new',
+            'author': util.get_reporter_id(req),
+            'parent': {'type': attachment.parent_type,
+                       'id': attachment.parent_id, 'name': text, 'href': link}
+        }
+
+    def _render_view(self, req, attachment):
+        perm_map = {'ticket': 'TICKET_VIEW', 'wiki': 'WIKI_VIEW'}
+        req.perm.assert_permission(perm_map[attachment.parent_type])
+
+        req.check_modified(attachment.time)
+
+        # Render HTML view
+        text, link = self._get_parent_link(attachment)
+        add_link(req, 'up', link, text)
+
+        req.hdf['title'] = attachment.title
+        req.hdf['attachment'] = attachment_to_hdf(self.env, None, req,
+                                                  attachment)
+        req.hdf['attachment.parent'] = {
+            'type': attachment.parent_type, 'id': attachment.parent_id,
+            'name': text, 'href': link,
+        }
+
+        perm_map = {'ticket': 'TICKET_ADMIN', 'wiki': 'WIKI_DELETE'}
+        if req.perm.has_permission(perm_map[attachment.parent_type]):
+            req.hdf['attachment.can_delete'] = 1
+
+        fd = attachment.open()
+        try:
+            mimeview = Mimeview(self.env)
+            data = fd.read(mimeview.max_preview_size())
+
+            mime_type = get_mimetype(attachment.filename, data) or \
+                        'application/octet-stream'
+            self.log.debug("Rendering preview of file %s with mime-type %s"
+                           % (attachment.filename, mime_type))
+
+            raw_href = attachment.href(format='raw')
+            add_link(req, 'alternate', raw_href, 'Original Format', mime_type)
+            req.hdf['attachment.raw_href'] = raw_href
+
+            format = req.args.get('format')
+            render_unsafe = self.config.getbool('attachment',
+                                                'render_unsafe_content')
+            binary = not detect_unicode(data) and is_binary(data)
+
+            if format in ('raw', 'txt'): # Send raw file
+                if not render_unsafe and not binary:
+                    # Force browser to download HTML/SVG/etc pages that may
+                    # contain malicious code enabling XSS attacks
+                    req.send_header('Content-Disposition', 'attachment;' +
+                                    'filename=' + attachment.filename)
+                charset = mimeview.get_charset(data, mime_type)
+                if render_unsafe and not binary and format == 'txt':
+                    mime_type = 'text/plain'
+                req.send_file(attachment.path,
+                              mime_type + ';charset=' + charset)
+
+            if render_unsafe and not binary:
+                plaintext_href = attachment.href(format='txt')
+                add_link(req, 'alternate', plaintext_href, 'Plain Text',
+                         mime_type)
+
+            hdf = mimeview.preview_to_hdf(req, data, mime_type,
+                                          attachment.filename, None,
+                                          annotations=['lineno'])
+            req.hdf['attachment'] = hdf
+        finally:
+            fd.close()
+
+    def _format_link(self, formatter, ns, link, label):
+        ids = link.split(':', 2)
+        params = ''
+        if len(ids) == 3:
+            parent_type, parent_id, filename = ids
+        else:
+            # FIXME: the formatter should know which object the text being
+            #        formatter belongs to
+            parent_type, parent_id = 'wiki', 'WikiStart'
+            if formatter.req:
+                path_info = formatter.req.path_info.split('/', 2)
+                if len(path_info) > 1:
+                    parent_type = path_info[1]
+                if len(path_info) > 2:
+                    parent_id = path_info[2]
+            filename = link
+        idx = filename.find('?')
+        if idx >= 0:
+            filename, params = filename[:idx], filename[idx:]
+        try:
+            attachment = Attachment(self.env, parent_type, parent_id, filename)
+            return '<a class="attachment" title="Attachment %s" href="%s">%s</a>' \
+                   % (util.escape(attachment.title),
+                      util.escape(attachment.href() + params),
+                      util.escape(label))
+        except TracError:
+            return '<a class="missing attachment" href="%s" rel="nofollow">%s</a>' \
+                   % (self.env.href.wiki(), label)
diff -urN trac-trunk/build/lib/trac/config.py aw-trac/build/lib/trac/config.py
--- trac-trunk/build/lib/trac/config.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/config.py	2006-02-10 02:09:59.000000000 -0800
@@ -0,0 +1,141 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+from ConfigParser import ConfigParser
+import os
+import sys
+
+_TRUE_VALUES = ('yes', 'true',  'on', 'aye', '1', 1, True)
+
+
+class Configuration:
+    """Thin layer over `ConfigParser` from the Python standard library.
+
+    In addition to providing some convenience methods, the class remembers
+    the last modification time of the configuration file, and reparses it
+    when the file has changed.
+    """
+
+    def __init__(self, filename):
+        self._defaults = {}
+        self.filename = filename
+        self.parser = ConfigParser()
+        self._lastmtime = 0
+        self.site_filename = os.path.join(default_dir('conf'), 'trac.ini')
+        self.site_parser = ConfigParser()
+        self._lastsitemtime = 0
+        self.parse_if_needed()
+
+    def get(self, section, name, default=None):
+        if not self.parser.has_option(section, name):
+            return self._defaults.get((section, name)) or default or ''
+        return self.parser.get(section, name)
+
+    def getbool(self, section, name, default=None):
+        """Return the specified option as boolean value.
+        
+        If the value of the option is one of "yes", "true",  "on", or "1", this
+        method wll return `True`, otherwise `False`.
+        
+        (since Trac 0.9.3)
+        """
+        if isinstance(default, basestring):
+            default = default.lower()
+        return self.get(section, name, default) in _TRUE_VALUES
+
+    def setdefault(self, section, name, value):
+        if (section, name) not in self._defaults:
+            self._defaults[(section, name)] = value
+
+    def set(self, section, name, value):
+        """Change a configuration value.
+        
+        These changes are not persistent unless saved with `save()`.
+        """
+        if not self.parser.has_section(section):
+            self.parser.add_section(section)
+        return self.parser.set(section, name, value)
+
+    def options(self, section):
+        options = []
+        if self.parser.has_section(section):
+            for option in self.parser.options(section):
+                options.append((option, self.parser.get(section, option)))
+        for option, value in self._defaults.iteritems():
+            if option[0] == section:
+                if not [exists for exists in options if exists[0] == option[1]]:
+                    options.append((option[1], value))
+        return options
+
+    def __contains__(self, name):
+        return self.parser.has_section(name)
+
+    def remove(self, section, name):
+        if self.parser.has_section(section):
+            self.parser.remove_option(section, name)
+
+    def sections(self):
+        return self.parser.sections()
+
+    def save(self):
+        if not self.filename:
+            return
+        fileobj = file(self.filename, 'w')
+        try:
+            self.parser.write(fileobj)
+        finally:
+            fileobj.close()
+
+    def parse_if_needed(self):
+        # Merge global configuration option into _defaults
+        if os.path.isfile(self.site_filename):
+            modtime = os.path.getmtime(self.site_filename)
+            if modtime > self._lastsitemtime:
+                self.site_parser.read(self.site_filename)
+                for section in self.site_parser.sections():
+                    for option in self.site_parser.options(section):
+                        value = self.site_parser.get(section, option)
+                        self._defaults[(section, option)] = value
+                self._lastsitemtime = modtime
+
+        if not self.filename or not os.path.isfile(self.filename):
+            return
+        modtime = os.path.getmtime(self.filename)
+        if modtime > self._lastmtime:
+            self.parser.read(self.filename)
+            self._lastmtime = modtime
+
+
+def default_dir(name):
+    try:
+        from trac import siteconfig
+        return getattr(siteconfig, '__default_%s_dir__' % name)
+    except ImportError:
+        # This is not a regular install with a generated siteconfig.py file,
+        # so try to figure out the directory based on common setups
+        special_dirs = {'wiki': 'wiki-default', 'macros': 'wiki-macros'}
+        dirname = special_dirs.get(name, name)
+
+        # First assume we're being executing directly form the source directory
+        import trac
+        path = os.path.join(os.path.split(os.path.dirname(trac.__file__))[0],
+                            dirname)
+        if not os.path.isdir(path):
+            # Not being executed from the source directory, so assume the
+            # default installation prefix
+            path = os.path.join(sys.prefix, 'share', 'trac', dirname)
+
+        return path
diff -urN trac-trunk/build/lib/trac/core.py aw-trac/build/lib/trac/core.py
--- trac-trunk/build/lib/trac/core.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/core.py	2006-03-08 01:23:06.000000000 -0800
@@ -0,0 +1,223 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2004 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+__all__ = ['Component', 'ExtensionPoint', 'SingletonExtensionPoint',
+           'implements', 'Interface', 'TracError']
+
+
+class TracError(Exception):
+    """Exception base class for errors in Trac."""
+
+    def __init__(self, message, title=None, show_traceback=False):
+        Exception.__init__(self, message)
+        self.message = message
+        self.title = title
+        self.show_traceback = show_traceback
+
+
+class Interface(object):
+    """Marker base class for extension point interfaces."""
+
+
+class ExtensionPoint(property):
+    """Marker class for extension points in components."""
+
+    def __init__(self, interface):
+        """Create the extension point.
+        
+        @param interface: the `Interface` subclass that defines the protocol
+            for the extension point
+        """
+        property.__init__(self, self.extensions)
+        self.interface = interface
+        self.__doc__ = 'List of components that implement `%s`' % \
+                       self.interface.__name__
+
+    def extensions(self, component):
+        """Return a list of components that declare to implement the extension
+        point interface."""
+        extensions = ComponentMeta._registry.get(self.interface, [])
+        return filter(None, [component.compmgr[cls] for cls in extensions])
+
+    def __repr__(self):
+        """Return a textual representation of the extension point."""
+        return '<ExtensionPoint %s>' % self.interface.__name__
+
+
+class SingletonExtensionPoint(property):
+    def __init__(self, interface, cfg_section, cfg_property, default=None):
+        property.__init__(self, self.implementation)
+        self.xtnpt = ExtensionPoint(interface)
+        self.cfg_section = cfg_section
+        self.cfg_property = cfg_property
+        self.default = default
+
+    def implementation(self, component):
+        cfgvalue = component.config.get(self.cfg_section, self.cfg_property)
+        for impl in self.xtnpt.extensions(component):
+            if impl.__class__.__name__ == cfgvalue:
+                return impl
+        if self.default is not None:
+            return self.default(component.env)
+        raise AttributeError('Cannot find an implementation of the "%s" '
+                             'interface named "%s".  Please update your '
+                             'trac.ini setting "%s.%s"'
+                             % (self.xtnpt.interface.__name__, cfgvalue,
+                                self.cfg_section, self.cfg_property))
+
+
+class ComponentMeta(type):
+    """Meta class for components.
+    
+    Takes care of component and extension point registration.
+    """
+    _components = []
+    _registry = {}
+
+    def __new__(cls, name, bases, d):
+        """Create the component class."""
+
+        new_class = type.__new__(cls, name, bases, d)
+        if name == 'Component':
+            # Don't put the Component base class in the registry
+            return new_class
+
+        # Only override __init__ for Components not inheriting ComponentManager
+        if True not in [issubclass(x, ComponentManager) for x in bases]:
+            # Allow components to have a no-argument initializer so that
+            # they don't need to worry about accepting the component manager
+            # as argument and invoking the super-class initializer
+            init = d.get('__init__')
+            if not init:
+                # Because we're replacing the initializer, we need to make sure
+                # that any inherited initializers are also called.
+                for init in [b.__init__._original for b in new_class.mro()
+                             if issubclass(b, Component)
+                             and b.__dict__.has_key('__init__')]:
+                    break
+            def maybe_init(self, compmgr, init=init, cls=new_class):
+                if not cls in compmgr.components:
+                    compmgr.components[cls] = self
+                    if init:
+                        init(self)
+            maybe_init._original = init
+            setattr(new_class, '__init__', maybe_init)
+
+        if d.get('abstract'):
+            # Don't put abstract component classes in the registry
+            return new_class
+
+        ComponentMeta._components.append(new_class)
+        for interface in d.get('_implements', []):
+            ComponentMeta._registry.setdefault(interface, []).append(new_class)
+        for base in [base for base in bases if hasattr(base, '_implements')]:
+            for interface in base._implements:
+                ComponentMeta._registry.setdefault(interface, []).append(new_class)
+
+        return new_class
+
+
+def implements(*interfaces):
+    """
+    Can be used in the class definiton of `Component` subclasses to declare
+    the extension points that are extended.
+    """
+    import sys
+
+    frame = sys._getframe(1)
+    locals = frame.f_locals
+
+    # Some sanity checks
+    assert locals is not frame.f_globals and '__module__' in frame.f_locals, \
+           'implements() can only be used in a class definition'
+    assert not '_implements' in locals, \
+           'implements() can only be used once in a class definition'
+
+    locals['_implements'] = interfaces
+
+
+class Component(object):
+    """Base class for components.
+
+    Every component can declare what extension points it provides, as well as
+    what extension points of other components it extends.
+    """
+    __metaclass__ = ComponentMeta
+
+    def __new__(cls, *args, **kwargs):
+        """Return an existing instance of the component if it has already been
+        activated, otherwise create a new instance.
+        """
+        # If this component is also the component manager, just invoke that
+        if issubclass(cls, ComponentManager):
+            self = super(Component, cls).__new__(cls)
+            self.compmgr = self
+            return self
+
+        # The normal case where the component is not also the component manager
+        compmgr = args[0]
+        if not cls in compmgr.components:
+            self = super(Component, cls).__new__(cls)
+            self.compmgr = compmgr
+            compmgr.component_activated(self)
+            return self
+        return compmgr[cls]
+
+
+class ComponentManager(object):
+    """The component manager keeps a pool of active components."""
+
+    def __init__(self):
+        """Initialize the component manager."""
+        self.components = {}
+        if isinstance(self, Component):
+            self.components[self.__class__] = self
+
+    def __contains__(self, cls):
+        """Return wether the given class is in the list of active components."""
+        return cls in self.components
+
+    def __getitem__(self, cls):
+        """Activate the component instance for the given class, or return the
+        existing the instance if the component has already been activated."""
+        component = self.components.get(cls)
+        if not component:
+            if not self.is_component_enabled(cls):
+                return None
+            if cls not in ComponentMeta._components:
+                raise TracError, 'Component "%s" not registered' % cls.__name__
+            try:
+                component = cls(self)
+            except TypeError, e:
+                raise TracError, 'Unable to instantiate component "%s" (%s)' \
+                                 % (cls.__name__, e)
+        return component
+
+    def component_activated(self, component):
+        """Can be overridden by sub-classes so that special initialization for
+        components can be provided.
+        """
+
+    def is_component_enabled(self, cls):
+        """Can be overridden by sub-classes to veto the activation of a
+        component.
+
+        If this method returns False, the component with the given class will
+        not be available.
+        """
+        return True
diff -urN trac-trunk/build/lib/trac/db/__init__.py aw-trac/build/lib/trac/db/__init__.py
--- trac-trunk/build/lib/trac/db/__init__.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/db/__init__.py	2005-11-24 13:45:40.000000000 -0800
@@ -0,0 +1,2 @@
+from trac.db.api import *
+from trac.db.schema import *
diff -urN trac-trunk/build/lib/trac/db/api.py aw-trac/build/lib/trac/db/api.py
--- trac-trunk/build/lib/trac/db/api.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/db/api.py	2005-11-27 09:20:19.000000000 -0800
@@ -0,0 +1,150 @@
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+import os
+import urllib
+
+from trac.core import *
+from trac.db.pool import ConnectionPool
+
+
+class IDatabaseConnector(Interface):
+    """Extension point interface for components that support the connection to
+    relational databases."""
+
+    def get_supported_schemes():
+        """Return the connection URL schemes supported by the connector, and
+        their relative priorities as an iterable of `(scheme, priority)` tuples.
+        """
+
+    def get_connection(**kwargs):
+        """Create a new connection to the database."""
+        
+    def init_db(**kwargs):
+        """Initialize the database."""
+
+    def to_sql(table):
+        """Return the DDL statements necessary to create the specified table,
+        including indices."""
+
+
+class DatabaseManager(Component):
+
+    connectors = ExtensionPoint(IDatabaseConnector)
+
+    def __init__(self):
+        self._cnx_pool = None
+
+    def init_db(self):
+        connector, args = self._get_connector()
+        connector.init_db(**args)
+
+    def get_connection(self):
+        if not self._cnx_pool:
+            connector, args = self._get_connector()
+            self._cnx_pool = ConnectionPool(5, connector, **args)
+        return self._cnx_pool.get_cnx()
+
+    def shutdown(self):
+        if self._cnx_pool:
+            self._cnx_pool.shutdown()
+            self._cnx_pool = None
+
+    def _get_connector(self): ### FIXME: Make it public?
+        scheme, args = _parse_db_str(self.env.config.get('trac', 'database'))
+        candidates = {}
+        for connector in self.connectors:
+            for scheme_, priority in connector.get_supported_schemes():
+                if scheme_ != scheme:
+                    continue
+                highest = candidates.get(scheme_, (None, 0))[1]
+                if priority > highest:
+                    candidates[scheme] = (connector, priority)
+            connector = candidates.get(scheme, [None])[0]
+        if not connector:
+            raise TracError, 'Unsupported database type "%s"' % scheme
+
+        if scheme == 'sqlite':
+            # Special case for SQLite to support a path relative to the
+            # environment directory
+            if args['path'] != ':memory:' and \
+                   not args['path'].startswith('/'):
+                args['path'] = os.path.join(self.env.path,
+                                            args['path'].lstrip('/'))
+
+        return connector, args
+
+
+def _parse_db_str(db_str):
+    scheme, rest = db_str.split(':', 1)
+
+    if not rest.startswith('/'):
+        if scheme == 'sqlite':
+            # Support for relative and in-memory SQLite connection strings
+            host = None
+            path = rest
+        else:
+            raise TracError, 'Database connection string %s must start with ' \
+                             'scheme:/' % db_str
+    else:
+        if rest.startswith('/') and not rest.startswith('//'):
+            host = None
+            rest = rest[1:]
+        elif rest.startswith('///'):
+            host = None
+            rest = rest[3:]
+        else:
+            rest = rest[2:]
+            if rest.find('/') == -1:
+                host = rest
+                rest = ''
+            else:
+                host, rest = rest.split('/', 1)
+        path = None
+
+    if host and host.find('@') != -1:
+        user, host = host.split('@', 1)
+        if user.find(':') != -1:
+            user, password = user.split(':', 1)
+        else:
+            password = None
+    else:
+        user = password = None
+    if host and host.find(':') != -1:
+        host, port = host.split(':')
+        port = int(port)
+    else:
+        port = None
+
+    if not path:
+        path = '/' + rest
+    if os.name == 'nt':
+        # Support local paths containing drive letters on Win32
+        if len(rest) > 1 and rest[1] == '|':
+            path = "%s:%s" % (rest[0], rest[2:])
+
+    params = {}
+    if path.find('?') != -1:
+        path, qs = path.split('?', 1)
+        qs = qs.split('&')
+        for param in qs:
+            name, value = param.split('=', 1)
+            value = urllib.unquote(value)
+            params[name] = value
+
+    args = zip(('user', 'password', 'host', 'port', 'path', 'params'),
+               (user, password, host, port, path, params))
+    return scheme, dict([(key, value) for key, value in args if value])
diff -urN trac-trunk/build/lib/trac/db/pool.py aw-trac/build/lib/trac/db/pool.py
--- trac-trunk/build/lib/trac/db/pool.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/db/pool.py	2006-01-13 14:45:47.000000000 -0800
@@ -0,0 +1,119 @@
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+try:
+    import threading
+except ImportError:
+    import dummy_threading as threading
+    threading._get_ident = lambda: 0
+import time
+
+from trac.db.util import ConnectionWrapper
+
+
+class TimeoutError(Exception):
+    """Exception raised by the connection pool when no connection has become
+    available after a given timeout."""
+
+
+class PooledConnection(ConnectionWrapper):
+    """A database connection that can be pooled. When closed, it gets returned
+    to the pool.
+    """
+
+    def __init__(self, pool, cnx):
+        ConnectionWrapper.__init__(self, cnx)
+        self._pool = pool
+
+    def close(self):
+        if self.cnx:
+            self._pool._return_cnx(self.cnx)
+            self.cnx = None
+
+    def __del__(self):
+        self.close()
+
+
+class ConnectionPool(object):
+    """A very simple connection pool implementation."""
+
+    def __init__(self, maxsize, connector, **kwargs):
+        self._dormant = [] # inactive connections in pool
+        self._active = {} # active connections by thread ID
+        self._available = threading.Condition(threading.Lock())
+        self._maxsize = maxsize # maximum pool size
+        self._cursize = 0 # current pool size, includes active connections
+        self._connector = connector
+        self._kwargs = kwargs
+
+    def get_cnx(self, timeout=None):
+        start = time.time()
+        self._available.acquire()
+        try:
+            tid = threading._get_ident()
+            if tid in self._active:
+                self._active[tid][0] += 1
+                return PooledConnection(self, self._active[tid][1])
+            while True:
+                if self._dormant:
+                    cnx = self._dormant.pop()
+                    break
+                elif self._maxsize and self._cursize < self._maxsize:
+                    cnx = self._connector.get_connection(**self._kwargs)
+                    self._cursize += 1
+                    break
+                else:
+                    if timeout:
+                        self._available.wait(timeout)
+                        if (time.time() - start) >= timeout:
+                            raise TimeoutError, 'Unable to get database ' \
+                                                'connection within %d seconds' \
+                                                % timeout
+                    else:
+                        self._available.wait()
+            self._active[tid] = [1, cnx]
+            return PooledConnection(self, cnx)
+        finally:
+            self._available.release()
+
+    def _return_cnx(self, cnx):
+        self._available.acquire()
+        try:
+            tid = threading._get_ident()
+            if tid in self._active:
+                num, cnx_ = self._active.get(tid)
+                assert cnx is cnx_
+                if num > 1:
+                    self._active[tid][0] = num - 1
+                else:
+                    del self._active[tid]
+                    if cnx not in self._dormant:
+                        cnx.rollback()
+                        if cnx.poolable:
+                            self._dormant.append(cnx)
+                        else:
+                            self._cursize -= 1
+                        self._available.notify()
+        finally:
+            self._available.release()
+
+    def shutdown(self):
+        self._available.acquire()
+        try:
+            for cnx in self._dormant:
+                cnx.cnx.close()
+        finally:
+            self._available.release()
diff -urN trac-trunk/build/lib/trac/db/postgres_backend.py aw-trac/build/lib/trac/db/postgres_backend.py
--- trac-trunk/build/lib/trac/db/postgres_backend.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/db/postgres_backend.py	2006-03-08 16:14:58.000000000 -0800
@@ -0,0 +1,141 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+from trac.core import *
+from trac.db.api import IDatabaseConnector
+from trac.db.util import ConnectionWrapper
+
+psycopg = None
+PgSQL = None
+PGSchemaError = None
+
+
+class PostgreSQLConnector(Component):
+    """PostgreSQL database support."""
+
+    implements(IDatabaseConnector)
+
+    def get_supported_schemes(self):
+        return [('postgres', 1)]
+
+    def get_connection(self, path, user=None, password=None, host=None,
+                       port=None, params={}):
+        return PostgreSQLConnection(path, user, password, host, port, params)
+
+    def init_db(self, path, user=None, password=None, host=None, port=None,
+                params={}):
+        cnx = self.get_connection(path, user, password, host, port, params)
+        cursor = cnx.cursor()
+        if cnx.schema:
+            cursor.execute('CREATE SCHEMA %s' % cnx.schema) 
+            cursor.execute('SET search_path TO %s, public', (cnx.schema,)) 
+        from trac.db_default import schema
+        for table in schema:
+            for stmt in self.to_sql(table):
+                cursor.execute(stmt)
+        cnx.commit()
+
+    def to_sql(self, table):
+        sql = ["CREATE TABLE %s (" % table.name]
+        coldefs = []
+        for column in table.columns:
+            ctype = column.type
+            if column.auto_increment:
+                ctype = "SERIAL"
+            if len(table.key) == 1 and column.name in table.key:
+                ctype += " PRIMARY KEY"
+            coldefs.append("    %s %s" % (column.name, ctype))
+        if len(table.key) > 1:
+            coldefs.append("    CONSTRAINT %s_pk PRIMARY KEY (%s)"
+                           % (table.name, ','.join(table.key)))
+        sql.append(',\n'.join(coldefs) + '\n)')
+        yield '\n'.join(sql)
+        for index in table.indices:
+            yield "CREATE INDEX %s_%s_idx ON %s (%s)" % (table.name, 
+                   '_'.join(index.columns), table.name, ','.join(index.columns))
+
+
+class PostgreSQLConnection(ConnectionWrapper):
+    """Connection wrapper for PostgreSQL."""
+
+    poolable = True
+
+    def __init__(self, path, user=None, password=None, host=None, port=None,
+                 params={}):
+        if path.startswith('/'):
+            path = path[1:]
+        # We support both psycopg and PgSQL but prefer psycopg
+        global psycopg
+        global PgSQL
+        global PGSchemaError
+        if not psycopg and not PgSQL:
+            try:
+                try:
+                    from psycopg2 import ProgrammingError as PGSchemaError
+                    import psycopg2 as psycopg
+                except ImportError:
+                    import psycopg
+                    from psycopg import ProgrammingError as PGSchemaError
+            except ImportError:
+                from pyPgSQL import PgSQL
+                from pyPgSQL.libpq import OperationalError as PGSchemaError
+        if psycopg:
+            dsn = []
+            if path:
+                dsn.append('dbname=' + path)
+            if user:
+                dsn.append('user=' + user)
+            if password:
+                dsn.append('password=' + password)
+            if host:
+                dsn.append('host=' + host)
+            if port:
+                dsn.append('port=' + str(port))
+            cnx = psycopg.connect(' '.join(dsn))
+        else:
+            cnx = PgSQL.connect('', user, password, host, path, port)
+        try: 
+            self.schema = None
+            if 'schema' in params:
+                self.schema = params['schema'] 
+            cnx.cursor().execute('SET search_path TO %s, public', (self.schema,)) 
+        except PGSchemaError: 
+            cnx.rollback() 
+        ConnectionWrapper.__init__(self, cnx)
+
+    def cast(self, column, type):
+        # Temporary hack needed for the union of selects in the search module
+        return 'CAST(%s AS %s)' % (column, type)
+
+    def like(self):
+        # Temporary hack needed for the case-insensitive string matching in the
+        # search module
+        return 'ILIKE'
+
+    def get_last_id(self, cursor, table, column='id'):
+        cursor.execute("SELECT CURRVAL('%s_%s_seq')" % (table, column))
+        return cursor.fetchone()[0]
+
+    def cursor(self):
+        cursor = self.cnx.cursor()
+        if self.schema:
+            try:
+                cursor.execute("SET search_path TO %s, public", (self.schema,))
+                self.cnx.commit()
+            except PGSchemaError:
+                self.cnx.rollback()
+        return cursor
+
diff -urN trac-trunk/build/lib/trac/db/schema.py aw-trac/build/lib/trac/db/schema.py
--- trac-trunk/build/lib/trac/db/schema.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/db/schema.py	2005-11-24 13:45:40.000000000 -0800
@@ -0,0 +1,50 @@
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+
+class Table(object):
+    """Declare a table in a database schema."""
+
+    def __init__(self, name, key=[]):
+        self.name = name
+        self.columns = []
+        self.indices = []
+        self.key = key
+        if isinstance(key, (str, unicode)):
+            self.key = [key]
+
+    def __getitem__(self, objs):
+        self.columns = [o for o in objs if isinstance(o, Column)]
+        self.indices = [o for o in objs if isinstance(o, Index)]
+        return self
+
+
+class Column(object):
+    """Declare a table column in a database schema."""
+
+    def __init__(self, name, type='text', size=None, unique=False,
+                 auto_increment=False):
+        self.name = name
+        self.type = type
+        self.size = size
+        self.auto_increment = auto_increment
+
+
+class Index(object):
+    """Declare an index for a database schema."""
+
+    def __init__(self, columns):
+        self.columns = columns
diff -urN trac-trunk/build/lib/trac/db/sqlite_backend.py aw-trac/build/lib/trac/db/sqlite_backend.py
--- trac-trunk/build/lib/trac/db/sqlite_backend.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/db/sqlite_backend.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,180 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+import os
+import weakref
+
+from trac.core import *
+from trac.db.api import IDatabaseConnector
+from trac.db.util import ConnectionWrapper
+
+try:
+    import pysqlite2.dbapi2 as sqlite
+    have_pysqlite = 2
+
+    class PyFormatCursor(sqlite.Cursor):
+        def _rollback_on_error(self, function, *args, **kwargs):
+            try:
+                return function(self, *args, **kwargs)
+            except sqlite.OperationalError, e:
+                self.cnx.rollback()
+                raise
+        def execute(self, sql, args=None):
+            if args:
+                sql = sql % (('?',) * len(args))
+            return self._rollback_on_error(sqlite.Cursor.execute, sql,
+                                           args or [])
+        def executemany(self, sql, args=None):
+            if args:
+                sql = sql % (('?',) * len(args[0]))
+            return self._rollback_on_error(sqlite.Cursor.executemany, sql,
+                                           args or [])
+        def _convert_row(self, row):
+            return tuple([(isinstance(v, unicode) and [v.encode('utf-8')] or [v])[0]
+                          for v in row])
+        def fetchone(self):
+            row = sqlite.Cursor.fetchone(self)
+            return row and self._convert_row(row) or None
+        def fetchmany(self, num):
+            rows = sqlite.Cursor.fetchmany(self, num)
+            return rows != None and [self._convert_row(row)
+                                     for row in rows] or None
+        def fetchall(self):
+            rows = sqlite.Cursor.fetchall(self)
+            return rows != None and [self._convert_row(row)
+                                     for row in rows] or None
+
+except ImportError:
+    try:
+        import sqlite
+        have_pysqlite = 1
+    except ImportError:
+        have_pysqlite = 0
+
+def _to_sql(table):
+    sql = ["CREATE TABLE %s (" % table.name]
+    coldefs = []
+    for column in table.columns:
+        ctype = column.type.lower()
+        if column.auto_increment:
+            ctype = "integer PRIMARY KEY"
+        elif len(table.key) == 1 and column.name in table.key:
+            ctype += " PRIMARY KEY"
+        elif ctype == "int":
+            ctype = "integer"
+        coldefs.append("    %s %s" % (column.name, ctype))
+    if len(table.key) > 1:
+        coldefs.append("    UNIQUE (%s)" % ','.join(table.key))
+    sql.append(',\n'.join(coldefs) + '\n);')
+    yield '\n'.join(sql)
+    for index in table.indices:
+        yield "CREATE INDEX %s_%s_idx ON %s (%s);" % (table.name,
+              '_'.join(index.columns), table.name, ','.join(index.columns))
+
+
+class SQLiteConnector(Component):
+    """SQLite database support."""
+    implements(IDatabaseConnector)
+
+    def get_supported_schemes(self):
+        return [('sqlite', 1)]
+
+    def get_connection(self, path, params={}):
+        return SQLiteConnection(path, params)
+
+    def init_db(cls, path, params={}):
+        if path != ':memory:':
+            # make the directory to hold the database
+            if os.path.exists(path):
+                raise TracError, 'Database already exists at %s' % path
+            os.makedirs(os.path.split(path)[0])
+        cnx = sqlite.connect(path, timeout=int(params.get('timeout', 10000)))
+        cursor = cnx.cursor()
+        from trac.db_default import schema
+        for table in schema:
+            for stmt in cls.to_sql(table):
+                cursor.execute(stmt)
+        cnx.commit()
+
+    def to_sql(cls, table):
+        return _to_sql(table)
+
+
+class SQLiteConnection(ConnectionWrapper):
+    """Connection wrapper for SQLite."""
+
+    __slots__ = ['_active_cursors']
+    poolable = False
+
+    def __init__(self, path, params={}):
+        assert have_pysqlite > 0
+        self.cnx = None
+        if path != ':memory:':
+            if not os.access(path, os.F_OK):
+                raise TracError, 'Database "%s" not found.' % path
+
+            dbdir = os.path.dirname(path)
+            if not os.access(path, os.R_OK + os.W_OK) or \
+                   not os.access(dbdir, os.R_OK + os.W_OK):
+                from getpass import getuser
+                raise TracError, 'The user %s requires read _and_ write ' \
+                                 'permission to the database file %s and the ' \
+                                 'directory it is located in.' \
+                                 % (getuser(), path)
+
+        if have_pysqlite == 2:
+            self._active_cursors = weakref.WeakKeyDictionary()
+            timeout = int(params.get('timeout', 10.0))
+            # Convert unicode to UTF-8 bytestrings. This is case-sensitive, so
+            # we need two converters
+            sqlite.register_converter('text', str)
+            sqlite.register_converter('TEXT', str)
+
+            cnx = sqlite.connect(path, detect_types=sqlite.PARSE_DECLTYPES,
+                                 timeout=timeout)
+        else:
+            timeout = int(params.get('timeout', 10000))
+            cnx = sqlite.connect(path, timeout=timeout)
+        ConnectionWrapper.__init__(self, cnx)
+
+    if have_pysqlite == 2:
+        def cursor(self):
+            cursor = self.cnx.cursor(PyFormatCursor)
+            self._active_cursors[cursor] = True
+            cursor.cnx = self
+            return cursor
+
+        def rollback(self):
+            for cursor in self._active_cursors.keys():
+                cursor.close()
+            self.cnx.rollback()
+
+    else:
+        def cursor(self):
+            return self.cnx.cursor()
+
+    def cast(self, column, type):
+        return column
+
+    def like(self):
+        return 'LIKE'
+
+    if have_pysqlite == 2:
+        def get_last_id(self, cursor, table, column='id'):
+            return cursor.lastrowid
+    else:
+        def get_last_id(self, cursor, table, column='id'):
+            return self.cnx.db.sqlite_last_insert_rowid()
diff -urN trac-trunk/build/lib/trac/db/util.py aw-trac/build/lib/trac/db/util.py
--- trac-trunk/build/lib/trac/db/util.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/db/util.py	2006-02-25 19:26:54.000000000 -0800
@@ -0,0 +1,73 @@
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2005-2006 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2006 Matthew Good <trac@matt-good.net>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+def sql_escape_percent(sql):
+    import re
+    return re.sub("'((?:[^']|(?:''))*)'", lambda m: m.group(0).replace('%', '%%'), sql)
+
+
+class IterableCursor(object):
+    """Wrapper for DB-API cursor objects that makes the cursor iterable
+    and escapes all "%"s used inside literal strings with parameterized
+    queries.
+    
+    Iteration will generate the rows of a SELECT query one by one.
+    """
+    __slots__ = ['cursor']
+
+    def __init__(self, cursor):
+        self.cursor = cursor
+
+    def __getattr__(self, name):
+        return getattr(self.cursor, name)
+
+    def __iter__(self):
+        while True:
+            row = self.cursor.fetchone()
+            if not row:
+                return
+            yield row
+
+    def execute(self, sql, args=None):
+        if args:
+            return self.cursor.execute(sql_escape_percent(sql), args)
+        return self.cursor.execute(sql)
+
+    def executemany(self, sql, args=None):
+        if args:
+            return self.cursor.executemany(sql_escape_percent(sql), args)
+        return self.cursor.executemany(sql)
+
+
+class ConnectionWrapper(object):
+    """Generic wrapper around connection objects.
+    
+    This wrapper makes cursors produced by the connection iterable using
+    `IterableCursor`.
+    """
+    __slots__ = ['cnx']
+
+    def __init__(self, cnx):
+        self.cnx = cnx
+
+    def __getattr__(self, name):
+        if hasattr(self, 'cnx'):
+            return getattr(self.cnx, name)
+        return object.__getattr__(self, name)
+
+    def cursor(self):
+        return IterableCursor(self.cnx.cursor())
diff -urN trac-trunk/build/lib/trac/db_default.py aw-trac/build/lib/trac/db_default.py
--- trac-trunk/build/lib/trac/db_default.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/db_default.py	2006-03-08 01:28:30.000000000 -0800
@@ -0,0 +1,458 @@
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Daniel Lundin <daniel@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+
+from trac.config import default_dir
+from trac.db import Table, Column, Index
+
+# Database version identifier. Used for automatic upgrades.
+db_version = 17
+
+def __mkreports(reports):
+    """Utility function used to create report data in same syntax as the
+    default data. This extra step is done to simplify editing the default
+    reports."""
+    result = []
+    for report in reports:
+        result.append((None, report[0], report[2], report[1]))
+    return result
+
+
+##
+## Database schema
+##
+
+schema = [
+    # Common
+    Table('system', key='name')[
+        Column('name'),
+        Column('value')],
+    Table('permission', key=('username', 'action'))[
+        Column('username'),
+        Column('action')],
+    Table('auth_cookie', key=('cookie', 'ipnr', 'name'))[
+        Column('cookie'),
+        Column('name'),
+        Column('ipnr'),
+        Column('time', type='int')],
+    Table('session', key=('sid', 'authenticated', 'var_name'))[
+        Column('sid'),
+        Column('authenticated', type='int'),
+        Column('var_name'),
+        Column('var_value')],
+
+    # Attachments
+    Table('attachment', key=('type', 'id', 'filename'))[
+        Column('type'),
+        Column('id'),
+        Column('filename'),
+        Column('size', type='int'),
+        Column('time', type='int'),
+        Column('description'),
+        Column('author'),
+        Column('ipnr')],
+
+    # Wiki system
+    Table('wiki', key=('name', 'version'))[
+        Column('name'),
+        Column('version', type='int'),
+        Column('time', type='int'),
+        Column('author'),
+        Column('ipnr'),
+        Column('text'),
+        Column('comment'),
+        Column('readonly', type='int'),
+        Index(['time'])],
+
+    # Version control cache
+    Table('revision', key='rev')[
+        Column('rev'),
+        Column('time', type='int'),
+        Column('author'),
+        Column('message'),
+        Index(['time'])],
+    Table('node_change', key=('rev', 'path', 'change_type'))[
+        Column('rev'),
+        Column('path'),
+        Column('node_type', size=1),
+        Column('change_type', size=1),
+        Column('base_path'),
+        Column('base_rev'),
+        Index(['rev'])],
+
+    # Ticket system
+    Table('ticket', key='id')[
+        Column('id', auto_increment=True),
+        Column('type'),
+        Column('time', type='int'),
+        Column('changetime', type='int'),
+        Column('component'),
+        Column('severity'),
+        Column('priority'),
+        Column('owner'),
+        Column('reporter'),
+        Column('cc'),
+        Column('version'),
+        Column('milestone'),
+        Column('status'),
+        Column('resolution'),
+        Column('summary'),
+        Column('description'),
+        Column('keywords'),
+        Index(['time']),
+        Index(['status'])],    
+    Table('ticket_change', key=('ticket', 'time', 'field'))[
+        Column('ticket', type='int'),
+        Column('time', type='int'),
+        Column('author'),
+        Column('field'),
+        Column('oldvalue'),
+        Column('newvalue'),
+        Index(['ticket', 'time'])],
+    Table('ticket_custom', key=('ticket', 'name'))[
+        Column('ticket', type='int'),
+        Column('name'),
+        Column('value')],
+    Table('enum', key=('type', 'name'))[
+        Column('type'),
+        Column('name'),
+        Column('value')],
+    Table('component', key='name')[
+        Column('name'),
+        Column('owner'),
+        Column('description')],
+    Table('milestone', key='name')[
+        Column('name'),
+        Column('due', type='int'),
+        Column('completed', type='int'),
+        Column('description')],
+    Table('version', key='name')[
+        Column('name'),
+        Column('time', type='int'),
+        Column('description')],
+
+    # Report system
+    Table('report', key='id')[
+        Column('id', auto_increment=True),
+        Column('author'),
+        Column('title'),
+        Column('sql'),
+        Column('description')],
+]
+
+
+##
+## Default Reports
+##
+
+reports = (
+('Active Tickets',
+"""
+ * List all active tickets by priority.
+ * Color each row based on priority.
+ * If a ticket has been accepted, a '*' is appended after the owner's name
+""",
+"""
+SELECT p.value AS __color__,
+   id AS ticket, summary, component, version, milestone, t.type AS type, 
+   (CASE status WHEN 'assigned' THEN owner||' *' ELSE owner END) AS owner,
+   time AS created,
+   changetime AS _changetime, description AS _description,
+   reporter AS _reporter
+  FROM ticket t, enum p
+  WHERE status IN ('new', 'assigned', 'reopened') 
+AND p.name = t.priority AND p.type = 'priority'
+  ORDER BY p.value, milestone, t.type, time
+"""),
+#----------------------------------------------------------------------------
+ ('Active Tickets by Version',
+"""
+This report shows how to color results by priority,
+while grouping results by version.
+
+Last modification time, description and reporter are included as hidden fields
+for useful RSS export.
+""",
+"""
+SELECT p.value AS __color__,
+   version AS __group__,
+   id AS ticket, summary, component, version, t.type AS type, 
+   (CASE status WHEN 'assigned' THEN owner||' *' ELSE owner END) AS owner,
+   time AS created,
+   changetime AS _changetime, description AS _description,
+   reporter AS _reporter
+  FROM ticket t, enum p
+  WHERE status IN ('new', 'assigned', 'reopened') 
+AND p.name = t.priority AND p.type = 'priority'
+  ORDER BY (version IS NULL),version, p.value, t.type, time
+"""),
+#----------------------------------------------------------------------------
+('All Tickets by Milestone',
+"""
+This report shows how to color results by priority,
+while grouping results by milestone.
+
+Last modification time, description and reporter are included as hidden fields
+for useful RSS export.
+""",
+"""
+SELECT p.value AS __color__,
+   milestone||' Release' AS __group__,
+   id AS ticket, summary, component, version, t.type AS type, 
+   (CASE status WHEN 'assigned' THEN owner||' *' ELSE owner END) AS owner,
+   time AS created,
+   changetime AS _changetime, description AS _description,
+   reporter AS _reporter
+  FROM ticket t, enum p
+  WHERE status IN ('new', 'assigned', 'reopened') 
+AND p.name = t.priority AND p.type = 'priority'
+  ORDER BY (milestone IS NULL),milestone, p.value, t.type, time
+"""),
+#----------------------------------------------------------------------------
+('Assigned, Active Tickets by Owner',
+"""
+List assigned tickets, group by ticket owner, sorted by priority.
+""",
+"""
+
+SELECT p.value AS __color__,
+   owner AS __group__,
+   id AS ticket, summary, component, milestone, t.type AS type, time AS created,
+   changetime AS _changetime, description AS _description,
+   reporter AS _reporter
+  FROM ticket t,enum p
+  WHERE status = 'assigned'
+AND p.name=t.priority AND p.type='priority'
+  ORDER BY owner, p.value, t.type, time
+"""),
+#----------------------------------------------------------------------------
+('Assigned, Active Tickets by Owner (Full Description)',
+"""
+List tickets assigned, group by ticket owner.
+This report demonstrates the use of full-row display.
+""",
+"""
+SELECT p.value AS __color__,
+   owner AS __group__,
+   id AS ticket, summary, component, milestone, t.type AS type, time AS created,
+   description AS _description_,
+   changetime AS _changetime, reporter AS _reporter
+  FROM ticket t, enum p
+  WHERE status = 'assigned'
+AND p.name = t.priority AND p.type = 'priority'
+  ORDER BY owner, p.value, t.type, time
+"""),
+#----------------------------------------------------------------------------
+('All Tickets By Milestone  (Including closed)',
+"""
+A more complex example to show how to make advanced reports.
+""",
+"""
+SELECT p.value AS __color__,
+   t.milestone AS __group__,
+   (CASE status 
+      WHEN 'closed' THEN 'color: #777; background: #ddd; border-color: #ccc;'
+      ELSE 
+        (CASE owner WHEN '$USER' THEN 'font-weight: bold' END)
+    END) AS __style__,
+   id AS ticket, summary, component, status, 
+   resolution,version, t.type AS type, priority, owner,
+   changetime AS modified,
+   time AS _time,reporter AS _reporter
+  FROM ticket t,enum p
+  WHERE p.name=t.priority AND p.type='priority'
+  ORDER BY (milestone IS NULL), milestone DESC, (status = 'closed'), 
+        (CASE status WHEN 'closed' THEN modified ELSE (-1)*p.value END) DESC
+"""),
+#----------------------------------------------------------------------------
+('My Tickets',
+"""
+This report demonstrates the use of the automatically set 
+$USER dynamic variable, replaced with the username of the
+logged in user when executed.
+""",
+"""
+SELECT p.value AS __color__,
+   (CASE status WHEN 'assigned' THEN 'Assigned' ELSE 'Owned' END) AS __group__,
+   id AS ticket, summary, component, version, milestone,
+   t.type AS type, priority, time AS created,
+   changetime AS _changetime, description AS _description,
+   reporter AS _reporter
+  FROM ticket t, enum p
+  WHERE t.status IN ('new', 'assigned', 'reopened') 
+AND p.name = t.priority AND p.type = 'priority' AND owner = '$USER'
+  ORDER BY (status = 'assigned') DESC, p.value, milestone, t.type, time
+"""),
+#----------------------------------------------------------------------------
+('Active Tickets, Mine first',
+"""
+ * List all active tickets by priority.
+ * Show all tickets owned by the logged in user in a group first.
+""",
+"""
+SELECT p.value AS __color__,
+   (CASE owner 
+     WHEN '$USER' THEN 'My Tickets' 
+     ELSE 'Active Tickets' 
+    END) AS __group__,
+   id AS ticket, summary, component, version, milestone, t.type AS type, 
+   (CASE status WHEN 'assigned' THEN owner||' *' ELSE owner END) AS owner,
+   time AS created,
+   changetime AS _changetime, description AS _description,
+   reporter AS _reporter
+  FROM ticket t, enum p
+  WHERE status IN ('new', 'assigned', 'reopened') 
+AND p.name = t.priority AND p.type = 'priority'
+  ORDER BY (owner = '$USER') DESC, p.value, milestone, t.type, time
+"""))
+
+
+##
+## Default database values
+##
+
+# (table, (column1, column2), ((row1col1, row1col2), (row2col1, row2col2)))
+data = (('component',
+             ('name', 'owner'),
+               (('component1', 'somebody'),
+                ('component2', 'somebody'))),
+           ('milestone',
+             ('name', 'due', 'completed'),
+               (('milestone1', 0, 0),
+                ('milestone2', 0, 0),
+                ('milestone3', 0, 0),
+                ('milestone4', 0, 0))),
+           ('version',
+             ('name', 'time'),
+               (('1.0', 0),
+                ('2.0', 0))),
+           ('enum',
+             ('type', 'name', 'value'),
+               (('status', 'new', 1),
+                ('status', 'assigned', 2),
+                ('status', 'reopened', 3),
+                ('status', 'closed', 4),
+                ('resolution', 'fixed', 1),
+                ('resolution', 'invalid', 2),
+                ('resolution', 'wontfix', 3),
+                ('resolution', 'duplicate', 4),
+                ('resolution', 'worksforme', 5),
+                ('priority', 'blocker', 1),
+                ('priority', 'critical', 2),
+                ('priority', 'major', 3),
+                ('priority', 'minor', 4),
+                ('priority', 'trivial', 5),
+                ('ticket_type', 'defect', 1),
+                ('ticket_type', 'enhancement', 2),
+                ('ticket_type', 'task', 3))),
+           ('permission',
+             ('username', 'action'),
+               (('anonymous', 'LOG_VIEW'),
+                ('anonymous', 'FILE_VIEW'),
+                ('anonymous', 'WIKI_VIEW'),
+                ('anonymous', 'WIKI_CREATE'),
+                ('anonymous', 'WIKI_MODIFY'),
+                ('anonymous', 'SEARCH_VIEW'),
+                ('anonymous', 'REPORT_VIEW'),
+                ('anonymous', 'REPORT_SQL_VIEW'),
+                ('anonymous', 'TICKET_VIEW'),
+                ('anonymous', 'TICKET_CREATE'),
+                ('anonymous', 'TICKET_MODIFY'),
+                ('anonymous', 'BROWSER_VIEW'),
+                ('anonymous', 'TIMELINE_VIEW'),
+                ('anonymous', 'CHANGESET_VIEW'),
+                ('anonymous', 'ROADMAP_VIEW'),
+                ('anonymous', 'MILESTONE_VIEW'))),
+           ('system',
+             ('name', 'value'),
+               (('database_version', str(db_version)),)),
+           ('report',
+             ('author', 'title', 'sql', 'description'),
+               __mkreports(reports)))
+
+default_config = \
+ (('trac', 'repository_type', 'svn'),
+  ('trac', 'repository_dir', ''),
+  ('trac', 'templates_dir', default_dir('templates')),
+  ('trac', 'database', 'sqlite:db/trac.db'),
+  ('trac', 'default_charset', 'iso-8859-15'),
+  ('trac', 'default_handler', 'WikiModule'),
+  ('trac', 'check_auth_ip', 'true'),
+  ('trac', 'ignore_auth_case', 'false'),
+  ('trac', 'metanav', 'login,logout,settings,help,about'),
+  ('trac', 'mainnav', 'wiki,timeline,roadmap,browser,tickets,newticket,search'),
+  ('trac', 'permission_store', 'DefaultPermissionStore'),
+  ('logging', 'log_type', 'none'),
+  ('logging', 'log_file', 'trac.log'),
+  ('logging', 'log_level', 'DEBUG'),
+  ('project', 'name', 'My Project'),
+  ('project', 'descr', 'My example project'),
+  ('project', 'url', 'http://example.com/'),
+  ('project', 'icon', 'common/trac.ico'),
+  ('project', 'footer',
+   ' Visit the Trac open source project at<br />'
+   '<a href="http://trac.edgewall.com/">http://trac.edgewall.com/</a>'),
+  ('ticket', 'default_version', ''),
+  ('ticket', 'default_type', 'defect'),
+  ('ticket', 'default_priority', 'major'),
+  ('ticket', 'default_milestone', ''),
+  ('ticket', 'default_component', 'component1'),
+  ('ticket', 'restrict_owner', 'false'),
+  ('header_logo', 'link', 'http://trac.edgewall.com/'),
+  ('header_logo', 'src', 'common/trac_banner.png'),
+  ('header_logo', 'alt', 'Trac'),
+  ('header_logo', 'width', '236'),
+  ('header_logo', 'height', '73'),
+  ('attachment', 'max_size', '262144'),
+  ('attachment', 'render_unsafe_content', 'false'),
+  ('mimeviewer', 'enscript_path', 'enscript'),
+  ('mimeviewer', 'php_path', 'php'),
+  ('mimeviewer', 'tab_width', '8'),
+  ('mimeviewer', 'max_preview_size', '262144'),
+  ('notification', 'smtp_enabled', 'false'),
+  ('notification', 'smtp_server', 'localhost'),
+  ('notification', 'smtp_port', '25'),
+  ('notification', 'smtp_user', ''),
+  ('notification', 'smtp_password', ''),
+  ('notification', 'smtp_always_cc', ''),
+  ('notification', 'always_notify_owner', 'false'),
+  ('notification', 'always_notify_reporter', 'false'),
+  ('notification', 'smtp_from', 'trac@localhost'),
+  ('notification', 'smtp_replyto', 'trac@localhost'),
+  ('notification', 'mime_encoding', 'base64'),
+  ('notification', 'allow_public_cc', 'false'),
+  ('notification', 'maxheaderlen', '78'),
+  ('timeline', 'default_daysback', '30'),
+  ('timeline', 'changeset_show_files', '0'),
+  ('timeline', 'ticket_show_details', 'false'),
+  ('changeset', 'max_diff_files', '1000'),
+  ('changeset', 'max_diff_bytes', '10000000'),
+  ('browser', 'hide_properties', 'svk:merge'),
+  ('wiki', 'ignore_missing_pages', 'false'),
+)
+
+default_components = ('trac.About', 'trac.attachment',
+                      'trac.db.postgres_backend', 'trac.db.sqlite_backend',
+                      'trac.mimeview.enscript', 'trac.mimeview.patch',
+                      'trac.mimeview.php', 'trac.mimeview.rst',
+                      'trac.mimeview.silvercity', 'trac.mimeview.txtl',
+                      'trac.Search', 'trac.Settings',
+                      'trac.ticket.query', 'trac.ticket.report',
+                      'trac.ticket.roadmap', 'trac.ticket.web_ui',
+                      'trac.Timeline',
+                      'trac.versioncontrol.web_ui',
+                      'trac.versioncontrol.svn_fs',
+                      'trac.wiki.macros', 'trac.wiki.web_ui',
+                      'trac.web.auth')
diff -urN trac-trunk/build/lib/trac/env.py aw-trac/build/lib/trac/env.py
--- trac-trunk/build/lib/trac/env.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/env.py	2006-02-08 05:43:17.000000000 -0800
@@ -0,0 +1,373 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+import os
+
+from trac import db_default, util
+from trac.config import Configuration
+from trac.core import Component, ComponentManager, implements, Interface, \
+                      ExtensionPoint, TracError
+from trac.db import DatabaseManager
+from trac.versioncontrol import RepositoryManager
+
+__all__ = ['Environment', 'IEnvironmentSetupParticipant', 'open_environment']
+
+
+class IEnvironmentSetupParticipant(Interface):
+    """Extension point interface for components that need to participate in the
+    creation and upgrading of Trac environments, for example to create
+    additional database tables."""
+
+    def environment_created():
+        """Called when a new Trac environment is created."""
+
+    def environment_needs_upgrade(db):
+        """Called when Trac checks whether the environment needs to be upgraded.
+        
+        Should return `True` if this participant needs an upgrade to be
+        performed, `False` otherwise.
+        """
+
+    def upgrade_environment(db):
+        """Actually perform an environment upgrade.
+        
+        Implementations of this method should not commit any database
+        transactions. This is done implicitly after all participants have
+        performed the upgrades they need without an error being raised.
+        """
+
+
+class Environment(Component, ComponentManager):
+    """Trac stores project information in a Trac environment.
+
+    A Trac environment consists of a directory structure containing among other
+    things:
+     * a configuration file.
+     * an SQLite database (stores tickets, wiki pages...)
+     * Project specific templates and wiki macros.
+     * wiki and ticket attachments.
+    """   
+    setup_participants = ExtensionPoint(IEnvironmentSetupParticipant)
+
+    def __init__(self, path, create=False, options=[]):
+        """Initialize the Trac environment.
+        
+        @param path:   the absolute path to the Trac environment
+        @param create: if `True`, the environment is created and populated with
+                       default data; otherwise, the environment is expected to
+                       already exist.
+        @param options: A list of `(section, name, value)` tuples that define
+                        configuration options
+        """
+        ComponentManager.__init__(self)
+
+        self.path = path
+        self.load_config()
+        self.setup_log() 
+
+        from trac.loader import load_components
+        load_components(self)
+
+        if create:
+            self.create(options)
+        else:
+            self.verify()
+
+        if create:
+            for setup_participant in self.setup_participants:
+                setup_participant.environment_created()
+
+    def component_activated(self, component):
+        """Initialize additional member variables for components.
+        
+        Every component activated through the `Environment` object gets three
+        member variables: `env` (the environment object), `config` (the
+        environment configuration) and `log` (a logger object)."""
+        component.env = self
+        component.config = self.config
+        component.log = self.log
+
+    def is_component_enabled(self, cls):
+        """Implemented to only allow activation of components that are not
+        disabled in the configuration.
+        
+        This is called by the `ComponentManager` base class when a component is
+        about to be activated. If this method returns false, the component does
+        not get activated."""
+        if not isinstance(cls, (str, unicode)):
+            component_name = (cls.__module__ + '.' + cls.__name__).lower()
+        else:
+            component_name = cls.lower()
+
+        rules = [(name.lower(), value.lower() in ('enabled', 'on'))
+                 for name, value in self.config.options('components')]
+        rules.sort(lambda a, b: -cmp(len(a[0]), len(b[0])))
+
+        for pattern, enabled in rules:
+            if component_name == pattern or pattern.endswith('*') \
+                    and component_name.startswith(pattern[:-1]):
+                return enabled
+
+        # versioncontrol components are enabled if the repository is configured
+        if component_name.startswith('trac.versioncontrol.'):
+            return self.config.get('trac', 'repository_dir') != ''
+
+        # By default, all components in the trac package are enabled
+        return component_name.startswith('trac.')
+
+    def verify(self):
+        """Verify that the provided path points to a valid Trac environment
+        directory."""
+        fd = open(os.path.join(self.path, 'VERSION'), 'r')
+        assert fd.read(26) == 'Trac Environment Version 1'
+        fd.close()
+
+    def get_db_cnx(self):
+        """Return a database connection from the connection pool."""
+        return DatabaseManager(self).get_connection()
+
+    def shutdown(self):
+        """Close the environment."""
+        DatabaseManager(self).shutdown()
+
+    def get_repository(self, authname=None):
+        """Return the version control repository configured for this
+        environment.
+        
+        @param authname: user name for authorization
+        """
+        repos_type = self.config.get('trac', 'repository_type')
+        repos_dir = self.config.get('trac', 'repository_dir')
+        if not repos_dir:
+            raise TracError, 'Path to repository not configured'
+        return RepositoryManager(self).get_repository(repos_type, repos_dir,
+                                                      authname)
+
+    def create(self, options=[]):
+        """Create the basic directory structure of the environment, initialize
+        the database and populate the configuration file with default values."""
+        def _create_file(fname, data=None):
+            fd = open(fname, 'w')
+            if data: fd.write(data)
+            fd.close()
+
+        # Create the directory structure
+        os.mkdir(self.path)
+        os.mkdir(self.get_log_dir())
+        os.mkdir(self.get_htdocs_dir())
+        os.mkdir(os.path.join(self.path, 'plugins'))
+        os.mkdir(os.path.join(self.path, 'wiki-macros'))
+
+        # Create a few files
+        _create_file(os.path.join(self.path, 'VERSION'),
+                     'Trac Environment Version 1\n')
+        _create_file(os.path.join(self.path, 'README'),
+                     'This directory contains a Trac environment.\n'
+                     'Visit http://trac.edgewall.com/ for more information.\n')
+
+        # Setup the default configuration
+        os.mkdir(os.path.join(self.path, 'conf'))
+        _create_file(os.path.join(self.path, 'conf', 'trac.ini'))
+        self.load_config()
+        for section, name, value in db_default.default_config:
+            self.config.set(section, name, value)
+        for section, name, value in options:
+            self.config.set(section, name, value)
+        self.config.save()
+
+        # Create the database
+        DatabaseManager(self).init_db()
+
+    def get_version(self, db=None):
+        """Return the current version of the database."""
+        if not db:
+            db = self.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT value FROM system WHERE name='database_version'")
+        row = cursor.fetchone()
+        return row and int(row[0])
+
+    def load_config(self):
+        """Load the configuration file."""
+        self.config = Configuration(os.path.join(self.path, 'conf', 'trac.ini'))
+        for section, name, value in db_default.default_config:
+            self.config.setdefault(section, name, value)
+
+    def get_templates_dir(self):
+        """Return absolute path to the templates directory."""
+        return os.path.join(self.path, 'templates')
+
+    def get_htdocs_dir(self):
+        """Return absolute path to the htdocs directory."""
+        return os.path.join(self.path, 'htdocs')
+
+    def get_log_dir(self):
+        """Return absolute path to the log directory."""
+        return os.path.join(self.path, 'log')
+
+    def setup_log(self):
+        """Initialize the logging sub-system."""
+        from trac.log import logger_factory
+        logtype = self.config.get('logging', 'log_type')
+        loglevel = self.config.get('logging', 'log_level')
+        logfile = self.config.get('logging', 'log_file')
+        if not os.path.isabs(logfile):
+            logfile = os.path.join(self.get_log_dir(), logfile)
+        logid = self.path # Env-path provides process-unique ID
+        self.log = logger_factory(logtype, logfile, loglevel, logid)
+
+    def get_known_users(self, cnx=None):
+        """Generator that yields information about all known users, i.e. users
+        that have logged in to this Trac environment and possibly set their name
+        and email.
+
+        This function generates one tuple for every user, of the form
+        (username, name, email) ordered alpha-numerically by username.
+
+        @param cnx: the database connection; if ommitted, a new connection is
+                    retrieved
+        """
+        if not cnx:
+            cnx = self.get_db_cnx()
+        cursor = cnx.cursor()
+        cursor.execute("SELECT DISTINCT s.sid, n.var_value, e.var_value "
+                       "FROM session AS s "
+                       " LEFT JOIN session AS n ON (n.sid=s.sid "
+                       "  AND n.authenticated=1 AND n.var_name = 'name') "
+                       " LEFT JOIN session AS e ON (e.sid=s.sid "
+                       "  AND e.authenticated=1 AND e.var_name = 'email') "
+                       "WHERE s.authenticated=1 ORDER BY s.sid")
+        for username,name,email in cursor:
+            yield username, name, email
+
+    def backup(self, dest=None):
+        """Simple SQLite-specific backup of the database.
+
+        @param dest: Destination file; if not specified, the backup is stored in
+                     a file called db_name.trac_version.bak
+        """
+        import shutil
+
+        db_str = self.config.get('trac', 'database')
+        if not db_str.startswith('sqlite:'):
+            raise EnvironmentError, 'Can only backup sqlite databases'
+        db_name = os.path.join(self.path, db_str[7:])
+        if not dest:
+            dest = '%s.%i.bak' % (db_name, self.get_version())
+        shutil.copy (db_name, dest)
+
+    def needs_upgrade(self):
+        """Return whether the environment needs to be upgraded."""
+        db = self.get_db_cnx()
+        for participant in self.setup_participants:
+            if participant.environment_needs_upgrade(db):
+                self.log.warning('Component %s requires environment upgrade',
+                                 participant)
+                return True
+        return False
+
+    def upgrade(self, backup=False, backup_dest=None):
+        """Upgrade database.
+        
+        Each db version should have its own upgrade module, names
+        upgrades/dbN.py, where 'N' is the version number (int).
+
+        @param backup: whether or not to backup before upgrading
+        @param backup_dest: name of the backup file
+        @return: whether the upgrade was performed
+        """
+        db = self.get_db_cnx()
+
+        upgraders = []
+        for participant in self.setup_participants:
+            if participant.environment_needs_upgrade(db):
+                upgraders.append(participant)
+        if not upgraders:
+            return False
+
+        if backup:
+            self.backup(backup_dest)
+        for participant in upgraders:
+            participant.upgrade_environment(db)
+        db.commit()
+
+        # Database schema may have changed, so close all connections
+        self.shutdown()
+
+        return True
+
+
+class EnvironmentSetup(Component):
+    implements(IEnvironmentSetupParticipant)
+
+    # IEnvironmentSetupParticipant methods
+
+    def environment_created(self):
+        """Insert default data into the database."""
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        for table, cols, vals in db_default.data:
+            cursor.executemany("INSERT INTO %s (%s) VALUES (%s)" % (table,
+                               ','.join(cols), ','.join(['%s' for c in cols])),
+                               vals)
+        db.commit()
+
+    def environment_needs_upgrade(self, db):
+        dbver = self.env.get_version(db)
+        if dbver == db_default.db_version:
+            return False
+        elif dbver > db_default.db_version:
+            raise TracError, 'Database newer than Trac version'
+        return True
+
+    def upgrade_environment(self, db):
+        cursor = db.cursor()
+        dbver = self.env.get_version()
+        for i in range(dbver + 1, db_default.db_version + 1):
+            name  = 'db%i' % i
+            try:
+                upgrades = __import__('upgrades', globals(), locals(), [name])
+                script = getattr(upgrades, name)
+            except AttributeError:
+                err = 'No upgrade module for version %i (%s.py)' % (i, name)
+                raise TracError, err
+            script.do_upgrade(self.env, i, cursor)
+        cursor.execute("UPDATE system SET value=%s WHERE "
+                       "name='database_version'", (db_default.db_version,))
+        self.log.info('Upgraded database version from %d to %d',
+                      dbver, db_default.db_version)
+
+
+def open_environment(env_path=None):
+    """Open an existing environment object, and verify that the database is up
+    to date.
+
+    @param: env_path absolute path to the environment directory; if ommitted,
+            the value of the `TRAC_ENV` environment variable is used
+    @return: the `Environment` object
+    """
+    if not env_path:
+        env_path = os.getenv('TRAC_ENV')
+    if not env_path:
+        raise TracError, 'Missing environment variable "TRAC_ENV". Trac ' \
+                         'requires this variable to point to a valid Trac ' \
+                         'environment.'
+
+    env = Environment(env_path)
+    if env.needs_upgrade():
+        raise TracError, 'The Trac Environment needs to be upgraded. Run ' \
+                         'trac-admin %s upgrade"' % env_path
+    return env
diff -urN trac-trunk/build/lib/trac/loader.py aw-trac/build/lib/trac/loader.py
--- trac-trunk/build/lib/trac/loader.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/loader.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,120 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+import os
+import sys
+
+try:
+    import pkg_resources
+except ImportError:
+    pkg_resources = None
+
+TRAC_META = 'trac_plugin.txt'
+
+__all__ = ['load_components']
+
+def normalize_path(s):
+  return os.path.normcase(os.path.abspath(s))
+
+def paths_equal(path1, path2):
+  return normalize_path(path1) == normalize_path(path2)
+
+def load_components(env):
+
+    loaded_components = []
+
+    def load_module(name):
+         if name not in loaded_components:
+             try:
+                 module = __import__(name)
+                 loaded_components.append(name)
+                 return module
+             except ImportError, e:
+                 env.log.error('Component module %s not found',
+                               name, exc_info=True)
+
+    plugins_dir = os.path.join(env.path, 'plugins')
+
+    def enable_modules(egg_path, modules):
+        """Automatically enable any components provided by plugins loaded from
+        the environment plugins directory."""
+        if paths_equal(os.path.dirname(egg_path), os.path.realpath(plugins_dir)):
+            for module in modules:
+                env.config.setdefault('components', module + '.*', 'enabled')
+
+    # Load components from the environment plugins directory
+    if pkg_resources is not None: # But only if setuptools is installed!
+        if hasattr(pkg_resources, 'Environment'):
+            # setuptools >= 0.6
+            pkg_env = pkg_resources.Environment([plugins_dir] + sys.path)
+            for name in pkg_env:
+                egg = pkg_env[name][0]
+                modules = []
+
+                for name in egg.get_entry_map('trac.plugins'):
+                    # Load plugins declared via the `trac.plugins` entry point.
+                    # This is the only supported option going forward, the
+                    # others will be dropped at some point in the future.
+                    env.log.debug('Loading plugin %s from %s', name,
+                                  egg.location)
+                    egg.activate()
+                    try:
+                        entry_point = egg.get_entry_info('trac.plugins', name)
+                        if entry_point.module_name not in loaded_components:
+                            entry_point.load()
+                            modules.append(entry_point.module_name)
+                            loaded_components.append(entry_point.module_name)
+                    except ImportError, e:
+                        env.log.error('Failed to load plugin %s from %s', name,
+                                      egg.location, exc_info=True)
+
+                else:
+                    # Support for pre-entry-point plugins
+                    if egg.has_metadata('trac_plugin.txt'):
+                        env.log.debug('Loading plugin %s from %s', name,
+                                      egg.location)
+                        egg.activate()
+                        for module in egg.get_metadata_lines('trac_plugin.txt'):
+                            if load_module(module):
+                                modules.append(module)
+
+                if modules:
+                    enable_modules(egg.location, modules)
+
+        else:
+            # setuptools < 0.6
+            distributions = pkg_resources.AvailableDistributions([plugins_dir] \
+                                                                 + sys.path)
+            for name in distributions:
+                egg = distributions[name][0]
+                modules = []
+                if egg.metadata.has_metadata(TRAC_META):
+                    egg.install_on()
+                    for module in egg.metadata.get_metadata_lines(TRAC_META):
+                        if load_module(module):
+                            modules.append(module)
+
+                if modules:
+                    enable_modules(egg.path, modules)
+
+    elif os.path.exists(plugins_dir) and os.listdir(plugins_dir):
+        env.log.warning('setuptools is required for plugin deployment')
+
+    # Load default components
+    from trac.db_default import default_components
+    for module in default_components:
+        if not module in loaded_components:
+            __import__(module)
diff -urN trac-trunk/build/lib/trac/log.py aw-trac/build/lib/trac/log.py
--- trac-trunk/build/lib/trac/log.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/log.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,58 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Daniel Lundin <daniel@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+
+import logging
+import logging.handlers
+import sys
+
+def logger_factory(logtype='syslog', logfile=None, level='WARNING',
+                   logid='Trac'):
+    logger = logging.getLogger(logid)
+    logtype = logtype.lower()
+    if logtype == 'file':
+        hdlr = logging.FileHandler(logfile)
+    elif logtype in ['winlog', 'eventlog', 'nteventlog']:
+        # Requires win32 extensions
+        hdlr = logging.handlers.NTEventLogHandler(logid,
+                                                  logtype='Application')
+    elif logtype in ['syslog', 'unix']:
+        hdlr = logging.handlers.SysLogHandler('/dev/log')
+    elif logtype in ['stderr']:
+        hdlr = logging.StreamHandler(sys.stderr)
+    else:
+        hdlr = logging.handlers.MemoryHandler(1024)
+
+    format = 'Trac[%(module)s] %(levelname)s: %(message)s'
+    if logtype == 'file':
+        format = '%(asctime)s ' + format 
+    datefmt = ''
+    level = level.upper()
+    if level in ['DEBUG', 'ALL']:
+        logger.setLevel(logging.DEBUG)
+        datefmt = '%X'
+    elif level == 'INFO':
+        logger.setLevel(logging.INFO)
+    elif level == 'ERROR':
+        logger.setLevel(logging.ERROR)
+    elif level == 'CRITICAL':
+        logger.setLevel(logging.CRITICAL)
+    else:
+        logger.setLevel(logging.WARNING)
+    formatter = logging.Formatter(format,datefmt)
+    hdlr.setFormatter(formatter)
+    logger.addHandler(hdlr) 
+
+    return logger
diff -urN trac-trunk/build/lib/trac/mimeview/__init__.py aw-trac/build/lib/trac/mimeview/__init__.py
--- trac-trunk/build/lib/trac/mimeview/__init__.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/mimeview/__init__.py	2005-05-06 02:27:54.000000000 -0700
@@ -0,0 +1 @@
+from trac.mimeview.api import *
diff -urN trac-trunk/build/lib/trac/mimeview/api.py aw-trac/build/lib/trac/mimeview/api.py
--- trac-trunk/build/lib/trac/mimeview/api.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/mimeview/api.py	2006-02-10 02:09:59.000000000 -0800
@@ -0,0 +1,435 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2005 Edgewall Software
+# Copyright (C) 2004 Daniel Lundin <daniel@edgewall.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+#
+
+import re
+try:
+    from cStringIO import StringIO
+except ImportError:
+    from StringIO import StringIO
+
+from trac.core import *
+from trac.util import escape, to_utf8, Markup
+
+
+__all__ = ['get_mimetype', 'is_binary', 'detect_unicode', 'Mimeview']
+
+MIME_MAP = {
+    'css':'text/css',
+    'html':'text/html',
+    'txt':'text/plain', 'TXT':'text/plain', 'text':'text/plain',
+    'README':'text/plain', 'INSTALL':'text/plain', 
+    'AUTHORS':'text/plain', 'COPYING':'text/plain', 
+    'ChangeLog':'text/plain', 'RELEASE':'text/plain', 
+    'ada':'text/x-ada',
+    'asm':'text/x-asm',
+    'asp':'text/x-asp',
+    'awk':'text/x-awk',
+    'c':'text/x-csrc',
+    'csh':'application/x-csh',
+    'diff':'text/x-diff', 'patch':'text/x-diff',
+    'e':'text/x-eiffel',
+    'el':'text/x-elisp',
+    'f':'text/x-fortran',
+    'h':'text/x-chdr',
+    'cc':'text/x-c++src', 'CC':'text/x-c++src',
+    'cpp':'text/x-c++src', 'C':'text/x-c++src',
+    'hh':'text/x-c++hdr', 'HH':'text/x-c++hdr',
+    'hpp':'text/x-c++hdr', 'H':'text/x-c++hdr',
+    'hs':'text/x-haskell',
+    'ico':'image/x-icon',
+    'idl':'text/x-idl',
+    'inf':'text/x-inf',
+    'java':'text/x-java',
+    'js':'text/x-javascript',
+    'ksh':'text/x-ksh',
+    'lua':'text/x-lua',
+    'm':'text/x-objc', 'mm':'text/x-objc',
+    'm4':'text/x-m4',
+    'make':'text/x-makefile', 'mk':'text/x-makefile',
+    'Makefile':'text/x-makefile',
+    'makefile':'text/x-makefile', 'GNUMakefile':'text/x-makefile',
+    'mail':'text/x-mail',
+    'pas':'text/x-pascal',
+    'pdf':'application/pdf',
+    'pl':'text/x-perl', 'pm':'text/x-perl', 'PL':'text/x-perl',
+    'perl':'text/x-perl',
+    'php':'text/x-php', 'php4':'text/x-php', 'php3':'text/x-php',
+    'ps':'application/postscript',
+    'psp':'text/x-psp',
+    'py':'text/x-python', 'python':'text/x-python',
+    'pyx':'text/x-pyrex',
+    'nroff':'application/x-troff', 'roff':'application/x-troff',
+    'troff':'application/x-troff',
+    'rb':'text/x-ruby', 'ruby':'text/x-ruby',
+    'rfc':'text/x-rfc',
+    'rst': 'text/x-rst',
+    'rtf':'application/rtf',
+    'scm':'text/x-scheme',
+    'sh':'application/x-sh',
+    'sql':'text/x-sql',
+    'svg':'image/svg+xml',
+    'tcl':'text/x-tcl',
+    'tex':'text/x-tex',
+    'txtl': 'text/x-textile', 'textile': 'text/x-textile',
+    'vb':'text/x-vba', 'vba':'text/x-vba', 'bas':'text/x-vba',
+    'v':'text/x-verilog', 'verilog':'text/x-verilog',
+    'vhd':'text/x-vhdl',
+    'vrml':'model/vrml',
+    'wrl':'model/vrml',
+    'xml':'text/xml',
+    'xs':'text/x-csrc',
+    'xsl':'text/xsl',
+    'zsh':'text/x-zsh'
+}
+
+
+MODE_RE = re.compile(
+    r"#!(?:[/\w.-_]+/)?(\w+)|"               # look for shebang
+    r"-\*-\s*(?:mode:\s*)?([\w+-]+)\s*-\*-"  # look for Emacs' -*- mode -*-
+    )
+
+def get_mimetype(filename, content=None):
+    """Guess the most probable MIME type of a file with the given name."""
+    suffix = filename.split('.')[-1]
+    if MIME_MAP.has_key(suffix):
+        return MIME_MAP[suffix]
+    elif content:
+        match = re.search(MODE_RE, content[:1000])
+        if match:
+            mode = match.group(1) or match.group(2).lower()
+            if MIME_MAP.has_key(mode):
+                return MIME_MAP[mode]
+    try:
+        import mimetypes
+        return mimetypes.guess_type(filename)[0]
+    except:
+        if content and is_binary(content):
+            return 'application/octet-stream'
+        else:
+            return None
+
+def is_binary(str):
+    """Detect binary content by checking the first thousand bytes for zeroes."""
+    if detect_unicode(str):
+        return False
+    return '\0' in str[:1000]
+
+def detect_unicode(data):
+    """Detect different unicode charsets by looking for BOMs (Byte Order
+    Marks)."""
+    if data.startswith('\xff\xfe'):
+        return 'utf-16-le'
+    elif data.startswith('\xfe\xff'):
+        return 'utf-16-be'
+    elif data.startswith('\xef\xbb\xbf'):
+        return 'utf-8'
+    else:
+        return None
+
+
+class IHTMLPreviewRenderer(Interface):
+    """Extension point interface for components that add HTML renderers of
+    specific content types to the `Mimeview` component.
+    """
+
+    # implementing classes should set this property to True if they
+    # support text content where Trac should expand tabs into spaces
+    expand_tabs = False
+
+    def get_quality_ratio(mimetype):
+        """Return the level of support this renderer provides for the content of
+        the specified MIME type. The return value must be a number between 0
+        and 9, where 0 means no support and 9 means "perfect" support.
+        """
+
+    def render(req, mimetype, content, filename=None, rev=None):
+        """Render an XHTML preview of the given content of the specified MIME
+        type.
+        
+        Can return the generated XHTML text as a single string or as an iterable
+        that yields strings. In the latter case, the list will be considered to
+        correspond to lines of text in the original content.
+
+        The `filename` and `rev` parameters are provided for renderers that
+        embed objects (using <object> or <img>) instead of included the content
+        inline.
+        """
+
+class IHTMLPreviewAnnotator(Interface):
+    """Extension point interface for components that can annotate an XHTML
+    representation of file contents with additional information."""
+
+    def get_annotation_type():
+        """Return a (type, label, description) tuple that defines the type of
+        annotation and provides human readable names. The `type` element should
+        be unique to the annotator. The `label` element is used as column
+        heading for the table, while `description` is used as a display name to
+        let the user toggle the appearance of the annotation type.
+        """
+
+    def annotate_line(number, content):
+        """Return the XHTML markup for the table cell that contains the
+        annotation data."""
+
+
+class Mimeview(Component):
+    """A generic class to prettify data, typically source code."""
+
+    renderers = ExtensionPoint(IHTMLPreviewRenderer)
+    annotators = ExtensionPoint(IHTMLPreviewAnnotator)
+
+    # Public API
+
+    def get_annotation_types(self):
+        """Generator that returns all available annotation types."""
+        for annotator in self.annotators:
+            yield annotator.get_annotation_type()
+
+    def render(self, req, mimetype, content, filename=None, rev=None,
+               annotations=None):
+        """Render an XHTML preview of the given content of the specified MIME
+        type, selecting the most appropriate `IHTMLPreviewRenderer`
+        implementation available for the given MIME type.
+
+        Return a string containing the XHTML text.
+        """
+        if not content:
+            return ''
+
+        if filename and not mimetype:
+            mimetype = get_mimetype(filename, content)
+        mimetype = mimetype.split(';')[0].strip() # split off charset
+
+        expanded_content = None
+
+        candidates = []
+        for renderer in self.renderers:
+            qr = renderer.get_quality_ratio(mimetype)
+            if qr > 0:
+                expand_tabs = getattr(renderer, 'expand_tabs', False)
+                if expand_tabs and expanded_content is None:
+                    tab_width = int(self.config.get('mimeviewer', 'tab_width'))
+                    expanded_content = content.expandtabs(tab_width)
+
+                if expand_tabs:
+                    candidates.append((qr, renderer, expanded_content))
+                else:
+                    candidates.append((qr, renderer, content))
+        candidates.sort(lambda x,y: cmp(y[0], x[0]))
+
+        for qr, renderer, content in candidates:
+            try:
+                self.log.debug('Trying to render HTML preview using %s'
+                               % renderer.__class__.__name__)
+                result = renderer.render(req, mimetype, content, filename, rev)
+
+                if not result:
+                    continue
+                elif isinstance(result, (str, unicode)):
+                    return Markup(result)
+                elif annotations:
+                    return Markup(self._annotate(result, annotations))
+                else:
+                    buf = StringIO()
+                    buf.write('<div class="code"><pre>')
+                    for line in result:
+                        buf.write(line + '\n')
+                    buf.write('</pre></div>')
+                    return Markup(buf.getvalue())
+            except Exception, e:
+                self.log.warning('HTML preview using %s failed (%s)'
+                                 % (renderer, e), exc_info=True)
+
+    def _annotate(self, lines, annotations):
+        buf = StringIO()
+        buf.write('<table class="code"><thead><tr>')
+        annotators = []
+        for annotator in self.annotators:
+            atype, alabel, adesc = annotator.get_annotation_type()
+            if atype in annotations:
+                buf.write('<th class="%s">%s</th>' % (atype, alabel))
+                annotators.append(annotator)
+        buf.write('<th class="content">&nbsp;</th>')
+        buf.write('</tr></thead><tbody>')
+
+        space_re = re.compile('(?P<spaces> (?: +))|'
+                              '^(?P<tag><\w+.*?>)?( )')
+        def htmlify(match):
+            m = match.group('spaces')
+            if m:
+                div, mod = divmod(len(m), 2)
+                return div * '&nbsp; ' + mod * '&nbsp;'
+            return (match.group('tag') or '') + '&nbsp;'
+
+        num = -1
+        for num, line in enumerate(_html_splitlines(lines)):
+            cells = []
+            for annotator in annotators:
+                cells.append(annotator.annotate_line(num + 1, line))
+            cells.append('<td>%s</td>\n' % space_re.sub(htmlify, line))
+            buf.write('<tr>' + '\n'.join(cells) + '</tr>')
+        else:
+            if num < 0:
+                return ''
+        buf.write('</tbody></table>')
+        return buf.getvalue()
+
+    def max_preview_size(self):
+        return int(self.config.get('mimeviewer', 'max_preview_size'))
+
+    def get_charset(self, content='', mimetype=None):
+        """Infer the character encoding from the `content` or the `mimetype`.
+
+        The charset information in the `mimetype`, if given,
+        takes precedence over auto-detection.
+        Return the configured `default_charset` if no other information
+        is available.
+        """
+        if mimetype:
+            ctpos = mimetype.find('charset=')
+            if ctpos >= 0:
+                return mimetype[ctpos + 8:].strip()
+        return detect_unicode(content) or \
+               self.config.get('trac', 'default_charset')
+
+    def to_utf8(self, content, mimetype=None):
+        """Convert an encoded `content` to utf-8.
+
+        Tries to auto-detect the encoding using `Mimeview.get_charset()`.
+        """
+        return to_utf8(content, self.get_charset(content, mimetype))
+
+    def preview_to_hdf(self, req, content, mimetype, filename,
+                       detail=None, annotations=None):
+        max_preview_size = self.max_preview_size()
+        if len(content) >= max_preview_size:
+            return {'max_file_size_reached': True,
+                    'max_file_size': max_preview_size}
+
+        if not is_binary(content):
+            content = self.to_utf8(content, mimetype)
+        return {'preview': self.render(req, mimetype, content,
+                                       filename, detail, annotations)}
+
+
+def _html_splitlines(lines):
+    """Tracks open and close tags in lines of HTML text and yields lines that
+    have no tags spanning more than one line."""
+    open_tag_re = re.compile(r'<(\w+)(\s.*?)?[^/]?>')
+    close_tag_re = re.compile(r'</(\w+)>')
+    open_tags = []
+    for line in lines:
+        # Reopen tags still open from the previous line
+        for tag in open_tags:
+            line = tag.group(0) + line
+        open_tags = []
+
+        # Find all tags opened on this line
+        for tag in open_tag_re.finditer(line):
+            open_tags.append(tag)
+
+        open_tags.reverse()
+
+        # Find all tags closed on this line
+        for ctag in close_tag_re.finditer(line):
+            for otag in open_tags:
+                if otag.group(1) == ctag.group(1):
+                    open_tags.remove(otag)
+                    break
+
+        # Close all tags still open at the end of line, they'll get reopened at
+        # the beginning of the next line
+        for tag in open_tags:
+            line += '</%s>' % tag.group(1)
+
+        yield line
+
+
+class LineNumberAnnotator(Component):
+    """Text annotator that adds a column with line numbers."""
+    implements(IHTMLPreviewAnnotator)
+
+    # ITextAnnotator methods
+
+    def get_annotation_type(self):
+        return 'lineno', 'Line', 'Line numbers'
+
+    def annotate_line(self, number, content):
+        return '<th id="L%s"><a href="#L%s">%s</a></th>' % (number, number,
+                                                            number)
+
+
+class PlainTextRenderer(Component):
+    """HTML preview renderer for plain text, and fallback for any kind of text
+    for which no more specific renderer is available.
+    """
+    implements(IHTMLPreviewRenderer)
+
+    expand_tabs = True
+
+    TREAT_AS_BINARY = [
+        'application/pdf',
+        'application/postscript',
+        'application/rtf'
+    ]
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype in self.TREAT_AS_BINARY:
+            return 0
+        return 1
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        if is_binary(content):
+            self.env.log.debug("Binary data; no preview available")
+            return
+
+        self.env.log.debug("Using default plain text mimeviewer")
+        for line in content.splitlines():
+            yield escape(line)
+
+
+class ImageRenderer(Component):
+    """Inline image display."""
+    implements(IHTMLPreviewRenderer)
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype.startswith('image/'):
+            return 8
+        return 0
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        src = '?'
+        if rev:
+            src += 'rev=%d&' % rev
+        src += 'format=raw'
+        return '<div class="image-file"><img src="%s" alt="" /></div>' % src
+
+
+class WikiTextRenderer(Component):
+    """Render files containing Trac's own Wiki formatting markup."""
+    implements(IHTMLPreviewRenderer)
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype in ('text/x-trac-wiki', 'application/x-trac-wiki'):
+            return 8
+        return 0
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        from trac.wiki import wiki_to_html
+        return wiki_to_html(content, self.env, req)
diff -urN trac-trunk/build/lib/trac/mimeview/enscript.py aw-trac/build/lib/trac/mimeview/enscript.py
--- trac-trunk/build/lib/trac/mimeview/enscript.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/mimeview/enscript.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,123 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2005 Edgewall Software
+# Copyright (C) 2004 Daniel Lundin <daniel@edgewall.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+
+from trac.core import *
+from trac.mimeview.api import IHTMLPreviewRenderer
+from trac.util import escape, NaivePopen, Deuglifier
+
+__all__ = ['EnscriptRenderer']
+
+types = {
+    'application/xhtml+xml':    'html',
+    'application/postscript':   'postscript',
+    'application/x-csh':        'csh',
+    'application/x-troff':      'nroff',
+    'text/html':                'html',
+    'text/x-ada':               'ada',
+    'text/x-asm':               'asm',
+    'text/x-awk':               'awk',
+    'text/x-c++src':            'cpp',
+    'text/x-c++hdr':            'cpp',
+    'text/x-chdr':              'c',
+    'text/x-csh':               'csh',
+    'text/x-csrc':              'c',
+    'text/x-diff':              'diffu', # Assume unified diff (works otherwise)
+    'text/x-eiffel':            'eiffel',
+    'text/x-elisp':             'elisp',
+    'text/x-fortran':           'fortran',
+    'text/x-haskell':           'haskell',
+    'text/x-idl':               'idl',
+    'text/x-inf':               'inf',
+    'text/x-java':              'java',
+    'text/x-javascript':        'javascript',
+    'text/x-ksh':               'ksh',
+    'text/x-lua':               'lua',
+    'text/x-m4':                'm4',
+    'text/x-makefile':          'makefile',
+    'text/x-mail':              'mail',
+    'text/x-matlab':            'matlab',
+    'text/x-objc':              'objc',
+    'text/x-pascal':            'pascal',
+    'text/x-perl':              'perl',
+    'text/x-pyrex':             'pyrex',
+    'text/x-python':            'python',
+    'text/x-rfc':               'rfc',
+    'text/x-ruby':              'ruby',
+    'text/x-sh':                'sh',
+    'text/x-scheme':            'scheme',
+    'text/x-sql':               'sql',
+    'text/x-tcl':               'tcl',
+    'text/x-tex':               'tex',
+    'text/x-vba':               'vba',
+    'text/x-verilog':           'verilog',
+    'text/x-vhdl':              'vhdl',
+    'model/vrml':               'vrml',
+    'application/x-sh':         'sh',
+    'text/x-zsh':               'zsh',
+    'text/vnd.wap.wmlscript':   'wmlscript',
+}
+
+
+class EnscriptDeuglifier(Deuglifier):
+    def rules(cls):
+        return [
+            r'(?P<comment><FONT COLOR="#B22222">)',
+            r'(?P<keyword><FONT COLOR="#5F9EA0">)',
+            r'(?P<type><FONT COLOR="#228B22">)',
+            r'(?P<string><FONT COLOR="#BC8F8F">)',
+            r'(?P<func><FONT COLOR="#0000FF">)',
+            r'(?P<prep><FONT COLOR="#B8860B">)',
+            r'(?P<lang><FONT COLOR="#A020F0">)',
+            r'(?P<var><FONT COLOR="#DA70D6">)',
+            r'(?P<font><FONT.*?>)',
+            r'(?P<endfont></FONT>)'
+        ]
+    rules = classmethod(rules)
+
+
+class EnscriptRenderer(Component):
+    """Syntax highlighting using GNU Enscript."""
+
+    implements(IHTMLPreviewRenderer)
+
+    expand_tabs = True
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype in types:
+            return 2
+        return 0
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        cmdline = self.config.get('mimeviewer', 'enscript_path')
+        cmdline += ' --color -h -q --language=html -p - -E' + types[mimetype]
+        self.env.log.debug("Enscript command line: %s" % cmdline)
+
+        np = NaivePopen(cmdline, content, capturestderr=1)
+        if np.errorlevel or np.err:
+            err = 'Running (%s) failed: %s, %s.' % (cmdline, np.errorlevel,
+                                                    np.err)
+            raise Exception, err
+        odata = np.out
+
+        # Strip header and footer
+        i = odata.find('<PRE>')
+        beg = i > 0 and i + 6
+        i = odata.rfind('</PRE>')
+        end = i > 0 and i or len(odata)
+
+        odata = EnscriptDeuglifier().format(odata[beg:end])
+        return odata.splitlines()
diff -urN trac-trunk/build/lib/trac/mimeview/patch.py aw-trac/build/lib/trac/mimeview/patch.py
--- trac-trunk/build/lib/trac/mimeview/patch.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/mimeview/patch.py	2006-01-08 20:47:39.000000000 -0800
@@ -0,0 +1,198 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+#         Ludvig Strigeus
+
+from trac.core import *
+from trac.mimeview.api import IHTMLPreviewRenderer
+from trac.util import escape, Markup
+from trac.web.chrome import add_stylesheet
+
+__all__ = ['PatchRenderer']
+
+
+class PatchRenderer(Component):
+    """Structured display of patches in unified diff format, similar to the
+    layout provided by the changeset view.
+    """
+
+    implements(IHTMLPreviewRenderer)
+
+    diff_cs = """
+<?cs include:'macros.cs' ?>
+<div class="diff"><ul class="entries"><?cs
+ each:file = diff.files ?><li class="entry">
+  <h2><?cs var:file.filename ?></h2>
+  <table class="inline" summary="Differences" cellspacing="0">
+   <colgroup><col class="lineno" /><col class="lineno" /><col class="content" /></colgroup>
+   <thead><tr>
+    <th><?cs var:file.oldrev ?></th>
+    <th><?cs var:file.newrev ?></th>
+    <th>&nbsp;</th>
+   </tr></thead><?cs
+   each:change = file.diff ?><?cs
+    call:diff_display(change, diff.style) ?><?cs
+    if:name(change) < len(file.diff) - 1 ?>
+     <tbody class="skipped">
+      <tr><th>&hellip;</th><th>&hellip;</th><td>&nbsp;</td></tr>
+     </tbody><?cs
+    /if ?><?cs
+   /each ?>
+  </table>
+ </li><?cs /each ?>
+</ul></div>
+""" # diff_cs
+
+    # IHTMLPreviewRenderer methods
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype == 'text/x-diff':
+            return 8
+        return 0
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        from trac.web.clearsilver import HDFWrapper
+
+        tabwidth = int(self.config.get('diff', 'tab_width',
+                       self.config.get('mimeviewer', 'tab_width')))
+        d = self._diff_to_hdf(content.splitlines(), tabwidth)
+        if not d:
+            raise TracError, 'Invalid unified diff content'
+        hdf = HDFWrapper(loadpaths=[self.env.get_templates_dir(),
+                                    self.config.get('trac', 'templates_dir')])
+        hdf['diff.files'] = d
+
+        add_stylesheet(req, 'common/css/diff.css')
+        return hdf.render(hdf.parse(self.diff_cs))
+
+    # Internal methods
+
+    # FIXME: This function should probably share more code with the
+    #        trac.versioncontrol.diff module
+    def _diff_to_hdf(self, difflines, tabwidth):
+        """
+        Translate a diff file into something suitable for inclusion in HDF.
+        The result is [(filename, revname_old, revname_new, changes)],
+        where changes has the same format as the result of
+        `trac.versioncontrol.diff.hdf_diff`.
+
+        If the diff cannot be parsed, this method returns None.
+        """
+        def _markup_intraline_change(fromlines, tolines):
+            from trac.versioncontrol.diff import _get_change_extent
+            for i in xrange(len(fromlines)):
+                fr, to = fromlines[i], tolines[i]
+                (start, end) = _get_change_extent(fr, to)
+                if start != 0 and end != 0:
+                    fromlines[i] = fr[:start] + '\0' + fr[start:end+len(fr)] + \
+                                   '\1' + fr[end:]
+                    tolines[i] = to[:start] + '\0' + to[start:end+len(to)] + \
+                                 '\1' + to[end:]
+
+        import re
+        space_re = re.compile(' ( +)|^ ')
+        def htmlify(match):
+            div, mod = divmod(len(match.group(0)), 2)
+            return div * '&nbsp; ' + mod * '&nbsp;'
+
+        output = []
+        filename, groups = None, None
+        lines = iter(difflines)
+        for line in lines:
+            if not line.startswith('--- '):
+                continue
+
+            # Base filename/version
+            words = line.split(None, 2)
+            filename, fromrev = words[1], 'old'
+            groups, blocks = None, None
+
+            # Changed filename/version
+            line = lines.next()
+            if not line.startswith('+++ '):
+                return None
+
+            words = line.split(None, 2)
+            if len(words[1]) < len(filename):
+                # Always use the shortest filename for display
+                filename = words[1]
+            groups = []
+            output.append({'filename' : filename, 'oldrev' : fromrev,
+                           'newrev' : 'new', 'diff' : groups})
+
+            for line in lines:
+                # @@ -333,10 +329,8 @@
+                r = re.match(r'@@ -(\d+),(\d+) \+(\d+),(\d+) @@', line)
+                if not r:
+                    break
+                blocks = []
+                groups.append(blocks)
+                fromline,fromend,toline,toend = map(int, r.groups())
+                last_type = None
+
+                fromend += fromline
+                toend += toline
+
+                while fromline < fromend or toline < toend:
+                    line = lines.next()
+
+                    # First character is the command
+                    command, line = line[0], line[1:]
+                    # Make a new block?
+                    if (command == ' ') != last_type:
+                        last_type = command == ' '
+                        blocks.append({'type': last_type and 'unmod' or 'mod',
+                                       'base.offset': fromline - 1,
+                                       'base.lines': [],
+                                       'changed.offset': toline - 1,
+                                       'changed.lines': []})
+                    if command == ' ':
+                        blocks[-1]['changed.lines'].append(line)
+                        blocks[-1]['base.lines'].append(line)
+                        fromline += 1
+                        toline += 1
+                    elif command == '+':
+                        blocks[-1]['changed.lines'].append(line)
+                        toline += 1
+                    elif command == '-':
+                        blocks[-1]['base.lines'].append(line)
+                        fromline += 1
+                    else:
+                        return None
+
+        # Go through all groups/blocks and mark up intraline changes, and
+        # convert to html
+        for o in output:
+            for group in o['diff']:
+                for b in group:
+                    f, t = b['base.lines'], b['changed.lines']
+                    if b['type'] == 'mod':
+                        if len(f) == 0:
+                            b['type'] = 'add'
+                        elif len(t) == 0:
+                            b['type'] = 'rem'
+                        elif len(f) == len(t):
+                            _markup_intraline_change(f, t)
+                    for i in xrange(len(f)):
+                        line = f[i].expandtabs(tabwidth)
+                        line = escape(line).replace('\0', '<del>') \
+                                           .replace('\1', '</del>')
+                        f[i] = Markup(space_re.sub(htmlify, line))
+                    for i in xrange(len(t)):
+                        line = t[i].expandtabs(tabwidth)
+                        line = escape(line).replace('\0', '<ins>') \
+                                           .replace('\1', '</ins>')
+                        t[i] = Markup(space_re.sub(htmlify, line))
+        return output
diff -urN trac-trunk/build/lib/trac/mimeview/php.py aw-trac/build/lib/trac/mimeview/php.py
--- trac-trunk/build/lib/trac/mimeview/php.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/mimeview/php.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,75 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christian Boos <cboos@bct-technology.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christian Boos <cboos@bct-technology.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+from trac.core import *
+from trac.mimeview.api import IHTMLPreviewRenderer
+from trac.util import Deuglifier, NaivePopen
+
+__all__ = ['PHPRenderer']
+
+php_types = ('text/x-php', 'application/x-httpd-php',
+             'application/x-httpd-php4', 'application/x-httpd-php1')
+
+
+class PhpDeuglifier(Deuglifier):
+
+    def rules(cls):
+        colors = dict(comment='FF8000', lang='0000BB', keyword='007700',
+                      string='DD0000')
+        # rules check for <font> for PHP 4 or <span> for PHP 5
+        color_rules = [
+                r'(?P<%s><(?:font color="|span style="color: )#%s">)' % c
+                for c in colors.items()
+                ]
+        return color_rules + [ r'(?P<font><font.*?>)', r'(?P<endfont></font>)' ]
+    rules = classmethod(rules)
+
+class PHPRenderer(Component):
+    """
+    Syntax highlighting using the PHP executable if available.
+    """
+
+    implements(IHTMLPreviewRenderer)
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype in php_types:
+            return 4
+        return 0
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        cmdline = self.config.get('mimeviewer', 'php_path')
+        # -n to ignore php.ini so we're using default colors
+        cmdline += ' -sn'
+        self.env.log.debug("PHP command line: %s" % cmdline)
+
+        np = NaivePopen(cmdline, content, capturestderr=1)
+        if np.errorlevel or np.err:
+            err = 'Running (%s) failed: %s, %s.' % (cmdline, np.errorlevel,
+                                                    np.err)
+            raise Exception, err
+        odata = ''.join(np.out.splitlines()[1:-1])
+        if odata.startswith('X-Powered-By'):
+            raise TracError, 'You appear to be using the PHP CGI binary.  ' \
+                             'Trac requires the CLI version for syntax ' \
+                             'highlighting.'
+
+        html = PhpDeuglifier().format(odata)
+        for line in html.split('<br />'):
+            # PHP generates _way_ too many non-breaking spaces...
+            # We don't need them anyway, so replace them by normal spaces
+            yield line.replace('&nbsp;', ' ')
diff -urN trac-trunk/build/lib/trac/mimeview/rst.py aw-trac/build/lib/trac/mimeview/rst.py
--- trac-trunk/build/lib/trac/mimeview/rst.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/mimeview/rst.py	2006-02-24 11:34:51.000000000 -0800
@@ -0,0 +1,229 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2005 Edgewall Software
+# Copyright (C) 2004 Oliver Rutherfurd
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin
+#         Oliver Rutherfurd (initial implementation)
+#         Nuutti Kotivuori (role support)
+#
+# Trac support for reStructured Text, including a custom 'trac' directive
+#
+# 'trac' directive code by Oliver Rutherfurd.
+#
+# Inserts `reference` nodes for TracLinks into the document tree.
+
+__docformat__ = 'reStructuredText'
+
+from distutils.version import StrictVersion
+import re
+
+from trac.core import *
+from trac.mimeview.api import IHTMLPreviewRenderer
+from trac.web.href import Href
+from trac.wiki.formatter import WikiProcessor
+from trac.wiki import WikiSystem
+
+WIKI_LINK = re.compile(r'(?:wiki:)?(.+)')
+TICKET_LINK = re.compile(r'(?:#(\d+))|(?:ticket:(\d+))')
+REPORT_LINK = re.compile(r'(?:{(\d+)})|(?:report:(\d+))')
+CHANGESET_LINK = re.compile(r'(?:\[(\d+)\])|(?:changeset:(\d+))')
+FILE_LINK = re.compile(r'(?:browser|repos|source):([^#]+)#?(.*)')
+
+def _wikipage(href, args):
+    return href.wiki(args[0])
+
+def _ticket(href, args):
+    return href.ticket(args[0])
+
+def _report(href, args):
+    return href.report(args[0])
+
+def _changeset(href, args):
+    return href.changeset(int(args[0]))
+
+def _browser(href, args):
+    path = args[0]
+    rev = len(args) == 2 and args[1] or ''
+    return href.browser(path, rev=rev)
+
+# TracLink REs and callback functions
+LINKS = [(TICKET_LINK, _ticket),
+         (REPORT_LINK, _report),
+         (CHANGESET_LINK, _changeset),
+         (FILE_LINK, _browser),
+         (WIKI_LINK, _wikipage)]
+
+class ReStructuredTextRenderer(Component):
+    """
+    Renders plain text in reStructuredText format as HTML.
+    """
+    implements(IHTMLPreviewRenderer)
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype == 'text/x-rst':
+            return 8
+        return 0
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        try:
+            from docutils import nodes
+            from docutils.core import publish_string
+            from docutils.parsers import rst
+            from docutils import __version__
+        except ImportError:
+            raise TracError, 'Docutils not found'
+        if StrictVersion(__version__) < StrictVersion('0.3.3'):
+            raise TracError, 'Docutils version >= %s required, %s found' \
+                             % ('0.3.3', __version__)
+
+        def trac_get_reference(rawtext, link, text):
+            for (pattern, function) in LINKS:
+                m = pattern.match(link)
+                if m:
+                    g = filter(None, m.groups())
+                    missing = 0
+                    if not text:
+                        text = g[0]
+                    if pattern == WIKI_LINK:
+                        pagename = re.search(r'^[^\#]+',g[0])
+                        if not WikiSystem(self.env).has_page(pagename.group()):
+                            missing = 1
+                            text = text + "?"
+                    uri = function(self.env.href, g)
+                    reference = nodes.reference(rawtext, text)
+                    reference['refuri']= uri
+                    if missing:
+                        reference.set_class('missing')
+                    return reference
+            return None
+
+        def trac(name, arguments, options, content, lineno,
+                 content_offset, block_text, state, state_machine):
+            """Inserts a `reference` node into the document 
+            for a given `TracLink`_, based on the content 
+            of the arguments.
+
+            Usage::
+
+              .. trac:: target [text]
+
+            ``target`` may be one of the following:
+
+              * For wiki: ``WikiName`` or ``wiki:WikiName``
+               * For tickets: ``#1`` or ``ticket:1``
+              * For reports: ``{1}`` or ``report:1``
+              * For changesets: ``[1]`` or ``changeset:1``
+              * For files: ``source:trunk/COPYING``
+
+            ``[text]`` is optional.  If not given, ``target`` is
+            used as the reference text.
+
+            .. _TracLink: http://projects.edgewall.com/trac/wiki/TracLinks
+            """
+            link = arguments[0]
+            if len(arguments) == 2:
+                text = arguments[1]
+            else:
+                text = None
+            reference = trac_get_reference(block_text, link, text)
+            if reference:
+                p = nodes.paragraph()
+                p += reference
+                return p
+            # didn't find a match (invalid TracLink),
+            # report a warning
+            warning = state_machine.reporter.warning(
+                    '%s is not a valid TracLink' % (arguments[0]),
+                    nodes.literal_block(block_text, block_text),
+                    line=lineno)
+            return [warning]
+
+        def trac_role(name, rawtext, text, lineno, inliner, options={},
+                      content=[]):
+            args  = text.split(" ",1)
+            link = args[0]
+            if len(args)==2:
+                text = args[1]
+            else:
+                text = None
+            reference = trac_get_reference(rawtext, link, text)
+            if reference:
+                return [reference], []
+            warning = nodes.warning(None, nodes.literal_block(text,
+                'WARNING: %s is not a valid TracLink' % rawtext))
+            return warning, []
+
+        # 1 required arg, 1 optional arg, spaces allowed in last arg
+        trac.arguments = (1,1,1)
+        trac.options = None
+        trac.content = None
+        rst.directives.register_directive('trac', trac)
+        rst.roles.register_local_role('trac', trac_role)
+
+        # The code_block could is taken from the leo plugin rst2
+        def code_formatter(language, text):
+            processor = WikiProcessor(self.env, language)
+            html = processor.process(req, text)
+            raw = nodes.raw('', html, format='html')
+            return raw
+        
+        def code_role(name, rawtext, text, lineno, inliner, options={},
+                      content=[]):
+            language = options.get('language')
+            if not language:
+                args  = text.split(':', 1)
+                language = args[0]
+                if len(args) == 2:
+                    text = args[1]
+                else:
+                    text = ''
+            reference = code_formatter(language, text)
+            return [reference], []
+        
+        def code_block(name, arguments, options, content, lineno,
+                       content_offset, block_text, state, state_machine):
+            """
+            Create a code-block directive for docutils.
+
+            Usage: .. code-block:: language
+
+            If the language can be syntax highlighted it will be.
+            """
+            language = arguments[0]
+            text = '\n'.join(content)        
+            reference = code_formatter(language, text)
+            return [reference]
+
+        # These are documented
+        # at http://docutils.sourceforge.net/spec/howto/rst-directives.html.
+        code_block.arguments = (
+            1, # Number of required arguments.
+            0, # Number of optional arguments.
+            0) # True if final argument may contain whitespace.
+    
+        # A mapping from option name to conversion function.
+        code_role.options = code_block.options = {
+            'language' :
+            rst.directives.unchanged # Return the text argument, unchanged
+        }
+        code_block.content = 1 # True if content is allowed.
+        # Register the directive with docutils.
+        rst.directives.register_directive('code-block', code_block)
+        rst.roles.register_local_role('code-block', code_role)
+
+        _inliner = rst.states.Inliner()
+        _parser = rst.Parser(inliner=_inliner)
+
+        html = publish_string(content, writer_name='html', parser=_parser,
+                              settings_overrides={'halt_level': 6})
+        return html[html.find('<body>') + 6:html.find('</body>')].strip()
diff -urN trac-trunk/build/lib/trac/mimeview/silvercity.py aw-trac/build/lib/trac/mimeview/silvercity.py
--- trac-trunk/build/lib/trac/mimeview/silvercity.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/mimeview/silvercity.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,106 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004 Edgewall Software
+# Copyright (C) 2004 Daniel Lundin <daniel@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+
+"""Syntax highlighting module, based on the SilverCity module.
+
+Get it at: http://silvercity.sourceforge.net/
+"""
+
+import re
+try:
+    from cStringIO import StringIO
+except ImportError:
+    from StringIO import StringIO
+
+from trac.core import *
+from trac.mimeview.api import IHTMLPreviewRenderer
+
+__all__ = ['SilverCityRenderer']
+
+types = {
+    'text/css':['CSS'],
+    'text/html':['HyperText', {'asp.default.language':1}],
+    'application/xml':['XML'],
+    'application/xhtml+xml':['HyperText', {'asp.default.language':1}],
+    'application/x-javascript':['CPP'], # Kludgy.
+    'text/x-asp':['HyperText', {'asp.default.language':2}],
+    'text/x-c++hdr':['CPP'],
+    'text/x-c++src':['CPP'],
+    'text/x-chdr':['CPP'],
+    'text/x-csrc':['CPP'],
+    'text/x-perl':['Perl'],
+    'text/x-php':['HyperText', {'asp.default.language':4}],
+    'application/x-httpd-php':['HyperText', {'asp.default.language':4}],
+    'application/x-httpd-php4':['HyperText', {'asp.default.language':4}],
+    'application/x-httpd-php3':['HyperText', {'asp.default.language':4}],
+    'text/x-psp':['HyperText', {'asp.default.language':3}],
+    'text/x-python':['Python'],
+    'text/x-ruby':['Ruby'],
+    'text/x-sql':['SQL'],
+    'text/xml':['XML'],
+    'text/xslt':['XSLT'],
+    'image/svg+xml':['XML']
+}
+
+CRLF_RE = re.compile('\r$', re.MULTILINE)
+
+
+class SilverCityRenderer(Component):
+    """Syntax highlighting based on SilverCity."""
+
+    implements(IHTMLPreviewRenderer)
+
+    expand_tabs = True
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype in types:
+            return 3
+        return 0
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        import SilverCity
+        try:
+            typelang = types[mimetype]
+            lang = typelang[0]
+            module = getattr(SilverCity, lang)
+            generator = getattr(module, lang + "HTMLGenerator")
+            try:
+                allprops = typelang[1]
+                propset = SilverCity.PropertySet()
+                for p in allprops.keys():
+                    propset[p] = allprops[p]
+            except IndexError:
+                pass
+        except (KeyError, AttributeError):
+            err = "No SilverCity lexer found for mime-type '%s'." % mimetype
+            raise Exception, err
+
+        # SilverCity generates extra empty line against some types of
+        # the line such as comment or #include with CRLF. So we
+        # standardize to LF end-of-line style before call.
+        content = CRLF_RE.sub('', content)
+
+        buf = StringIO()
+        generator().generate_html(buf, content)
+
+        br_re = re.compile(r'<br\s*/?>$', re.MULTILINE)
+        span_default_re = re.compile(r'<span class="\w+_default">(.*?)</span>',
+                                     re.DOTALL)
+        html = span_default_re.sub(r'\1', br_re.sub('', buf.getvalue()))
+
+        # SilverCity generates _way_ too many non-breaking spaces...
+        # We don't need them anyway, so replace them by normal spaces
+        return html.replace('&nbsp;', ' ').splitlines()
diff -urN trac-trunk/build/lib/trac/mimeview/txtl.py aw-trac/build/lib/trac/mimeview/txtl.py
--- trac-trunk/build/lib/trac/mimeview/txtl.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/mimeview/txtl.py	2006-01-03 01:23:01.000000000 -0800
@@ -0,0 +1,36 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2006 Edgewall Software
+# Copyright (C) 2004 Daniel Lundin
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+
+"""Trac support for Textile
+See also: http://dealmeida.net/projects/textile/
+"""
+
+from trac.core import *
+from trac.mimeview.api import IHTMLPreviewRenderer
+
+
+class TextileRenderer(Component):
+    """Renders plain text in Textile format as HTML."""
+    implements(IHTMLPreviewRenderer)
+
+    def get_quality_ratio(self, mimetype):
+        if mimetype == 'text/x-textile':
+            return 8
+        return 0
+
+    def render(self, req, mimetype, content, filename=None, rev=None):
+        import textile
+        return textile.textile(content, encoding='utf-8')
diff -urN trac-trunk/build/lib/trac/notification.py aw-trac/build/lib/trac/notification.py
--- trac-trunk/build/lib/trac/notification.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/notification.py	2006-03-07 01:53:11.000000000 -0800
@@ -0,0 +1,263 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Daniel Lundin <daniel@edgewall.com>
+# Copyright (C) 2005-2006 Emmanuel Blot <emmanuel.blot@free.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+
+from trac import __version__
+from trac.core import TracError
+from trac.util import CRLF, wrap
+from trac.web.clearsilver import HDFWrapper
+from trac.web.main import populate_hdf
+
+import time
+import smtplib
+import re
+
+
+class Notify:
+    """Generic notification class for Trac. Subclass this to implement
+    different methods."""
+
+    db = None
+    hdf = None
+
+    def __init__(self, env):
+        self.env = env
+        self.config = env.config
+        self.db = env.get_db_cnx()
+        self.hdf = HDFWrapper(loadpaths=[env.get_templates_dir(),
+                                         self.config.get('trac', 'templates_dir')])
+        populate_hdf(self.hdf, env)
+
+    def notify(self, resid):
+        (torcpts, ccrcpts) = self.get_recipients(resid)
+        self.begin_send()
+        self.send(torcpts, ccrcpts)
+        self.finish_send()
+
+    def get_recipients(self, resid):
+        """Return a pair of list of subscribers to the resource 'resid'.
+           First list represents the direct recipients (To:),
+           second list represents the recipients in carbon copy (Cc:)"""
+        raise NotImplementedError
+
+    def begin_send(self):
+        """Prepare to send messages. Called before sending begins."""
+        pass
+
+    def send(self, torcpts, ccrcpts):
+        """Send message to recipients."""
+        raise NotImplementedError
+
+    def finish_send(self):
+        """Clean up after sending all messages. Called after sending all messages."""
+        pass
+
+
+class NotifyEmail(Notify):
+    """Baseclass for notification by email."""
+
+    smtp_server = 'localhost'
+    smtp_port = 25
+    from_email = 'trac+tickets@localhost'
+    subject = ''
+    server = None
+    email_map = None
+    template_name = None
+    addrfmt = r"[\w\d_\.\-]+\@(([\w\d\-])+\.)+([\w\d]{2,4})+"
+    shortaddr_re = re.compile(addrfmt)
+    longaddr_re = re.compile(r"^\s*(.*)\s+<(" + addrfmt + ")>\s*$");
+    nodomaddr_re = re.compile(r"[\w\d_\.\-]+")
+
+    def __init__(self, env):
+        Notify.__init__(self, env)
+
+        self._init_pref_encoding()
+        # Get the email addresses of all known users
+        self.email_map = {}
+        for username, name, email in self.env.get_known_users(self.db):
+            if email:
+                self.email_map[username] = email
+                
+    def _init_pref_encoding(self):
+        from email.Charset import Charset, QP, BASE64
+        self._charset = Charset()
+        self._charset.input_charset = 'utf-8'
+        self._charset.input_codec = 'utf-8'
+        pref = self.env.config.get('notification', 'mime_encoding').lower()
+        if pref == 'base64':
+            self._charset.header_encoding = BASE64
+            self._charset.body_encoding = BASE64
+            self._charset.output_charset = 'utf-8'
+            self._charset.output_codec = 'utf-8'    
+            self._pref_encoding = 'base64'
+        elif pref in ['qp', 'quoted-printable']:
+            self._charset.header_encoding = QP
+            self._charset.body_encoding = QP
+            self._charset.output_charset = 'utf-8'
+            self._charset.output_codec = 'utf-8'    
+            self._pref_encoding = 'quoted-printable'
+        elif pref == 'none':
+            self._charset.header_encoding = None
+            self._charset.body_encoding = None
+            self._charset.output_charset = 'ascii'
+            self._charset.output_codec = 'ascii'    
+            self._pref_encoding = None
+        else:
+            raise TracError, 'Invalid email encoding setting: %s' % pref
+
+    def notify(self, resid, subject):
+        self.subject = subject
+
+        if not self.config.getbool('notification', 'smtp_enabled'):
+            return
+        self.smtp_server = self.config.get('notification', 'smtp_server')
+        self.smtp_port = int(self.config.get('notification', 'smtp_port'))
+        self.maxheaderlen = int(self.config.get('notification', 'maxheaderlen'))
+        self.from_email = self.config.get('notification', 'smtp_from')
+        self.replyto_email = self.config.get('notification', 'smtp_replyto')
+        self.from_email = self.from_email or self.replyto_email
+        if not self.from_email and not self.replyto_email:
+            raise TracError('Unable to send email due to identity crisis.'
+                            '<br />Both <b>notification.from</b> and'
+                            ' <b>notification.reply_to</b> are unspecified'
+                            ' in configuration.',
+                            'SMTP Notification Error')
+
+        # Authentication info (optional)
+        self.user_name = self.config.get('notification', 'smtp_user')
+        self.password = self.config.get('notification', 'smtp_password')
+
+        Notify.notify(self, resid)
+
+    def format_header(self, name, email=None):
+        from email.Header import Header
+        try:
+            tmp = unicode(name, 'ascii')
+            name = Header(tmp, 'ascii', maxlinelen=self.maxheaderlen)
+        except UnicodeDecodeError:
+            name = Header(name, self._charset, maxlinelen=self.maxheaderlen)
+        if not email:
+            return name
+        else:
+            return "%s <%s>" % (name, email)
+
+    def add_headers(self, msg, headers):
+        for h in headers:
+            msg[h] = self.encode_header(headers[h])
+
+    def get_smtp_address(self, address):
+        if not address:
+            return None
+        if address.find('@') == -1:
+            if address == 'anonymous':
+                return None
+            if self.email_map.has_key(address):
+                address = self.email_map[address]
+            elif NotifyEmail.nodomaddr_re.match(address):
+                if self.config.getbool('notification', 'allow_short_addr'):
+                    return address
+                domain = self.config.get('notification', 'smtp_default_domain')
+                if domain:
+                    address = "%s@%s" % (address, domain)
+                else:
+                    self.env.log.info("Email address w/o domain: %s" % address)
+                    return None
+        mo = NotifyEmail.shortaddr_re.search(address)
+        if mo:
+            return mo.group(0)
+        mo = NotifyEmail.longaddr_re.search(address)
+        if mo:
+            return mo.group(2)
+        self.env.log.info("Invalid email address: %s" % address)
+        return None
+
+    def encode_header(self, value):
+        if isinstance(value, tuple):
+            return self.format_header(value[0], value[1])
+        if isinstance(value, list):
+            items = []
+            for v in value:
+                items.append(self.encode_header(v))
+            return ',\n\t'.join(items)
+        mo = NotifyEmail.longaddr_re.match(value)
+        if mo:
+            return self.format_header(mo.group(1), mo.group(2))
+        return self.format_header(value)
+
+    def begin_send(self):
+        self.server = smtplib.SMTP(self.smtp_server, self.smtp_port)
+        if self.user_name:
+            self.server.login(self.user_name, self.password)
+
+    def send(self, torcpts, ccrcpts, mime_headers={}):
+        from email.MIMEText import MIMEText
+        from email.Utils import formatdate, formataddr
+        body = self.hdf.render(self.template_name)
+        projname = self.config.get('project', 'name')
+        public_cc = self.config.getbool('notification', 'allow_public_cc')
+        headers = {}
+        headers['X-Mailer'] = 'Trac %s, by Edgewall Software' % __version__
+        headers['X-Trac-Version'] =  __version__
+        headers['X-Trac-Project'] =  projname
+        headers['X-URL'] = self.config.get('project', 'url')
+        headers['Subject'] = self.subject
+        headers['From'] = (projname, self.from_email)
+        headers['Sender'] = self.from_email
+        headers['Reply-To'] = self.replyto_email
+        # Format and remove invalid addresses
+        toaddrs = filter(lambda x: x, \
+                         [self.get_smtp_address(addr) for addr in torcpts])
+        ccaddrs = filter(lambda x: x, \
+                         [self.get_smtp_address(addr) for addr in ccrcpts])
+        # Remove duplicates
+        totmp = []
+        cctmp = []
+        for addr in toaddrs:
+            if addr not in totmp:
+                totmp.append(addr)
+        for addr in [c for c in ccaddrs if c not in totmp]:
+            if addr not in cctmp:
+                cctmp.append(addr)
+        (toaddrs, ccaddrs) = (totmp, cctmp)
+        if toaddrs:
+            headers['To'] = ', '.join(toaddrs)
+        if public_cc:
+            headers['Cc'] = ', '.join(ccaddrs)
+        headers['Date'] = formatdate()
+        charset = 'utf-8'
+        if not self._pref_encoding:
+            try:
+                dummy = unicode(body, 'ascii')
+            except UnicodeDecodeError:
+                raise TracError, "Ticket contains non-Ascii chars. " \
+                                 "Please change encoding setting"
+            charset = 'ascii'
+        else:
+            charset = 'utf-8'
+        msg = MIMEText(body, 'plain', charset)
+        del msg['Content-Transfer-Encoding']
+        if self._pref_encoding:
+            msg['Content-Transfer-Encoding'] = self._pref_encoding
+        msg.set_charset(self._charset)
+        self.add_headers(msg, headers);
+        self.add_headers(msg, mime_headers);
+        recipients = toaddrs + ccaddrs
+        self.env.log.debug("Sending SMTP notification to %s on port %d to %s"
+                           % (self.smtp_server, self.smtp_port, recipients))
+        msgtext = msg.as_string()
+        self.server.sendmail(msg['From'], recipients, msgtext)
+
+    def finish_send(self):
+        self.server.quit()
diff -urN trac-trunk/build/lib/trac/perm.py aw-trac/build/lib/trac/perm.py
--- trac-trunk/build/lib/trac/perm.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/perm.py	2006-02-02 07:40:46.000000000 -0800
@@ -0,0 +1,275 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2004 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+"""Management of permissions."""
+
+from trac.core import *
+
+
+__all__ = ['IPermissionRequestor', 'IPermissionStore',
+           'IPermissionGroupProvider', 'PermissionError', 'PermissionSystem']
+
+class PermissionError(StandardError):
+    """Insufficient permissions to complete the operation"""
+
+    def __init__ (self, action):
+        StandardError.__init__(self)
+        self.action = action
+
+    def __str__ (self):
+        return '%s privileges are required to perform this operation' % self.action
+
+
+class IPermissionRequestor(Interface):
+    """Extension point interface for components that define actions."""
+
+    def get_permission_actions():
+        """Return a list of actions defined by this component.
+        
+        The items in the list may either be simple strings, or
+        `(string, sequence)` tuples. The latter are considered to be "meta
+        permissions" that group several simple actions under one name for
+        convenience.
+        """
+
+
+class IPermissionStore(Interface):
+    """Extension point interface for components that provide storage and
+    management of permissions."""
+
+    def get_user_permissions(username):
+        """Return all permissions for the user with the specified name.
+        
+        The permissions are returned as a dictionary where the key is the name
+        of the permission, and the value is either `True` for granted
+        permissions or `False` for explicitly denied permissions."""
+
+    def get_all_permissions():
+        """Return all permissions for all users.
+
+        The permissions are returned as a list of (subject, action)
+        formatted tuples."""
+
+    def grant_permission(username, action):
+        """Grant a user permission to perform an action."""
+
+    def revoke_permission(username, action):
+        """Revokes the permission of the given user to perform an action."""
+
+
+class PermissionSystem(Component):
+    """Sub-system that manages user permissions."""
+
+    implements(IPermissionRequestor)
+
+    requestors = ExtensionPoint(IPermissionRequestor)
+    store = SingletonExtensionPoint(IPermissionStore,
+                                    'trac', 'permission_store')
+
+    # Public API
+
+    def grant_permission(self, username, action):
+        """Grant the user with the given name permission to perform to specified
+        action."""
+        if action.isupper() and action not in self.get_actions():
+            raise TracError, '%s is not a valid action.' % action
+
+        self.store.grant_permission(username, action)
+
+    def revoke_permission(self, username, action):
+        """Revokes the permission of the specified user to perform an action."""
+        # TODO: Validate that this permission does in fact exist
+        if action.isupper() and action not in self.get_actions():
+            raise TracError, '%s is not a valid action.' % action
+
+        self.store.revoke_permission(username, action)
+
+    def get_actions(self):
+        actions = []
+        for requestor in self.requestors:
+            for action in requestor.get_permission_actions():
+                if isinstance(action, tuple):
+                    actions.append(action[0])
+                else:
+                    actions.append(action)
+        return actions
+
+    def get_user_permissions(self, username=None):
+        """Return the permissions of the specified user.
+        
+        The return value is a dictionary containing all the actions as keys, and
+        a boolean value. `True` means that the permission is granted, `False`
+        means the permission is denied."""
+        actions = []
+        for requestor in self.requestors:
+            actions += list(requestor.get_permission_actions())
+        permissions = {}
+        if username:
+            # Return all permissions that the given user has
+            meta = {}
+            for action in actions:
+                if isinstance(action, tuple):
+                    name, value = action
+                    meta[name] = value
+            def _expand_meta(action):
+                permissions[action] = True
+                if meta.has_key(action):
+                    [_expand_meta(perm) for perm in meta[action]]
+            for perm in self.store.get_user_permissions(username):
+                _expand_meta(perm)
+        else:
+            # Return all permissions available in the system
+            for action in actions:
+                if isinstance(action, tuple):
+                    permissions[action[0]] = True
+                else:
+                    permissions[action] = True
+        return permissions
+
+    def get_all_permissions(self):
+        """Return all permissions for all users.
+
+        The permissions are returned as a list of (subject, action)
+        formatted tuples."""
+        return self.store.get_all_permissions()
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        """Implement the global `TRAC_ADMIN` meta permission."""
+        actions = []
+        for requestor in [r for r in self.requestors if r is not self]:
+            for action in requestor.get_permission_actions():
+                if isinstance(action, tuple):
+                    actions.append(action[0])
+                else:
+                    actions.append(action)
+        return [('TRAC_ADMIN', actions)]
+
+
+class IPermissionGroupProvider(Interface):
+    """
+    Extension point interface for components that provide information about user
+    groups.
+    """
+
+    def get_permission_groups(username):
+        """Return a list of names of the groups that the user with the specified
+        name is a member of."""
+
+
+class DefaultPermissionStore(Component):
+    """Default implementation of permission storage and simple group management.
+    
+    This component uses the `PERMISSION` table in the database to store both
+    permissions and groups.
+    """
+    implements(IPermissionStore)
+
+    group_providers = ExtensionPoint(IPermissionGroupProvider)
+
+    def get_user_permissions(self, username):
+        """Retrieve the permissions for the given user and return them in a
+        dictionary.
+        
+        The permissions are stored in the database as (username, action)
+        records. There's simple support for groups by using lowercase names for
+        the action column: such a record represents a group and not an actual
+        permission, and declares that the user is part of that group.
+        """
+        subjects = [username]
+        for provider in self.group_providers:
+            subjects += list(provider.get_permission_groups(username))
+
+        actions = []
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT username,action FROM permission")
+        rows = cursor.fetchall()
+        while True:
+            num_users = len(subjects)
+            num_actions = len(actions)
+            for user, action in rows:
+                if user in subjects:
+                    if not action.islower() and action not in actions:
+                        actions.append(action)
+                    if action.islower() and action not in subjects:
+                        # action is actually the name of the permission group
+                        # here
+                        subjects.append(action)
+            if num_users == len(subjects) and num_actions == len(actions):
+                break
+        return [action for action in actions if not action.islower()]
+
+    def get_all_permissions(self):
+        """Return all permissions for all users.
+
+        The permissions are returned as a list of (subject, action)
+        formatted tuples."""
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT username,action FROM permission")
+        return [(row[0], row[1]) for row in cursor]
+
+    def grant_permission(self, username, action):
+        """Grants a user the permission to perform the specified action."""
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("INSERT INTO permission VALUES (%s, %s)",
+                       (username, action))
+        self.log.info('Granted permission for %s to %s' % (action, username))
+        db.commit()
+
+    def revoke_permission(self, username, action):
+        """Revokes a users' permission to perform the specified action."""
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("DELETE FROM permission WHERE username=%s AND action=%s",
+                       (username, action))
+        self.log.info('Revoked permission for %s to %s' % (action, username))
+        db.commit()
+
+
+class DefaultPermissionGroupProvider(Component):
+    """Provides the basic builtin permission groups 'anonymous' and
+    'authenticated'."""
+
+    implements(IPermissionGroupProvider)
+
+    def get_permission_groups(self, username):
+        groups = ['anonymous']
+        if username and username != 'anonymous':
+            groups.append('authenticated')
+        return groups
+
+
+class PermissionCache:
+    """Cache that maintains the permissions of a single user."""
+
+    def __init__(self, env, username):
+        self.perms = PermissionSystem(env).get_user_permissions(username)
+
+    def has_permission(self, action):
+        return self.perms.has_key(action)
+
+    def assert_permission(self, action):
+        if not self.perms.has_key(action):
+            raise PermissionError(action)
+
+    def permissions(self):
+        return self.perms.keys()
diff -urN trac-trunk/build/lib/trac/scripts/admin.py aw-trac/build/lib/trac/scripts/admin.py
--- trac-trunk/build/lib/trac/scripts/admin.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/scripts/admin.py	2006-02-24 09:26:13.000000000 -0800
@@ -0,0 +1,1152 @@
+# -*- coding: iso-8859-1 -*-
+# 
+# Copyright (C) 2003-2006 Edgewall Software
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+
+__copyright__ = 'Copyright (c) 2003-2006 Edgewall Software'
+
+import cmd
+import getpass
+import os
+import shlex
+import shutil
+import StringIO
+import sys
+import time
+import traceback
+import urllib
+
+import trac
+from trac import perm, util, db_default
+from trac.config import default_dir, Configuration
+from trac.env import Environment
+from trac.perm import PermissionSystem
+from trac.ticket.model import *
+from trac.wiki import WikiPage
+
+def copytree(src, dst, symlinks=False, skip=[]):
+    """Recursively copy a directory tree using copy2() (from shutil.copytree.)
+
+    Added a `skip` parameter consisting of absolute paths
+    which we don't want to copy.
+    """
+    names = os.listdir(src)
+    os.mkdir(dst)
+    errors = []
+    for name in names:
+        srcname = os.path.join(src, name)
+        if srcname in skip:
+            continue
+        dstname = os.path.join(dst, name)
+        try:
+            if symlinks and os.path.islink(srcname):
+                linkto = os.readlink(srcname)
+                os.symlink(linkto, dstname)
+            elif os.path.isdir(srcname):
+                copytree(srcname, dstname, symlinks, skip)
+            else:
+                shutil.copy2(srcname, dstname)
+            # XXX What about devices, sockets etc.?
+        except (IOError, os.error), why:
+            errors.append((srcname, dstname, why))
+    if errors:
+        raise shutil.Error, errors
+
+
+class TracAdmin(cmd.Cmd):
+    intro = ''
+    license = trac.__license_long__
+    doc_header = 'Trac Admin Console %(ver)s\n' \
+                 'Available Commands:\n' \
+                 % {'ver':trac.__version__ }
+    ruler = ''
+    prompt = "Trac> "
+    __env = None
+    _date_format = '%Y-%m-%d'
+    _datetime_format = '%Y-%m-%d %H:%M:%S'
+    _date_format_hint = 'YYYY-MM-DD'
+
+    def __init__(self, envdir=None):
+        cmd.Cmd.__init__(self)
+        self.interactive = False
+        if envdir:
+            self.env_set(os.path.abspath(envdir))
+        self._permsys = None
+
+    def emptyline(self):
+        pass
+
+    def onecmd(self, line):
+        try:
+            rv = cmd.Cmd.onecmd(self, line) or 0
+        except SystemExit:
+            raise
+        except Exception, e:
+            print>>sys.stderr, 'Command failed: %s' % e
+            rv = 2
+        if not self.interactive:
+            return rv
+
+    def run(self):
+        self.interactive = True
+        print 'Welcome to trac-admin %(ver)s\n'                \
+              'Interactive Trac administration console.\n'       \
+              '%(copy)s\n\n'                                    \
+              "Type:  '?' or 'help' for help on commands.\n" %  \
+              {'ver':trac.__version__,'copy':__copyright__}
+        self.cmdloop()
+
+    ##
+    ## Environment methods
+    ##
+
+    def env_set(self, envname, env=None):
+        self.envname = envname
+        self.prompt = "Trac [%s]> " % self.envname
+        if env is not None:
+            self.__env = env
+
+    def env_check(self):
+        try:
+            self.__env = Environment(self.envname)
+        except:
+            return 0
+        return 1
+
+    def env_open(self):
+        try:
+            if not self.__env:
+                self.__env = Environment(self.envname)
+            return self.__env
+        except Exception, e:
+            print 'Failed to open environment.', e
+            traceback.print_exc()
+            sys.exit(1)
+
+    def db_open(self):
+        return self.env_open().get_db_cnx()
+
+    def db_query(self, sql, cursor=None, params=None):
+        if not cursor:
+            cnx = self.db_open()
+            cursor = cnx.cursor()
+        if params:
+            cursor.execute(sql, params)
+        else:
+            cursor.execute(sql)
+        for row in cursor:
+            yield row
+
+    def db_update(self, sql, cursor=None, params=None):
+        if not cursor:
+            cnx = self.db_open()
+            cursor = cnx.cursor()
+        else:
+            cnx = None
+        if params:
+            cursor.execute(sql, params)
+        else:
+            cursor.execute(sql)
+        if cnx:
+            cnx.commit()
+
+    ##
+    ## Utility methods
+    ##
+
+    def arg_tokenize (self, argstr):
+        argstr = util.to_utf8(argstr, sys.stdin.encoding)
+        return shlex.split(argstr) or ['']
+
+    def word_complete (self, text, words):
+        return [a for a in words if a.startswith (text)]
+
+    def print_listing(self, headers, data, sep=' ', decor=True):
+        ldata = list(data)
+        if decor:
+            ldata.insert(0, headers)
+        print
+        colw = []
+        ncols = len(ldata[0]) # assumes all rows are of equal length
+        for cnum in xrange(0, ncols):
+            mw = 0
+            for cell in [str(d[cnum]) or '' for d in ldata]:
+                if len(cell) > mw:
+                    mw = len(cell)
+            colw.append(mw)
+        for rnum in xrange(len(ldata)):
+            for cnum in xrange(ncols):
+                if decor and rnum == 0:
+                    sp = ('%%%ds' % len(sep)) % ' '  # No separator in header
+                else:
+                    sp = sep
+                if cnum + 1 == ncols:
+                    sp = '' # No separator after last column
+                print ('%%-%ds%s' % (colw[cnum], sp)) \
+                      % (ldata[rnum][cnum] or ''),
+            print
+            if rnum == 0 and decor:
+                print ''.join(['-' for x in
+                               xrange(0, (1 + len(sep)) * cnum + sum(colw))])
+        print
+
+    def print_doc(self, doc, decor=False):
+        if not doc: return
+        self.print_listing(['Command', 'Description'], doc, '  --', decor) 
+
+    def get_component_list(self):
+        rows = self.db_query("SELECT name FROM component")
+        return [row[0] for row in rows]
+
+    def get_user_list(self):
+        rows = self.db_query("SELECT DISTINCT username FROM permission")
+        return [row[0] for row in rows]
+
+    def get_wiki_list(self):
+        rows = self.db_query('SELECT DISTINCT name FROM wiki') 
+        return [row[0] for row in rows]
+
+    def get_dir_list(self, pathstr, justdirs=False):
+        dname = os.path.dirname(pathstr)
+        d = os.path.join(os.getcwd(), dname)
+        dlist = os.listdir(d)
+        if justdirs:
+            result = []
+            for entry in dlist:
+                try:
+                    if os.path.isdir(entry):
+                        result.append(entry)
+                except:
+                    pass
+        else:
+            result = dlist
+        return result
+
+    def get_enum_list(self, type):
+        rows = self.db_query("SELECT name FROM enum WHERE type=%s",
+                             params=[type])
+        return [row[0] for row in rows]
+
+    def get_milestone_list(self):
+        rows = self.db_query("SELECT name FROM milestone")
+        return [row[0] for row in rows]
+
+    def get_version_list(self):
+        rows = self.db_query("SELECT name FROM version")
+        return [row[0] for row in rows]
+
+    def _parse_date(self, t):
+        seconds = None
+        t = t.strip()
+        if t == 'now':
+            seconds = int(time.time())
+        else:
+            for format in [self._date_format, '%x %X', '%x, %X', '%X %x',
+                           '%X, %x', '%x', '%c', '%b %d, %Y']:
+                try:
+                    pt = time.strptime(t, format)
+                    seconds = int(time.mktime(pt))
+                except ValueError:
+                    continue
+                break
+        if seconds == None:
+            try:
+                seconds = int(t)
+            except ValueError:
+                pass
+        if seconds == None:
+            print>>sys.stderr, 'Unknown time format %s' % t
+        return seconds
+
+    def _format_date(self, s):
+        return time.strftime(self._date_format, time.localtime(s))
+
+    def _format_datetime(self, s):
+        return time.strftime(self._datetime_format, time.localtime(s))
+
+
+    ##
+    ## Available Commands
+    ##
+
+    ## Help
+    _help_help = [('help', 'Show documentation')]
+
+    def do_help(self, line=None):
+        arg = self.arg_tokenize(line)
+        if arg[0]:
+            try:
+                doc = getattr(self, "_help_" + arg[0])
+                self.print_doc (doc)
+            except AttributeError:
+                print "No documentation found for '%s'" % arg[0]
+        else:
+            docs = (self._help_about + self._help_help +
+                    self._help_initenv + self._help_hotcopy +
+                    self._help_resync + self._help_upgrade +
+                    self._help_wiki +
+#                    self._help_config + self._help_wiki +
+                    self._help_permission + self._help_component +
+                    self._help_ticket +
+                    self._help_ticket_type + self._help_priority +
+                    self._help_severity +  self._help_version +
+                    self._help_milestone)
+            print 'trac-admin - The Trac Administration Console %s' \
+                  % trac.__version__
+            if not self.interactive:
+                print
+                print "Usage: trac-admin </path/to/projenv> [command [subcommand] [option ...]]\n"
+                print "Invoking trac-admin without command starts "\
+                      "interactive mode."
+            self.print_doc (docs)
+
+    
+    ## About / Version
+    _help_about = [('about', 'Shows information about trac-admin')]
+
+    def do_about(self, line):
+        print
+        print 'Trac Admin Console %s' % trac.__version__
+        print '================================================================='
+        print self.license
+
+
+    ## Quit / EOF
+    _help_quit = [['quit', 'Exit the program']]
+    _help_exit = _help_quit
+    _help_EOF = _help_quit
+
+    def do_quit(self, line):
+        print
+        sys.exit()
+
+    do_exit = do_quit # Alias
+    do_EOF = do_quit # Alias
+
+
+    # Component
+    _help_component = [('component list', 'Show available components'),
+                       ('component add <name> <owner>', 'Add a new component'),
+                       ('component rename <name> <newname>',
+                        'Rename a component'),
+                       ('component remove <name>',
+                        'Remove/uninstall component'),
+                       ('component chown <name> <owner>',
+                        'Change component ownership')]
+
+    def complete_component(self, text, line, begidx, endidx):
+        if begidx in (16, 17):
+            comp = self.get_component_list()
+        elif begidx > 15 and line.startswith('component chown '):
+            comp = self.get_user_list()
+        else:
+            comp = ['list', 'add', 'rename', 'remove', 'chown']
+        return self.word_complete(text, comp)
+
+    def do_component(self, line):
+        arg = self.arg_tokenize(line)
+        if arg[0]  == 'list':
+            self._do_component_list()
+        elif arg[0] == 'add' and len(arg)==3:
+            name = arg[1]
+            owner = arg[2]
+            self._do_component_add(name, owner)
+        elif arg[0] == 'rename' and len(arg)==3:
+            name = arg[1]
+            newname = arg[2]
+            self._do_component_rename(name, newname)
+        elif arg[0] == 'remove'  and len(arg)==2:
+            name = arg[1]
+            self._do_component_remove(name)
+        elif arg[0] == 'chown' and len(arg)==3:
+            name = arg[1]
+            owner = arg[2]
+            self._do_component_set_owner(name, owner)
+        else:    
+            self.do_help ('component')
+
+    def _do_component_list(self):
+        data = []
+        for c in Component.select(self.env_open()):
+            data.append((c.name, c.owner))
+        self.print_listing(['Name', 'Owner'], data)
+
+    def _do_component_add(self, name, owner):
+        component = Component(self.env_open())
+        component.name = name
+        component.owner = owner
+        component.insert()
+
+    def _do_component_rename(self, name, newname):
+        component = Component(self.env_open(), name)
+        component.name = newname
+        component.update()
+
+    def _do_component_remove(self, name):
+        component = Component(self.env_open(), name)
+        component.delete()
+
+    def _do_component_set_owner(self, name, owner):
+        component = Component(self.env_open(), name)
+        component.owner = owner
+        component.update()
+
+
+    ## Permission
+    _help_permission = [('permission list [user]', 'List permission rules'),
+                        ('permission add <user> <action> [action] [...]',
+                         'Add a new permission rule'),
+                        ('permission remove <user> <action> [action] [...]',
+                         'Remove permission rule')]
+
+    def complete_permission(self, text, line, begidx, endidx):
+        argv = self.arg_tokenize(line)
+        argc = len(argv)
+        if line[-1] == ' ': # Space starts new argument
+            argc += 1
+        if argc == 2:
+            comp = ['list', 'add', 'remove']
+        elif argc >= 4:
+            comp = perm.permissions + perm.meta_permissions.keys()
+            comp.sort()
+        return self.word_complete(text, comp)
+
+    def do_permission(self, line):
+        arg = self.arg_tokenize(line)
+        if arg[0]  == 'list':
+            user = None
+            if len(arg) > 1:
+                user = arg[1]
+            self._do_permission_list(user)
+        elif arg[0] == 'add' and len(arg) >= 3:
+            user = arg[1]
+            for action in arg[2:]:
+                self._do_permission_add(user, action)
+        elif arg[0] == 'remove'  and len(arg) >= 3:
+            user = arg[1]
+            for action in arg[2:]:
+                self._do_permission_remove(user, action)
+        else:
+            self.do_help('permission')
+
+    def _do_permission_list(self, user=None):
+        if not self._permsys:
+            self._permsys = PermissionSystem(self.env_open())
+        if user:
+            rows = []
+            perms = self._permsys.get_user_permissions(user)
+            for action in perms:
+                if perms[action]:
+                    rows.append((action, user))
+        else:
+            rows = self._permsys.get_all_permissions()
+        rows.sort()
+        self.print_listing(['User', 'Action'], rows)
+        print
+        print 'Available actions:'
+        actions = self._permsys.get_actions()
+        actions.sort()
+        text = ', '.join(actions)
+        print util.wrap(text, initial_indent=' ', subsequent_indent=' ',
+                        linesep='\n')
+        print
+
+    def _do_permission_add(self, user, action):
+        if not self._permsys:
+            self._permsys = PermissionSystem(self.env_open())
+        if not action.islower() and not action.isupper():
+            print 'Group names must be in lower case and actions in upper case'
+            return
+        self._permsys.grant_permission(user, action)
+
+    def _do_permission_remove(self, user, action):
+        if not self._permsys:
+            self._permsys = PermissionSystem(self.env_open())
+        rows = self._permsys.get_all_permissions()
+        if action == '*':
+            for row in rows:
+                if user != '*' and user != row[0]:
+                    continue
+                self._permsys.revoke_permission(row[0], row[1])
+        else:
+            for row in rows:
+                if action != row[1]:
+                    continue
+                if user != '*' and user != row[0]:
+                    continue
+                self._permsys.revoke_permission(row[0], row[1])
+
+    ## Initenv
+    _help_initenv = [('initenv',
+                      'Create and initialize a new environment interactively'),
+                     ('initenv <projectname> <db> <repostype> <repospath> <templatepath>',
+                      'Create and initialize a new environment from arguments')]
+
+    def do_initdb(self, line):
+        self.do_initenv(line)
+
+    def get_initenv_args(self):
+        returnvals = []
+        print 'Creating a new Trac environment at %s' % self.envname
+        print
+        print 'Trac will first ask a few questions about your environment '
+        print 'in order to initalize and prepare the project database.'
+        print
+        print " Please enter the name of your project."
+        print " This name will be used in page titles and descriptions."
+        print
+        dp = 'My Project'
+        returnvals.append(raw_input('Project Name [%s]> ' % dp).strip() or dp)
+        print
+        print ' Please specify the connection string for the database to use.'
+        print ' By default, a local SQLite database is created in the environment '
+        print ' directory. It is also possible to use an already existing '
+        print ' PostgreSQL database (check the Trac documentation for the exact '
+        print ' connection string syntax).'
+        print
+        ddb = 'sqlite:db/trac.db'
+        prompt = 'Database connection string [%s]> ' % ddb
+        returnvals.append(raw_input(prompt).strip() or ddb)
+        print
+        print ' Please specify the type of version control system,'
+        print ' By default, it will be svn.'
+        print
+        print ' If you don\'t want to use Trac with version control integration, '
+        print ' choose the default here and don\'t specify a repository directory. '
+        print ' in the next question.'
+        print 
+        drpt = 'svn'
+        prompt = 'Repository type [%s]> ' % drpt
+        returnvals.append(raw_input(prompt).strip() or drpt)
+        print
+        print ' Please specify the absolute path to the version control '
+        print ' repository, or leave it blank to use Trac without a repository.'
+        print ' You can also set the repository location later.'
+        print 
+        prompt = 'Path to repository [/path/to/repos]> '
+        returnvals.append(raw_input(prompt).strip())
+        print
+        print ' Please enter location of Trac page templates.'
+        print ' Default is the location of the site-wide templates installed with Trac.'
+        print
+        dt = default_dir('templates')
+        prompt = 'Templates directory [%s]> ' % dt
+        returnvals.append(raw_input(prompt).strip() or dt)
+        print
+        return returnvals
+
+    def do_initenv(self, line):
+        if self.env_check():
+            print "Initenv for '%s' failed." % self.envname
+            print "Does an environment already exist?"
+            return 2
+
+        arg = self.arg_tokenize(line)
+        project_name = None
+        db_str = None
+        repository_dir = None
+        templates_dir = None
+        if len(arg) == 1 and not arg[0]:
+            returnvals = self.get_initenv_args()
+            project_name, db_str, repository_type, repository_dir, \
+                          templates_dir = returnvals
+        elif len(arg) != 5:
+            print 'Wrong number of arguments to initenv: %d' % len(arg)
+            return 2
+        else:
+            project_name, db_str, repository_type, repository_dir, \
+                          templates_dir = arg[:5]
+
+        if not os.access(os.path.join(templates_dir, 'header.cs'), os.F_OK):
+            print templates_dir, "doesn't look like a Trac templates directory"
+            return 2
+
+        try:
+            print 'Creating and Initializing Project'
+            options = [
+                ('trac', 'database', db_str),
+                ('trac', 'repository_type', repository_type),
+                ('trac', 'repository_dir', repository_dir),
+                ('trac', 'templates_dir', templates_dir),
+                ('project', 'name', project_name)
+            ]
+            try:
+                self.__env = Environment(self.envname, create=True,
+                                         options=options)
+            except Exception, e:
+                print 'Failed to create environment.', e
+                traceback.print_exc()
+                sys.exit(1)
+
+            # Add a few default wiki pages
+            print ' Installing default wiki pages'
+            cnx = self.__env.get_db_cnx()
+            cursor = cnx.cursor()
+            self._do_wiki_load(default_dir('wiki'), cursor)
+            cnx.commit()
+
+            if repository_dir:
+                try:
+                    repos = self.__env.get_repository()
+                    if repos:
+                        print ' Indexing repository'
+                        repos.sync()
+                except util.TracError, e:
+                    print>>sys.stderr, "\nWarning:\n"
+                    if repository_type == "svn":
+                        print>>sys.stderr, "You should install the SVN bindings"
+                    else:
+                        print>>sys.stderr, ("You should install the plugin for"
+                                            " %s in the %s folder." \
+                                            % (repository_type,
+                                               os.path.join(self.envname,
+                                                            'plugins')))
+        except Exception, e:
+            print 'Failed to initialize environment.', e
+            traceback.print_exc()
+            return 2
+
+        print """
+---------------------------------------------------------------------
+Project environment for '%(project_name)s' created.
+
+You may now configure the environment by editing the file:
+
+  %(config_path)s
+
+If you'd like to take this new project environment for a test drive,
+try running the Trac standalone web server `tracd`:
+
+  tracd --port 8000 %(project_path)s
+
+Then point your browser to http://localhost:8000/%(project_dir)s.
+There you can also browse the documentation for your installed
+version of Trac, including information on further setup (such as
+deploying Trac to a real web server).
+
+The latest documentation can also always be found on the project
+website:
+
+  http://projects.edgewall.com/trac/
+
+Congratulations!
+""" % dict(project_name=project_name, project_path=self.envname,
+           project_dir=os.path.basename(self.envname),
+           config_path=os.path.join(self.envname, 'conf', 'trac.ini'))
+
+    _help_resync = [('resync', 'Re-synchronize trac with the repository')]
+
+    ## Resync
+    def do_resync(self, line):
+        print 'Resyncing repository history...'
+        cnx = self.db_open()
+        cursor = cnx.cursor()
+        cursor.execute("DELETE FROM revision")
+        cursor.execute("DELETE FROM node_change")
+        repos = self.__env.get_repository()
+        cursor.execute("DELETE FROM system WHERE name='repository_dir'")
+        cursor.execute("INSERT INTO system (name,value) "
+                       "VALUES ('repository_dir',%s)", (repos.name,))
+        repos.sync()
+        print 'Done.'
+
+    ## Wiki
+    _help_wiki = [('wiki list', 'List wiki pages'),
+                  ('wiki remove <name>', 'Remove wiki page'),
+                  ('wiki export <page> [file]',
+                   'Export wiki page to file or stdout'),
+                  ('wiki import <page> [file]',
+                   'Import wiki page from file or stdin'),
+                  ('wiki dump <directory>',
+                   'Export all wiki pages to files named by title'),
+                  ('wiki load <directory>',
+                   'Import all wiki pages from directory'),
+                  ('wiki upgrade',
+                   'Upgrade default wiki pages to current version')]
+
+    def complete_wiki(self, text, line, begidx, endidx):
+        argv = self.arg_tokenize(line)
+        argc = len(argv)
+        if line[-1] == ' ': # Space starts new argument
+            argc += 1
+        if argc == 2:
+            comp = ['list', 'remove', 'import', 'export', 'dump', 'load',
+                    'upgrade']
+        else:
+            if argv[1] in ('dump', 'load'):
+                comp = self.get_dir_list(argv[-1], 1)
+            elif argv[1] == 'remove':
+                comp = self.get_wiki_list()
+            elif argv[1] in ('export', 'import'):
+                if argc == 3:
+                    comp = self.get_wiki_list()
+                elif argc == 4:
+                    comp = self.get_dir_list(argv[-1])
+        return self.word_complete(text, comp)
+
+    def do_wiki(self, line):
+        arg = self.arg_tokenize(line)
+        if arg[0]  == 'list':
+            self._do_wiki_list()
+        elif arg[0] == 'remove'  and len(arg)==2:
+            name = arg[1]
+            self._do_wiki_remove(name)
+        elif arg[0] == 'import' and len(arg) == 3:
+            title = arg[1]
+            file = arg[2]
+            self._do_wiki_import(file, title)
+        elif arg[0] == 'export'  and len(arg) in [2,3]:
+            page = arg[1]
+            file = (len(arg) == 3 and arg[2]) or None
+            self._do_wiki_export(page, file)
+        elif arg[0] == 'dump' and len(arg) in [1,2]:
+            dir = (len(arg) == 2 and arg[1]) or ''
+            self._do_wiki_dump(dir)
+        elif arg[0] == 'load' and len(arg) in [1,2]:
+            dir = (len(arg) == 2 and arg[1]) or ''
+            self._do_wiki_load(dir)
+        elif arg[0] == 'upgrade' and len(arg) == 1:
+            self._do_wiki_load(default_dir('wiki'),
+                               ignore=['WikiStart', 'checkwiki.py'])
+        else:    
+            self.do_help ('wiki')
+
+    def _do_wiki_list(self):
+        rows = self.db_query("SELECT name, max(version), max(time) "
+                             "FROM wiki GROUP BY name ORDER BY name")
+        self.print_listing(['Title', 'Edits', 'Modified'],
+                           [(r[0], r[1], self._format_datetime(r[2])) for r in rows])
+
+    def _do_wiki_remove(self, name):
+        page = WikiPage(self.env_open(), name)
+        page.delete()
+
+    def _do_wiki_import(self, filename, title, cursor=None):
+        if not os.path.isfile(filename):
+            raise Exception, '%s is not a file' % filename
+
+        f = open(filename,'r')
+        data = util.to_utf8(f.read())
+
+        # Make sure we don't insert the exact same page twice
+        rows = self.db_query("SELECT text FROM wiki WHERE name=%s "
+                             "ORDER BY version DESC LIMIT 1", cursor,
+                             params=(title,))
+        old = list(rows)
+        if old and data == old[0][0]:
+            print '  %s already up to date.' % title
+            return
+        f.close()
+
+        self.db_update("INSERT INTO wiki(version,name,time,author,ipnr,text) "
+                       " SELECT 1+COALESCE(max(version),0),%s,%s,"
+                       " 'trac','127.0.0.1',%s FROM wiki "
+                       " WHERE name=%s",
+                       cursor, (title, int(time.time()), data, title))
+
+    def _do_wiki_export(self, page, filename=''):
+        data = self.db_query("SELECT text FROM wiki WHERE name=%s "
+                             "ORDER BY version DESC LIMIT 1", params=[page])
+        text = data.next()[0]
+        if not filename:
+            print text
+        else:
+            if os.path.isfile(filename):
+                raise Exception("File '%s' exists" % filename)
+            f = open(filename,'w')
+            f.write(text)
+            f.close()
+
+    def _do_wiki_dump(self, dir):
+        pages = self.get_wiki_list()
+        for p in pages:
+            dst = os.path.join(dir, urllib.quote(p, ''))
+            print " %s => %s" % (p, dst)
+            self._do_wiki_export(p, dst)
+
+    def _do_wiki_load(self, dir, cursor=None, ignore=[]):
+        for page in os.listdir(dir):
+            if page in ignore:
+                continue
+            filename = os.path.join(dir, page)
+            page = urllib.unquote(page)
+            if os.path.isfile(filename):
+                print " %s => %s" % (filename, page)
+                self._do_wiki_import(filename, page, cursor)
+
+    ## Ticket
+    _help_ticket = [('ticket remove <number>', 'Remove ticket')]
+
+    def complete_ticket(self, text, line, begidx, endidx):
+        argv = self.arg_tokenize(line)
+        argc = len(argv)
+        if line[-1] == ' ': # Space starts new argument
+            argc += 1
+        comp = []
+        if argc == 2:
+            comp = ['remove']
+        return self.word_complete(text, comp)
+
+    def do_ticket(self, line):
+        arg = self.arg_tokenize(line)
+        if arg[0] == 'remove'  and len(arg)==2:
+            try:
+                number = int(arg[1])
+            except ValueError:
+                print>>sys.stderr, "<number> must be a number"
+                return
+            self._do_ticket_remove(number)
+        else:    
+            self.do_help ('ticket')
+
+    def _do_ticket_remove(self, number):
+        ticket = Ticket(self.env_open(), number)
+        ticket.delete()
+        print "Ticket %d and all associated data removed." % number
+
+
+    ## (Ticket) Type
+    _help_ticket_type = [('ticket_type list', 'Show possible ticket types'),
+                         ('ticket_type add <value>', 'Add a ticket type'),
+                         ('ticket_type change <value> <newvalue>',
+                          'Change a ticket type'),
+                         ('ticket_type remove <value>', 'Remove a ticket type'),
+                         ('ticket_type order <value> up|down',
+                          'Move a ticket type up or down in the list')]
+
+    def complete_ticket_type (self, text, line, begidx, endidx):
+        if begidx == 16:
+            comp = self.get_enum_list ('ticket_type')
+        elif begidx < 15:
+            comp = ['list', 'add', 'change', 'remove', 'order']
+        return self.word_complete(text, comp)
+ 
+    def do_ticket_type(self, line):
+        self._do_enum('ticket_type', line)
+ 
+    ## (Ticket) Priority
+    _help_priority = [('priority list', 'Show possible ticket priorities'),
+                       ('priority add <value>', 'Add a priority value option'),
+                       ('priority change <value> <newvalue>',
+                        'Change a priority value'),
+                       ('priority remove <value>', 'Remove priority value'),
+                       ('priority order <value> up|down',
+                        'Move a priority value up or down in the list')]
+
+    def complete_priority (self, text, line, begidx, endidx):
+        if begidx == 16:
+            comp = self.get_enum_list ('priority')
+        elif begidx < 15:
+            comp = ['list', 'add', 'change', 'remove', 'order']
+        return self.word_complete(text, comp)
+
+    def do_priority(self, line):
+        self._do_enum('priority', line)
+
+    ## (Ticket) Severity
+    _help_severity = [('severity list', 'Show possible ticket severities'),
+                      ('severity add <value>', 'Add a severity value option'),
+                      ('severity change <value> <newvalue>',
+                       'Change a severity value'),
+                      ('severity remove <value>', 'Remove severity value'),
+                      ('severity order <value> up|down',
+                       'Move a severity value up or down in the list')]
+
+    def complete_severity (self, text, line, begidx, endidx):
+        if begidx == 16:
+            comp = self.get_enum_list ('severity')
+        elif begidx < 15:
+            comp = ['list', 'add', 'change', 'remove', 'order']
+        return self.word_complete(text, comp)
+
+    def do_severity(self, line):
+        self._do_enum('severity', line)
+
+    # Type, priority, severity share the same datastructure and methods:
+
+    _enum_map = {'ticket_type': Type, 'priority': Priority,
+                 'severity': Severity}
+
+    def _do_enum(self, type, line):
+        arg = self.arg_tokenize(line)
+        if arg[0]  == 'list':
+            self._do_enum_list(type)
+        elif arg[0] == 'add' and len(arg) == 2:
+            name = arg[1]
+            self._do_enum_add(type, name)
+        elif arg[0] == 'change' and len(arg) == 3:
+            name = arg[1]
+            newname = arg[2]
+            self._do_enum_change(type, name, newname)
+        elif arg[0] == 'remove' and len(arg) == 2:
+            name = arg[1]
+            self._do_enum_remove(type, name)
+        elif arg[0] == 'order' and len(arg) == 3 and arg[2] in ('up', 'down'):
+            name = arg[1]
+            if arg[2] == 'up':
+                direction = -1
+            else:
+                direction = 1
+            self._do_enum_order(type, name, direction)
+        else:    
+            self.do_help(type)
+
+    def _do_enum_list(self, type):
+        enum_cls = self._enum_map[type]
+        self.print_listing(['Possible Values'],
+                           [(e.name,) for e in enum_cls.select(self.env_open())])
+
+    def _do_enum_add(self, type, name):
+        cnx = self.db_open()
+        sql = ("INSERT INTO enum(value,type,name) "
+               " SELECT 1+COALESCE(max(%(cast)s),0),'%(type)s','%(name)s'"
+               "   FROM enum WHERE type='%(type)s'" 
+               % {'type':type, 'name':name, 'cast': cnx.cast('value', 'int')})
+        cursor = cnx.cursor()
+        self.db_update(sql, cursor)
+        cnx.commit()
+
+    def _do_enum_change(self, type, name, newname):
+        enum_cls = self._enum_map[type]
+        enum = enum_cls(self.env_open(), name)
+        enum.name = newname
+        enum.update()
+
+    def _do_enum_remove(self, type, name):
+        enum_cls = self._enum_map[type]
+        enum = enum_cls(self.env_open(), name)
+        enum.delete()
+
+    def _do_enum_order(self, type, name, direction):
+        env = self.env_open()
+        enum_cls = self._enum_map[type]
+        enum1 = enum_cls(env, name)
+        enum1.value = int(float(enum1.value) + direction)
+        for enum2 in enum_cls.select(env):
+            if int(float(enum2.value)) == enum1.value:
+                enum2.value = int(float(enum2.value) - direction)
+                break
+        else:
+            return
+        enum1.update()
+        enum2.update()
+
+    ## Milestone
+
+    _help_milestone = [('milestone list', 'Show milestones'),
+                       ('milestone add <name> [due]', 'Add milestone'),
+                       ('milestone rename <name> <newname>',
+                        'Rename milestone'),
+                       ('milestone due <name> <due>',
+                        'Set milestone due date (Format: "%s" or "now")'
+                        % _date_format_hint),
+                       ('milestone completed <name> <completed>',
+                        'Set milestone completed date (Format: "%s" or "now")'
+                        % _date_format_hint),
+                       ('milestone remove <name>', 'Remove milestone')]
+
+    def complete_milestone (self, text, line, begidx, endidx):
+        if begidx in (15, 17):
+            comp = self.get_milestone_list()
+        elif begidx < 15:
+            comp = ['list', 'add', 'rename', 'time', 'remove']
+        return self.word_complete(text, comp)
+
+    def do_milestone(self, line):
+        arg = self.arg_tokenize(line)
+        if arg[0]  == 'list':
+            self._do_milestone_list()
+        elif arg[0] == 'add' and len(arg) in [2,3]:
+            self._do_milestone_add(arg[1])
+            if len(arg) == 3:
+                self._do_milestone_set_due(arg[1], arg[2])
+        elif arg[0] == 'rename' and len(arg) == 3:
+            self._do_milestone_rename(arg[1], arg[2])
+        elif arg[0] == 'remove' and len(arg) == 2:
+            self._do_milestone_remove(arg[1])
+        elif arg[0] == 'due' and len(arg) == 3:
+            self._do_milestone_set_due(arg[1], arg[2])
+        elif arg[0] == 'completed' and len(arg) == 3:
+            self._do_milestone_set_completed(arg[1], arg[2])
+        else:
+            self.do_help('milestone')
+
+    def _do_milestone_list(self):
+        data = []
+        for m in Milestone.select(self.env_open()):
+            data.append((m.name, m.due and self._format_date(m.due),
+                         m.completed and self._format_datetime(m.completed)))
+
+        self.print_listing(['Name', 'Due', 'Completed'], data)
+
+    def _do_milestone_rename(self, name, newname):
+        milestone = Milestone(self.env_open(), name)
+        milestone.name = newname
+        milestone.update()
+
+    def _do_milestone_add(self, name):
+        milestone = Milestone(self.env_open())
+        milestone.name = name
+        milestone.insert()
+
+    def _do_milestone_remove(self, name):
+        milestone = Milestone(self.env_open(), name)
+        milestone.delete(author=getpass.getuser())
+
+    def _do_milestone_set_due(self, name, t):
+        milestone = Milestone(self.env_open(), name)
+        milestone.due = self._parse_date(t)
+        milestone.update()
+
+    def _do_milestone_set_completed(self, name, t):
+        milestone = Milestone(self.env_open(), name)
+        milestone.completed = self._parse_date(t)
+        milestone.update()
+
+    ## Version
+    _help_version = [('version list', 'Show versions'),
+                       ('version add <name> [time]', 'Add version'),
+                       ('version rename <name> <newname>',
+                        'Rename version'),
+                       ('version time <name> <time>',
+                        'Set version date (Format: "%s" or "now")'
+                        % _date_format_hint),
+                       ('version remove <name>', 'Remove version')]
+
+    def complete_version (self, text, line, begidx, endidx):
+        if begidx in (13, 15):
+            comp = self.get_version_list()
+        elif begidx < 13:
+            comp = ['list', 'add', 'rename', 'time', 'remove']
+        return self.word_complete(text, comp)
+
+    def do_version(self, line):
+        arg = self.arg_tokenize(line)
+        if arg[0]  == 'list':
+            self._do_version_list()
+        elif arg[0] == 'add' and len(arg) in [2,3]:
+            self._do_version_add(arg[1])
+            if len(arg) == 3:
+                self._do_version_time(arg[1], arg[2])
+        elif arg[0] == 'rename' and len(arg) == 3:
+            self._do_version_rename(arg[1], arg[2])
+        elif arg[0] == 'time' and len(arg) == 3:
+            self._do_version_time(arg[1], arg[2])
+        elif arg[0] == 'remove' and len(arg) == 2:
+            self._do_version_remove(arg[1])
+        else:
+            self.do_help('version')
+
+    def _do_version_list(self):
+        data = []
+        for v in Version.select(self.env_open()):
+            data.append((v.name, v.time and self._format_date(v.time)))
+        self.print_listing(['Name', 'Time'], data)
+
+    def _do_version_rename(self, name, newname):
+        version = Version(self.env_open(), name)
+        version.name = newname
+        version.update()
+
+    def _do_version_add(self, name):
+        version = Version(self.env_open())
+        version.name = name
+        version.insert()
+
+    def _do_version_remove(self, name):
+        version = Version(self.env_open(), name)
+        version.delete()
+
+    def _do_version_time(self, name, t):
+        version = Version(self.env_open(), name)
+        version.time = self._parse_date(t)
+        version.update()
+
+    _help_upgrade = [('upgrade', 'Upgrade database to current version')]
+    def do_upgrade(self, line):
+        arg = self.arg_tokenize(line)
+        do_backup = True
+        if arg[0] in ['-b', '--no-backup']:
+            do_backup = False
+        self.db_open()
+        self._update_sample_config()
+
+        if not self.__env.needs_upgrade():
+            print "Database is up to date, no upgrade necessary."
+            return
+
+        self.__env.upgrade(backup=do_backup)
+        print 'Upgrade done.'
+
+    def _update_sample_config(self):
+        filename = os.path.join(self.__env.path, 'conf', 'trac.ini.sample')
+        try:
+            file(filename, 'w').close() # Create the config file
+            config = Configuration(filename)
+            for section, name, value in db_default.default_config:
+                config.set(section, name, value)
+            config.save()
+        except IOError, e:
+            print "Warning: couldn't write sample configuration file (%s)" % e
+
+    _help_hotcopy = [('hotcopy <backupdir>',
+                      'Make a hot backup copy of an environment')]
+    def do_hotcopy(self, line):
+        arg = self.arg_tokenize(line)
+        if arg[0]:
+            dest = arg[0]
+        else:
+            self.do_help('hotcopy')
+            return
+
+        # Bogus statement to lock the database while copying files
+        cnx = self.db_open()
+        cursor = cnx.cursor()
+        cursor.execute("UPDATE system SET name=NULL WHERE name IS NULL")
+
+        try:
+            print 'Hotcopying %s to %s ...' % (self.__env.path, dest),
+            db_str = self.__env.config.get('trac', 'database')
+            prefix, db_path = db_str.split(':', 1)
+            if prefix == 'sqlite':
+                # don't copy the journal (also, this would fail on Windows)
+                db_path = os.path.normpath(db_path)
+                skip = ['%s-journal' % os.path.join(self.__env.path, db_path)]
+            else:
+                skip = []
+            copytree(self.__env.path, dest, symlinks=1, skip=skip)
+        finally:
+            # Unlock database
+            cnx.rollback()
+
+        print 'Hotcopy done.'
+
+
+def run(args):
+    """Main entry point."""
+    admin = TracAdmin()
+    if len(args) > 0:
+        if args[0] in ('-h', '--help', 'help'):
+            return admin.onecmd("help")
+        elif args[0] in ('-v','--version','about'):
+            return admin.onecmd("about")
+        else:
+            admin.env_set(os.path.abspath(args[0]))
+            if len(args) > 1:
+                s_args = ' '.join(["'%s'" % c for c in args[2:]])
+                command = args[1] + ' ' +s_args
+                return admin.onecmd(command)
+            else:
+                while True:
+                    admin.run()
+    else:
+        return admin.onecmd("help")
diff -urN trac-trunk/build/lib/trac/siteconfig.py aw-trac/build/lib/trac/siteconfig.py
--- trac-trunk/build/lib/trac/siteconfig.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/siteconfig.py	2006-03-08 16:15:06.000000000 -0800
@@ -0,0 +1,10 @@
+
+# PLEASE DO NOT EDIT THIS FILE!
+# This file was autogenerated when installing Trac 0.10dev.
+#
+__default_conf_dir__ = '/usr/share/trac/conf'
+__default_templates_dir__ = '/usr/share/trac/templates'
+__default_htdocs_dir__ = '/usr/share/trac/htdocs'
+__default_wiki_dir__ = '/usr/share/trac/wiki-default'
+__default_macros_dir__ = '/usr/share/trac/wiki-macros'
+
diff -urN trac-trunk/build/lib/trac/test.py aw-trac/build/lib/trac/test.py
--- trac-trunk/build/lib/trac/test.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/test.py	2006-02-18 16:42:16.000000000 -0800
@@ -0,0 +1,196 @@
+#!/usr/bin/env python
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import unittest
+
+from trac.core import ComponentManager
+from trac.db.sqlite_backend import SQLiteConnection
+
+
+def Mock(bases=(), *initargs, **kw):
+    """
+    Simple factory for dummy classes that can be used as replacement for the 
+    real implementation in tests.
+    
+    Base classes for the mock can be specified using the first parameter, which
+    must be either a tuple of class objects or a single class object. If the
+    bases parameter is omitted, the base class of the mock will be object.
+
+    So to create a mock that is derived from the builtin dict type, you can do:
+
+    >>> mock = Mock(dict)
+    >>> mock['foo'] = 'bar'
+    >>> mock['foo']
+    'bar'
+
+    Attributes of the class are provided by any additional keyword parameters.
+
+    >>> mock = Mock(foo='bar')
+    >>> mock.foo
+    'bar'
+
+    Objects produces by this function have the special feature of not requiring
+    the 'self' parameter on methods, because you should keep data at the scope
+    of the test function. So you can just do:
+
+    >>> mock = Mock(add=lambda x,y: x+y)
+    >>> mock.add(1, 1)
+    2
+
+    To access attributes from the mock object from inside a lambda function,
+    just access the mock itself:
+
+    >>> mock = Mock(dict, do=lambda x: 'going to the %s' % mock[x])
+    >>> mock['foo'] = 'bar'
+    >>> mock.do('foo')
+    'going to the bar'
+
+    Because assignments or other types of statements don't work in lambda
+    functions, assigning to a local variable from a mock function requires some
+    extra work:
+
+    >>> myvar = [None]
+    >>> mock = Mock(set=lambda x: myvar.__setitem__(0, x))
+    >>> mock.set(1)
+    >>> myvar[0]
+    1
+    """
+    if not isinstance(bases, tuple):
+        bases = (bases,)
+    cls = type('Mock', bases, {})
+    mock = cls(*initargs)
+    for k,v in kw.items():
+        setattr(mock, k, v)
+    return mock
+
+
+class TestSetup(unittest.TestSuite):
+    """
+    Test suite decorator that allows a fixture to be setup for a complete
+    suite of test cases.
+    """
+    def setUp(self):
+        pass
+
+    def tearDown(self):
+        pass
+
+    def __call__(self, result):
+        self.setUp()
+        unittest.TestSuite.__call__(self, result)
+        self.tearDown()
+        return result
+
+
+class InMemoryDatabase(SQLiteConnection):
+    """
+    DB-API connection object for an SQLite in-memory database, containing all
+    the default Trac tables but no data.
+    """
+    def __init__(self):
+        SQLiteConnection.__init__(self, ':memory:')
+        cursor = self.cnx.cursor()
+
+        from trac.db_default import schema
+        from trac.db.sqlite_backend import _to_sql
+        for table in schema:
+            for stmt in _to_sql(table):
+                cursor.execute(stmt)
+
+        self.cnx.commit()
+
+
+class EnvironmentStub(ComponentManager):
+    """A stub of the trac.env.Environment object for testing."""
+
+    def __init__(self, default_data=False, enable=None):
+        ComponentManager.__init__(self)
+        self.enabled_components = enable
+        self.db = InMemoryDatabase()
+
+        from trac.config import Configuration
+        self.config = Configuration(None)
+
+        from trac.log import logger_factory
+        self.log = logger_factory('test')
+
+        from trac.web.href import Href
+        self.href = Href('/trac.cgi')
+        self.abs_href = Href('http://example.org/trac.cgi')
+
+        from trac import db_default
+        for section, name, value in db_default.default_config:
+            self.config.set(section, name, value)
+        if default_data:
+            cursor = self.db.cursor()
+            for table, cols, vals in db_default.data:
+                cursor.executemany("INSERT INTO %s (%s) VALUES (%s)"
+                                   % (table, ','.join(cols),
+                                      ','.join(['%s' for c in cols])),
+                                   vals)
+            self.db.commit()
+            
+        self.known_users = []
+
+    def component_activated(self, component):
+        component.env = self
+        component.config = self.config
+        component.log = self.log
+
+    def is_component_enabled(self, cls):
+        if self.enabled_components is None:
+            return True
+        return cls in self.enabled_components
+
+    def get_db_cnx(self):
+        return self.db
+
+    def get_templates_dir(self):
+        return None
+
+    def get_known_users(self, db):
+        return self.known_users
+
+
+def suite():
+    import trac.tests
+    import trac.db.tests
+    import trac.mimeview.tests
+    import trac.scripts.tests
+    import trac.ticket.tests
+    import trac.versioncontrol.tests
+    import trac.web.tests
+    import trac.wiki.tests
+
+    suite = unittest.TestSuite()
+    suite.addTest(trac.tests.suite())
+    suite.addTest(trac.db.tests.suite())
+    suite.addTest(trac.mimeview.tests.suite())
+    suite.addTest(trac.scripts.tests.suite())
+    suite.addTest(trac.ticket.tests.suite())
+    suite.addTest(trac.versioncontrol.tests.suite())
+    suite.addTest(trac.web.tests.suite())
+    suite.addTest(trac.wiki.tests.suite())
+
+    return suite
+
+if __name__ == '__main__':
+    import doctest, sys
+    doctest.testmod(sys.modules[__name__])
+    unittest.main(defaultTest='suite')
diff -urN trac-trunk/build/lib/trac/ticket/__init__.py aw-trac/build/lib/trac/ticket/__init__.py
--- trac-trunk/build/lib/trac/ticket/__init__.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/ticket/__init__.py	2005-05-29 03:35:57.000000000 -0700
@@ -0,0 +1,2 @@
+from trac.ticket.api import *
+from trac.ticket.model import *
diff -urN trac-trunk/build/lib/trac/ticket/api.py aw-trac/build/lib/trac/ticket/api.py
--- trac-trunk/build/lib/trac/ticket/api.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/ticket/api.py	2006-03-08 07:36:24.000000000 -0800
@@ -0,0 +1,202 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+import re
+
+from trac import util
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.wiki import IWikiSyntaxProvider, Formatter
+from trac.Search import ISearchSource, search_to_sql, shorten_result
+
+
+class TicketSystem(Component):
+    implements(IPermissionRequestor, IWikiSyntaxProvider, ISearchSource)
+
+    # Public API
+
+    def get_available_actions(self, ticket, perm_):
+        """Returns the actions that can be performed on the ticket."""
+        actions = {
+            'new':      ['leave', 'resolve', 'reassign', 'accept'],
+            'assigned': ['leave', 'resolve', 'reassign'          ],
+            'reopened': ['leave', 'resolve', 'reassign'          ],
+            'closed':   ['leave',                        'reopen']
+        }
+        perms = {'resolve': 'TICKET_MODIFY', 'reassign': 'TICKET_CHGPROP',
+                 'accept': 'TICKET_CHGPROP', 'reopen': 'TICKET_CREATE'}
+        return [action for action in actions.get(ticket['status'], ['leave'])
+                if action not in perms or perm_.has_permission(perms[action])]
+
+    def get_ticket_fields(self):
+        """Returns the list of fields available for tickets."""
+        from trac.ticket import model
+
+        db = self.env.get_db_cnx()
+        fields = []
+
+        # Basic text fields
+        for name in ('summary', 'reporter'):
+            field = {'name': name, 'type': 'text', 'label': name.title()}
+            fields.append(field)
+
+        # Owner field, can be text or drop-down depending on configuration
+        field = {'name': 'owner', 'label': 'Owner'}
+        if self.config.getbool('ticket', 'restrict_owner'):
+            field['type'] = 'select'
+            users = []
+            for username, name, email in self.env.get_known_users(db):
+                users.append(username)
+            field['options'] = users
+            field['optional'] = True
+        else:
+            field['type'] = 'text'
+        fields.append(field)
+
+        # Description
+        fields.append({'name': 'description', 'type': 'textarea',
+                       'label': 'Description'})
+
+        # Default select and radio fields
+        selects = [('type', model.Type), ('status', model.Status),
+                   ('priority', model.Priority), ('milestone', model.Milestone),
+                   ('component', model.Component), ('version', model.Version),
+                   ('severity', model.Severity), ('resolution', model.Resolution)]
+        for name, cls in selects:
+            options = [val.name for val in cls.select(self.env, db=db)]
+            if not options:
+                # Fields without possible values are treated as if they didn't
+                # exist
+                continue
+            field = {'name': name, 'type': 'select', 'label': name.title(),
+                     'value': self.config.get('ticket', 'default_' + name),
+                     'options': options}
+            if name in ('status', 'resolution'):
+                field['type'] = 'radio'
+            elif name in ('milestone', 'version'):
+                field['optional'] = True
+            fields.append(field)
+
+        # Advanced text fields
+        for name in ('keywords', 'cc', ):
+            field = {'name': name, 'type': 'text', 'label': name.title()}
+            fields.append(field)
+
+        for field in self.get_custom_fields():
+            if field['name'] in [f['name'] for f in fields]:
+                self.log.warning('Duplicate field name "%s" (ignoring)',
+                                 field['name'])
+                continue
+            if not re.match('^[a-zA-Z][a-zA-Z0-9_]+$', field['name']):
+                self.log.warning('Invalid name for custom field: "%s" '
+                                 '(ignoring)', field['name'])
+                continue
+            field['custom'] = True
+            fields.append(field)
+
+        return fields
+
+    def get_custom_fields(self):
+        fields = []
+        for name in [option for option, value
+                     in self.config.options('ticket-custom')
+                     if '.' not in option]:
+            field = {
+                'name': name,
+                'type': self.config.get('ticket-custom', name),
+                'order': int(self.config.get('ticket-custom', name + '.order', '0')),
+                'label': self.config.get('ticket-custom', name + '.label') \
+                         or name.capitalize(),
+                'value': self.config.get('ticket-custom', name + '.value', '')
+            }
+            if field['type'] == 'select' or field['type'] == 'radio':
+                options = self.config.get('ticket-custom', name + '.options')
+                field['options'] = [value.strip() for value in options.split('|')]
+            elif field['type'] == 'textarea':
+                field['width'] = self.config.get('ticket-custom', name + '.cols')
+                field['height'] = self.config.get('ticket-custom', name + '.rows')
+            fields.append(field)
+
+        fields.sort(lambda x, y: cmp(x['order'], y['order']))
+        return fields
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        return ['TICKET_APPEND', 'TICKET_CREATE', 'TICKET_CHGPROP',
+                'TICKET_VIEW',  
+                ('TICKET_MODIFY', ['TICKET_APPEND', 'TICKET_CHGPROP']),  
+                ('TICKET_ADMIN', ['TICKET_CREATE', 'TICKET_MODIFY',  
+                                  'TICKET_VIEW'])]
+
+    # IWikiSyntaxProvider methods
+
+    def get_link_resolvers(self):
+        return [('bug', self._format_link),
+                ('ticket', self._format_link)]
+
+    def get_wiki_syntax(self):
+        yield (
+            # matches #... but not &#... (HTML entity)
+            r"!?(?<!&)#"
+            # optional intertrac shorthand #T... + digits
+            r"(?P<it_ticket>%s)?\d+" % Formatter.INTERTRAC_SCHEME,
+            lambda x, y, z: self._format_link(x, 'ticket', y[1:], y, z))
+
+    def _format_link(self, formatter, ns, target, label, fullmatch=None):
+        intertrac = formatter.shorthand_intertrac_helper(ns, target, label,
+                                                         fullmatch)
+        if intertrac:
+            return intertrac
+        cursor = formatter.db.cursor()
+        cursor.execute("SELECT summary,status FROM ticket WHERE id=%s",
+                       (target,))
+        row = cursor.fetchone()
+        if row:
+            summary = util.escape(util.shorten_line(row[0]))
+            return '<a class="%s ticket" href="%s" title="%s (%s)">%s</a>' \
+                   % (row[1], formatter.href.ticket(target), summary, row[1],
+                      label)
+        else:
+            return '<a class="missing ticket" href="%s" rel="nofollow">%s</a>' \
+                   % (formatter.href.ticket(target), label)
+
+    
+    # ISearchSource methods
+
+    def get_search_filters(self, req):
+        if req.perm.has_permission('TICKET_VIEW'):
+            yield ('ticket', 'Tickets')
+
+    def get_search_results(self, req, terms, filters):
+        if not 'ticket' in filters:
+            return
+        db = self.env.get_db_cnx()
+        sql, args = search_to_sql(db, ['b.newvalue'], terms)
+        sql2, args2 = search_to_sql(db, ['summary', 'keywords', 'description',
+                                         'reporter', 'cc'], terms)
+        cursor = db.cursor()
+        cursor.execute("SELECT DISTINCT a.summary,a.description,a.reporter, "
+                       "a.keywords,a.id,a.time FROM ticket a "
+                       "LEFT JOIN ticket_change b ON a.id = b.ticket "
+                       "WHERE (b.field='comment' AND %s ) OR %s" % (sql, sql2),
+                       args + args2)
+        for summary,desc,author,keywords,tid,date in cursor:
+            yield (self.env.href.ticket(tid),
+                   '#%d: %s' % (tid, util.shorten_line(summary)),
+                   date, author,
+                   shorten_result(desc, terms))
+            
diff -urN trac-trunk/build/lib/trac/ticket/model.py aw-trac/build/lib/trac/ticket/model.py
--- trac-trunk/build/lib/trac/ticket/model.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/ticket/model.py	2006-01-13 09:17:26.000000000 -0800
@@ -0,0 +1,738 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2006 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import time
+import sys
+
+from trac.core import TracError
+from trac.ticket import TicketSystem
+from trac.util import sorted, embedded_numbers
+
+__all__ = ['Ticket', 'Type', 'Status', 'Resolution', 'Priority', 'Severity',
+           'Component', 'Milestone', 'Version']
+
+
+class Ticket(object):
+
+    def __init__(self, env, tkt_id=None, db=None):
+        self.env = env
+        self.fields = TicketSystem(self.env).get_ticket_fields()
+        self.values = {}
+        if tkt_id:
+            self._fetch_ticket(tkt_id, db)
+        else:
+            self._init_defaults(db)
+            self.id = self.time_created = self.time_changed = None
+        self._old = {}
+
+    def _get_db(self, db):
+        return db or self.env.get_db_cnx()
+
+    def _get_db_for_write(self, db):
+        if db:
+            return (db, False)
+        else:
+            return (self.env.get_db_cnx(), True)
+
+    exists = property(fget=lambda self: self.id is not None)
+
+    def _init_defaults(self, db=None):
+        for field in self.fields:
+            default = None
+            if not field.get('custom'):
+                default = self.env.config.get('ticket',
+                                              'default_' + field['name'])
+            else:
+                default = field.get('value')
+                options = field.get('options')
+                if default and options and default not in options:
+                    try:
+                        default_idx = int(default)
+                        if default_idx > len(options):
+                            raise ValueError
+                        default = options[default_idx]
+                    except ValueError:
+                        self.env.log.warning('Invalid default value for '
+                                             'custom field "%s"'
+                                             % field['name'])
+            if default:
+                self.values.setdefault(field['name'], default)
+
+    def _fetch_ticket(self, tkt_id, db=None):
+        db = self._get_db(db)
+
+        # Fetch the standard ticket fields
+        std_fields = [f['name'] for f in self.fields if not f.get('custom')]
+        cursor = db.cursor()
+        cursor.execute("SELECT %s,time,changetime FROM ticket WHERE id=%%s"
+                       % ','.join(std_fields), (tkt_id,))
+        row = cursor.fetchone()
+        if not row:
+            raise TracError('Ticket %d does not exist.' % tkt_id,
+                            'Invalid Ticket Number')
+
+        self.id = tkt_id
+        for i in range(len(std_fields)):
+            self.values[std_fields[i]] = row[i] or ''
+        self.time_created = row[len(std_fields)]
+        self.time_changed = row[len(std_fields) + 1]
+
+        # Fetch custom fields if available
+        custom_fields = [f['name'] for f in self.fields if f.get('custom')]
+        cursor.execute("SELECT name,value FROM ticket_custom WHERE ticket=%s",
+                       (tkt_id,))
+        for name, value in cursor:
+            if name in custom_fields:
+                self.values[name] = value
+
+    def __getitem__(self, name):
+        return self.values[name]
+
+    def __setitem__(self, name, value):
+        """Log ticket modifications so the table ticket_change can be updated"""
+        if self.values.has_key(name) and self.values[name] == value:
+            return
+        if not self._old.has_key(name): # Changed field
+            self._old[name] = self.values.get(name)
+        elif self._old[name] == value: # Change of field reverted
+            del self._old[name]
+        if value:
+            field = [field for field in self.fields if field['name'] == name]
+            if field and field[0].get('type') != 'textarea':
+                value = value.strip()
+        self.values[name] = value
+
+    def populate(self, values):
+        """Populate the ticket with 'suitable' values from a dictionary"""
+        field_names = [f['name'] for f in self.fields]
+        for name in [name for name in values.keys() if name in field_names]:
+            self[name] = values.get(name, '')
+
+        # We have to do an extra trick to catch unchecked checkboxes
+        for name in [name for name in values.keys() if name[9:] in field_names
+                     and name.startswith('checkbox_')]:
+            if not values.has_key(name[9:]):
+                self[name[9:]] = '0'
+
+    def insert(self, when=0, db=None):
+        """Add ticket to database"""
+        assert not self.exists, 'Cannot insert an existing ticket'
+        db, handle_ta = self._get_db_for_write(db)
+
+        # Add a timestamp
+        if not when:
+            when = int(time.time())
+        self.time_created = self.time_changed = when
+
+        cursor = db.cursor()
+
+        # The owner field defaults to the component owner
+        if self.values.get('component') and not self.values.get('owner'):
+            try:
+                component = Component(self.env, self['component'], db=db)
+                if component.owner:
+                    self['owner'] = component.owner
+            except TracError, e:
+                # Assume that no such component exists
+                pass
+
+        # Insert ticket record
+        std_fields = [f['name'] for f in self.fields if not f.get('custom')
+                      and self.values.has_key(f['name'])]
+        cursor.execute("INSERT INTO ticket (%s,time,changetime) VALUES (%s)"
+                       % (','.join(std_fields),
+                          ','.join(['%s'] * (len(std_fields) + 2))),
+                       [self[name] for name in std_fields] +
+                       [self.time_created, self.time_changed])
+        tkt_id = db.get_last_id(cursor, 'ticket')
+
+        # Insert custom fields
+        custom_fields = [f['name'] for f in self.fields if f.get('custom')
+                         and self.values.has_key(f['name'])]
+        if custom_fields:
+            cursor.executemany("INSERT INTO ticket_custom (ticket,name,value) "
+                               "VALUES (%s,%s,%s)", [(tkt_id, name, self[name])
+                                                     for name in custom_fields])
+
+        if handle_ta:
+            db.commit()
+        self.id = tkt_id
+        self._old = {}
+        return self.id
+
+    def save_changes(self, author, comment, when=0, db=None):
+        """
+        Store ticket changes in the database. The ticket must already exist in
+        the database.
+        """
+        assert self.exists, 'Cannot update a new ticket'
+
+        if not self._old and not comment:
+            return # Not modified
+
+        db, handle_ta = self._get_db_for_write(db)
+        cursor = db.cursor()
+        when = int(when or time.time())
+
+        if self.values.has_key('component'):
+            # If the component is changed on a 'new' ticket then owner field
+            # is updated accordingly. (#623).
+            if self.values.get('status') == 'new' \
+                    and self._old.has_key('component') \
+                    and not self._old.has_key('owner'):
+                try:
+                    old_comp = Component(self.env, self._old['component'], db)
+                    old_owner = old_comp.owner or ''
+                    current_owner = self.values.get('owner') or ''
+                    if old_owner == current_owner:
+                        new_comp = Component(self.env, self['component'], db)
+                        self['owner'] = new_comp.owner
+                except TracError, e:
+                    # If the old component has been removed from the database we
+                    # just leave the owner as is.
+                    pass
+
+        custom_fields = [f['name'] for f in self.fields if f.get('custom')]
+        for name in self._old.keys():
+            if name in custom_fields:
+                cursor.execute("SELECT * FROM ticket_custom " 
+                               "WHERE ticket=%s and name=%s", (self.id, name))
+                if cursor.fetchone():
+                    cursor.execute("UPDATE ticket_custom SET value=%s "
+                                   "WHERE ticket=%s AND name=%s",
+                                   (self[name], self.id, name))
+                else:
+                    cursor.execute("INSERT INTO ticket_custom (ticket,name,"
+                                   "value) VALUES(%s,%s,%s)",
+                                   (self.id, name, self[name]))
+            else:
+                cursor.execute("UPDATE ticket SET %s=%%s WHERE id=%%s" % name,
+                               (self[name], self.id))
+            cursor.execute("INSERT INTO ticket_change "
+                           "(ticket,time,author,field,oldvalue,newvalue) "
+                           "VALUES (%s, %s, %s, %s, %s, %s)",
+                           (self.id, when, author, name, self._old[name],
+                            self[name]))
+        if comment:
+            cursor.execute("INSERT INTO ticket_change "
+                           "(ticket,time,author,field,oldvalue,newvalue) "
+                           "VALUES (%s,%s,%s,'comment','',%s)",
+                           (self.id, when, author, comment))
+
+        cursor.execute("UPDATE ticket SET changetime=%s WHERE id=%s",
+                       (when, self.id))
+        if handle_ta:
+            db.commit()
+        self._old = {}
+        self.time_changed = when
+
+    def get_changelog(self, when=0, db=None):
+        """Return the changelog as a list of tuples of the form
+        (time, author, field, oldvalue, newvalue).
+        """
+        db = self._get_db(db)
+        cursor = db.cursor()
+        if when:
+            cursor.execute("SELECT time,author,field,oldvalue,newvalue "
+                           "FROM ticket_change WHERE ticket=%s AND time=%s "
+                           "UNION "
+                           "SELECT time,author,'attachment',null,filename "
+                           "FROM attachment WHERE id=%s AND time=%s "
+                           "UNION "
+                           "SELECT time,author,'comment',null,description "
+                           "FROM attachment WHERE id=%s AND time=%s "
+                           "ORDER BY time",
+                           (self.id, when, str(self.id), when, self.id, when))
+        else:
+            cursor.execute("SELECT time,author,field,oldvalue,newvalue "
+                           "FROM ticket_change WHERE ticket=%s "
+                           "UNION "
+                           "SELECT time,author,'attachment',null,filename "
+                           "FROM attachment WHERE id=%s "
+                           "UNION "
+                           "SELECT time,author,'comment',null,description "
+                           "FROM attachment WHERE id=%s "
+                           "ORDER BY time", (self.id,  str(self.id), self.id))
+        log = []
+        for t, author, field, oldvalue, newvalue in cursor:
+            log.append((int(t), author, field, oldvalue or '', newvalue or ''))
+        return log
+
+    def delete(self, db=None):
+        db, handle_ta = self._get_db_for_write(db)
+        cursor = db.cursor()
+        cursor.execute("DELETE FROM ticket WHERE id=%s", (self.id,))
+        cursor.execute("DELETE FROM ticket_change WHERE ticket=%s", (self.id,))
+        cursor.execute("DELETE FROM attachment "
+                       " WHERE type='ticket' and id=%s", (self.id,))
+        cursor.execute("DELETE FROM ticket_custom WHERE ticket=%s", (self.id,))
+        if handle_ta:
+            db.commit()
+
+
+class AbstractEnum(object):
+    type = None
+    ticket_col = None
+
+    def __init__(self, env, name=None, db=None):
+        if not self.ticket_col:
+            self.ticket_col = self.type
+        self.env = env
+        if name:
+            if not db:
+                db = self.env.get_db_cnx()
+            cursor = db.cursor()
+            cursor.execute("SELECT value FROM enum WHERE type=%s AND name=%s",
+                           (self.type, name))
+            row = cursor.fetchone()
+            if not row:
+                raise TracError, '%s %s does not exist.' % (self.type, name)
+            self.value = self._old_value = row[0]
+            self.name = self._old_name = name
+        else:
+            self.value = self._old_value = None
+            self.name = self._old_name = None
+
+    exists = property(fget=lambda self: self._old_value is not None)
+
+    def delete(self, db=None):
+        assert self.exists, 'Cannot deleting non-existent %s' % self.type
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.info('Deleting %s %s' % (self.type, self.name))
+        cursor.execute("DELETE FROM enum WHERE type=%s AND value=%s",
+                       (self.type, self._old_value))
+
+        if handle_ta:
+            db.commit()
+        self.value = self._old_value = None
+        self.name = self._old_name = None
+
+    def insert(self, db=None):
+        assert not self.exists, 'Cannot insert existing %s' % self.type
+        assert self.name, 'Cannot create %s with no name' % self.type
+        self.name = self.name.strip()
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.debug("Creating new %s '%s'" % (self.type, self.name))
+        if not self.value:
+            cursor.execute(("SELECT COALESCE(MAX(%s),0) FROM enum "
+                            "WHERE type=%%s") % db.cast('value', 'int'),
+                           (self.type,))
+            self.value = int(float(cursor.fetchone()[0])) + 1
+        cursor.execute("INSERT INTO enum (type,name,value) VALUES (%s,%s,%s)",
+                       (self.type, self.name, self.value))
+
+        if handle_ta:
+            db.commit()
+        self._old_name = self.name
+        self._old_value = self.value
+
+    def update(self, db=None):
+        assert self.exists, 'Cannot update non-existent %s' % self.type
+        assert self.name, 'Cannot update %s with no name' % self.type
+        self.name = self.name.strip()
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.info('Updating %s "%s"' % (self.type, self.name))
+        cursor.execute("UPDATE enum SET name=%s,value=%s "
+                       "WHERE type=%s AND name=%s",
+                       (self.name, self.value, self.type, self._old_name))
+        if self.name != self._old_name:
+            # Update tickets
+            cursor.execute("UPDATE ticket SET %s=%%s WHERE %s=%%s" %
+                           (self.ticket_col, self.ticket_col),
+                           (self.name, self._old_name))
+
+        if handle_ta:
+            db.commit()
+        self._old_name = self.name
+        self._old_value = self.value
+
+    def select(cls, env, db=None):
+        if not db:
+            db = env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT name,value FROM enum WHERE type=%s "
+                       "ORDER BY value", (cls.type,))
+        for name, value in cursor:
+            obj = cls(env)
+            obj.name = obj._old_name = name
+            obj.value = obj._old_value = value
+            yield obj
+    select = classmethod(select)
+
+
+class Type(AbstractEnum):
+    type = 'ticket_type'
+    ticket_col = 'type'
+
+
+class Status(AbstractEnum):
+    type = 'status'
+
+
+class Resolution(AbstractEnum):
+    type = 'resolution'
+
+
+class Priority(AbstractEnum):
+    type = 'priority'
+
+
+class Severity(AbstractEnum):
+    type = 'severity'
+
+
+class Component(object):
+
+    def __init__(self, env, name=None, db=None):
+        self.env = env
+        if name:
+            if not db:
+                db = self.env.get_db_cnx()
+            cursor = db.cursor()
+            cursor.execute("SELECT owner,description FROM component "
+                           "WHERE name=%s", (name,))
+            row = cursor.fetchone()
+            if not row:
+                raise TracError, 'Component %s does not exist.' % name
+            self.name = self._old_name = name
+            self.owner = row[0] or None
+            self.description = row[1] or ''
+        else:
+            self.name = self._old_name = None
+            self.owner = None
+            self.description = None
+
+    exists = property(fget=lambda self: self._old_name is not None)
+
+    def delete(self, db=None):
+        assert self.exists, 'Cannot deleting non-existent component'
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.info('Deleting component %s' % self.name)
+        cursor.execute("DELETE FROM component WHERE name=%s", (self.name,))
+
+        self.name = self._old_name = None
+
+        if handle_ta:
+            db.commit()
+
+    def insert(self, db=None):
+        assert not self.exists, 'Cannot insert existing component'
+        assert self.name, 'Cannot create component with no name'
+        self.name = self.name.strip()
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.debug("Creating new component '%s'" % self.name)
+        cursor.execute("INSERT INTO component (name,owner,description) "
+                       "VALUES (%s,%s,%s)",
+                       (self.name, self.owner, self.description))
+
+        if handle_ta:
+            db.commit()
+
+    def update(self, db=None):
+        assert self.exists, 'Cannot update non-existent component'
+        assert self.name, 'Cannot update component with no name'
+        self.name = self.name.strip()
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.info('Updating component "%s"' % self.name)
+        cursor.execute("UPDATE component SET name=%s,owner=%s,description=%s "
+                       "WHERE name=%s",
+                       (self.name, self.owner, self.description,
+                        self._old_name))
+        if self.name != self._old_name:
+            # Update tickets
+            cursor.execute("UPDATE ticket SET component=%s WHERE component=%s",
+                           (self.name, self._old_name))
+            self._old_name = self.name
+
+        if handle_ta:
+            db.commit()
+
+    def select(cls, env, db=None):
+        if not db:
+            db = env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT name,owner,description FROM component "
+                       "ORDER BY name")
+        for name, owner, description in cursor:
+            component = cls(env)
+            component.name = name
+            component.owner = owner or None
+            component.description = description or ''
+            yield component
+    select = classmethod(select)
+
+
+class Milestone(object):
+
+    def __init__(self, env, name=None, db=None):
+        self.env = env
+        if name:
+            self._fetch(name, db)
+            self._old_name = name
+        else:
+            self.name = self._old_name = None
+            self.due = self.completed = 0
+            self.description = ''
+
+    def _fetch(self, name, db=None):
+        if not db:
+            db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT name,due,completed,description "
+                       "FROM milestone WHERE name=%s", (name,))
+        row = cursor.fetchone()
+        if not row:
+            raise TracError('Milestone %s does not exist.' % name,
+                            'Invalid Milestone Name')
+        self.name = row[0]
+        self.due = row[1] and int(row[1]) or 0
+        self.completed = row[2] and int(row[2]) or 0
+        self.description = row[3] or ''
+
+    exists = property(fget=lambda self: self._old_name is not None)
+    is_completed = property(fget=lambda self: self.completed != 0)
+    is_late = property(fget=lambda self: self.due and \
+                                         self.due < time.time() - 86400)
+
+    def delete(self, retarget_to=None, author=None, db=None):
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.info('Deleting milestone %s' % self.name)
+        cursor.execute("DELETE FROM milestone WHERE name=%s", (self.name,))
+
+        # Retarget/reset tickets associated with this milestone
+        now = time.time()
+        cursor.execute("SELECT id FROM ticket WHERE milestone=%s", (self.name,))
+        tkt_ids = [int(row[0]) for row in cursor]
+        for tkt_id in tkt_ids:
+            ticket = Ticket(self.env, tkt_id, db)
+            ticket['milestone'] = retarget_to
+            ticket.save_changes(author, 'Milestone %s deleted' % self.name,
+                                now, db=db)
+
+        if handle_ta:
+            db.commit()
+
+    def insert(self, db=None):
+        assert self.name, 'Cannot create milestone with no name'
+        self.name = self.name.strip()
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.debug("Creating new milestone '%s'" % self.name)
+        cursor.execute("INSERT INTO milestone (name,due,completed,description) "
+                       "VALUES (%s,%s,%s,%s)",
+                       (self.name, self.due, self.completed, self.description))
+
+        if handle_ta:
+            db.commit()
+
+    def update(self, db=None):
+        assert self.name, 'Cannot update milestone with no name'
+        self.name = self.name.strip()
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.info('Updating milestone "%s"' % self.name)
+        cursor.execute("UPDATE milestone SET name=%s,due=%s,"
+                       "completed=%s,description=%s WHERE name=%s",
+                       (self.name, self.due, self.completed, self.description,
+                        self._old_name))
+        self.env.log.info('Updating milestone field of all tickets '
+                          'associated with milestone "%s"' % self.name)
+        cursor.execute("UPDATE ticket SET milestone=%s WHERE milestone=%s",
+                       (self.name, self._old_name))
+        self._old_name = self.name
+
+        if handle_ta:
+            db.commit()
+
+    def select(cls, env, include_completed=True, db=None):
+        if not db:
+            db = env.get_db_cnx()
+        sql = "SELECT name,due,completed,description FROM milestone "
+        if not include_completed:
+            sql += "WHERE COALESCE(completed,0)=0 "
+        cursor = db.cursor()
+        cursor.execute(sql)
+        milestones = []
+        for name,due,completed,description in cursor:
+            milestone = Milestone(env)
+            milestone.name = milestone._old_name = name
+            milestone.due = due and int(due) or 0
+            milestone.completed = completed and int(completed) or 0
+            milestone.description = description or ''
+            milestones.append(milestone)
+        def milestone_order(m):
+            return (m.completed or sys.maxint,
+                    m.due or sys.maxint,
+                    embedded_numbers(m.name))
+        return sorted(milestones, key=milestone_order)
+    select = classmethod(select)
+
+
+class Version(object):
+
+    def __init__(self, env, name=None, db=None):
+        self.env = env
+        if name:
+            if not db:
+                db = self.env.get_db_cnx()
+            cursor = db.cursor()
+            cursor.execute("SELECT time,description FROM version "
+                           "WHERE name=%s", (name,))
+            row = cursor.fetchone()
+            if not row:
+                raise TracError, 'Version %s does not exist.' % name
+            self.name = self._old_name = name
+            self.time = row[0] and int(row[0]) or None
+            self.description = row[1] or ''
+        else:
+            self.name = self._old_name = None
+            self.time = None
+            self.description = None
+
+    exists = property(fget=lambda self: self._old_name is not None)
+
+    def delete(self, db=None):
+        assert self.exists, 'Cannot deleting non-existent version'
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.info('Deleting version %s' % self.name)
+        cursor.execute("DELETE FROM version WHERE name=%s", (self.name,))
+
+        self.name = self._old_name = None
+
+        if handle_ta:
+            db.commit()
+
+    def insert(self, db=None):
+        assert not self.exists, 'Cannot insert existing version'
+        assert self.name, 'Cannot create version with no name'
+        self.name = self.name.strip()
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.debug("Creating new version '%s'" % self.name)
+        cursor.execute("INSERT INTO version (name,time,description) "
+                       "VALUES (%s,%s,%s)",
+                       (self.name, self.time, self.description))
+
+        if handle_ta:
+            db.commit()
+
+    def update(self, db=None):
+        assert self.exists, 'Cannot update non-existent version'
+        assert self.name, 'Cannot update version with no name'
+        self.name = self.name.strip()
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        cursor = db.cursor()
+        self.env.log.info('Updating version "%s"' % self.name)
+        cursor.execute("UPDATE version SET name=%s,time=%s,description=%s "
+                       "WHERE name=%s",
+                       (self.name, self.time, self.description,
+                        self._old_name))
+        if self.name != self._old_name:
+            # Update tickets
+            cursor.execute("UPDATE ticket SET version=%s WHERE version=%s",
+                           (self.name, self._old_name))
+            self._old_name = self.name
+
+        if handle_ta:
+            db.commit()
+
+    def select(cls, env, db=None):
+        if not db:
+            db = env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT name,time,description FROM version")
+        versions = []
+        for name, time, description in cursor:
+            version = cls(env)
+            version.name = name
+            version.time = time and int(time) or None
+            version.description = description or ''
+            versions.append(version)
+        def version_order(v):
+            return (v.time or sys.maxint, embedded_numbers(v.name))
+        return sorted(versions, key=version_order, reverse=True)
+    select = classmethod(select)
diff -urN trac-trunk/build/lib/trac/ticket/notification.py aw-trac/build/lib/trac/ticket/notification.py
--- trac-trunk/build/lib/trac/ticket/notification.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/ticket/notification.py	2006-02-18 16:42:16.000000000 -0800
@@ -0,0 +1,201 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Daniel Lundin <daniel@edgewall.com>
+# Copyright (C) 2005-2006 Emmanuel Blot <emmanuel.blot@free.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+#
+
+from trac import __version__
+from trac.core import TracError
+from trac.util import CRLF, wrap
+from trac.notification import NotifyEmail
+
+import md5
+
+class TicketNotifyEmail(NotifyEmail):
+    """Notification of ticket changes."""
+
+    template_name = "ticket_notify_email.cs"
+    ticket = None
+    newticket = None
+    modtime = 0
+    from_email = 'trac+ticket@localhost'
+    COLS = 75
+
+    def __init__(self, env):
+        NotifyEmail.__init__(self, env)
+        self.prev_cc = []
+
+    def notify(self, ticket, newticket=True, modtime=0):
+        self.ticket = ticket
+        self.modtime = modtime
+        self.newticket = newticket
+        self.ticket['description'] = wrap(self.ticket.values.get('description', ''),
+                                          self.COLS, initial_indent=' ',
+                                          subsequent_indent=' ', linesep=CRLF)
+        self.ticket['link'] = self.env.abs_href.ticket(ticket.id)
+        self.hdf.set_unescaped('email.ticket_props', self.format_props())
+        self.hdf.set_unescaped('email.ticket_body_hdr', self.format_hdr())
+        self.hdf.set_unescaped('ticket', self.ticket.values)
+        self.hdf['ticket.new'] = self.newticket
+        subject = self.format_subj()
+        if not self.newticket:
+            subject = 'Re: ' + subject
+        self.hdf.set_unescaped('email.subject', subject)
+        changes = ''
+        if not self.newticket and modtime:  # Ticket change
+            changelog = ticket.get_changelog(modtime)
+            for date, author, field, old, new in changelog:
+                self.hdf.set_unescaped('ticket.change.author', author)
+                pfx = 'ticket.change.%s' % field
+                newv = ''
+                if field == 'comment':
+                    newv = wrap(new, self.COLS, ' ', ' ', CRLF)
+                elif field == 'description':
+                    new_descr = wrap(new, self.COLS, ' ', ' ', CRLF)
+                    old_descr = wrap(old, self.COLS, '> ', '> ', CRLF)
+                    old_descr = old_descr.replace(2*CRLF, CRLF + '>' + CRLF)
+                    cdescr = CRLF
+                    cdescr += 'Old description:' + 2*CRLF + old_descr + 2*CRLF
+                    cdescr += 'New description:' + 2*CRLF + new_descr + CRLF
+                    self.hdf.set_unescaped('email.changes_descr', cdescr)
+                else:
+                    newv = new
+                    l = 7 + len(field)
+                    chg = wrap('%s => %s' % (old, new), self.COLS - l, '',
+                               l * ' ', CRLF)
+                    changes += '  * %s:  %s%s' % (field, chg, CRLF)
+                if newv:
+                    self.hdf.set_unescaped('%s.oldvalue' % pfx, old)
+                    self.hdf.set_unescaped('%s.newvalue' % pfx, newv)
+                if field == 'cc':
+                    self.prev_cc += old and self.parse_cc(old) or []
+                self.hdf.set_unescaped('%s.author' % pfx, author)
+            if changes:
+                self.hdf.set_unescaped('email.changes_body', changes)
+        NotifyEmail.notify(self, ticket.id, subject)
+
+    def format_props(self):
+        tkt = self.ticket
+        fields = [f for f in tkt.fields if f['name'] not in ('summary', 'cc')]
+        width = [0, 0, 0, 0]
+        i = 0
+        for f in [f['name'] for f in fields if f['type'] != 'textarea']:
+            if not tkt.values.has_key(f):
+                continue
+            fval = tkt[f]
+            if fval.find('\n') != -1:
+                continue
+            idx = 2 * (i % 2)
+            if len(f) > width[idx]:
+                width[idx] = len(f)
+            if len(fval) > width[idx + 1]:
+                width[idx + 1] = len(fval)
+            i += 1
+        format = ('%%%is:  %%-%is  |  ' % (width[0], width[1]),
+                  ' %%%is:  %%-%is%s' % (width[2], width[3], CRLF))
+        l = (width[0] + width[1] + 5)
+        sep = l * '-' + '+' + (self.COLS - l) * '-'
+        txt = sep + CRLF
+        big = []
+        i = 0
+        for f in [f for f in fields if f['name'] != 'description']:
+            fname = f['name']
+            if not tkt.values.has_key(fname):
+                continue
+            fval = tkt[fname]
+            if f['type'] == 'textarea' or '\n' in str(fval):
+                big.append((fname.capitalize(), CRLF.join(fval.splitlines())))
+            else:
+                txt += format[i % 2] % (fname.capitalize(), fval)
+                i += 1
+        if i % 2:
+            txt += CRLF
+        if big:
+            txt += sep
+            for name, value in big:
+                txt += CRLF.join(['', name + ':', value, '', ''])
+        txt += sep
+        return txt
+
+    def parse_cc(self, txt):
+        return filter(lambda x: '@' in x, txt.replace(',', ' ').split())
+
+    def format_hdr(self):
+        return '#%s: %s' % (self.ticket.id, wrap(self.ticket['summary'],
+                                                 self.COLS, linesep=CRLF))
+
+    def format_subj(self):
+        projname = self.config.get('project', 'name')
+        return '[%s] #%s: %s' % (projname, self.ticket.id,
+                                 self.ticket['summary'])
+
+    def get_recipients(self, tktid):
+        notify_reporter = self.config.getbool('notification',
+                                              'always_notify_reporter')
+        notify_owner = self.config.getbool('notification',
+                                           'always_notify_owner')
+
+        ccrecipients = self.prev_cc
+        torecipients = []
+        cursor = self.db.cursor()
+
+        # Harvest email addresses from the cc, reporter, and owner fields
+        cursor.execute("SELECT cc,reporter,owner FROM ticket WHERE id=%s",
+                       (tktid,))
+        row = cursor.fetchone()
+        if row:
+            ccrecipients += row[0] and row[0].replace(',', ' ').split() or []
+            if notify_reporter:
+                torecipients.append(row[1])
+            if notify_owner:
+                torecipients.append(row[2])
+
+        # Harvest email addresses from the author field of ticket_change(s)
+        if notify_reporter:
+            cursor.execute("SELECT DISTINCT author,ticket FROM ticket_change "
+                           "WHERE ticket=%s", (tktid,))
+            for author,ticket in cursor:
+                torecipients.append(author)
+
+        # Add smtp_always_cc address
+        acc = self.config.get('notification', 'smtp_always_cc')
+        if acc:
+            ccrecipients += acc.replace(',', ' ').split()
+            
+        return (torecipients, ccrecipients)
+
+    def get_message_id(self, rcpt, modtime=0):
+        """Generate a predictable, but sufficiently unique message ID."""
+        s = '%s.%08d.%d.%s' % (self.config.get('project', 'url'),
+                               int(self.ticket.id), modtime, rcpt)
+        dig = md5.new(s).hexdigest()
+        host = self.from_email[self.from_email.find('@') + 1:]
+        msgid = '<%03d.%s@%s>' % (len(s), dig, host)
+        return msgid
+
+    def send(self, torcpts, ccrcpts):
+        hdrs = {}
+        dest = torcpts or ccrcpts
+        if not dest:
+            self.env.log.info('no recipient for a ticket notification')
+            return 
+        hdrs['Message-ID'] = self.get_message_id(dest[0], self.modtime)
+        hdrs['X-Trac-Ticket-ID'] = str(self.ticket.id)
+        hdrs['X-Trac-Ticket-URL'] = self.ticket['link']
+        if not self.newticket:
+            hdrs['In-Reply-To'] = self.get_message_id(dest[0])
+            hdrs['References'] = self.get_message_id(dest[0])
+        NotifyEmail.send(self, torcpts, ccrcpts, hdrs)
+
diff -urN trac-trunk/build/lib/trac/ticket/query.py aw-trac/build/lib/trac/ticket/query.py
--- trac-trunk/build/lib/trac/ticket/query.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/ticket/query.py	2006-03-06 03:36:02.000000000 -0800
@@ -0,0 +1,699 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2006 Edgewall Software
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+import re
+import time
+
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.ticket import Ticket, TicketSystem
+from trac.util import escape, unescape, format_datetime, http_date, \
+                      shorten_line, CRLF, Markup
+from trac.web import IRequestHandler
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.wiki import wiki_to_html, wiki_to_oneliner, IWikiMacroProvider, \
+                      IWikiSyntaxProvider
+
+
+class QuerySyntaxError(Exception):
+    """Exception raised when a ticket query cannot be parsed from a string."""
+
+
+class Query(object):
+
+    def __init__(self, env, constraints=None, order=None, desc=0, group=None,
+                 groupdesc = 0, verbose=0):
+        self.env = env
+        self.constraints = constraints or {}
+        self.order = order
+        self.desc = desc
+        self.group = group
+        self.groupdesc = groupdesc
+        self.verbose = verbose
+        self.fields = TicketSystem(self.env).get_ticket_fields()
+        self.cols = [] # lazily initialized
+
+        if self.order != 'id' \
+                and self.order not in [f['name'] for f in self.fields]:
+            # order by priority by default
+            self.order = 'priority'
+
+        if self.group not in [f['name'] for f in self.fields]:
+            self.group = None
+
+    def from_string(cls, env, string, **kw):
+        filters = string.split('&')
+        constraints = {}
+        for filter in filters:
+            filter = filter.split('=')
+            if len(filter) != 2:
+                raise QuerySyntaxError, 'Query filter requires field and ' \
+                                        'constraints separated by a "="'
+            field,values = filter
+            if not field:
+                raise QuerySyntaxError, 'Query filter requires field name'
+            values = values.split('|')
+            mode, neg = '', ''
+            if field[-1] in ('~', '^', '$'):
+                mode = field[-1]
+                field = field[:-1]
+            if field[-1] == '!':
+                neg = '!'
+                field = field[:-1]
+            values = map(lambda x: neg + mode + x, values)
+            constraints[field] = values
+        return cls(env, constraints, **kw)
+    from_string = classmethod(from_string)
+
+    def get_columns(self):
+        if self.cols:
+            return self.cols
+
+        # FIXME: the user should be able to configure which columns should
+        # be displayed
+        cols = ['id']
+        cols += [f['name'] for f in self.fields if f['type'] != 'textarea']
+        for col in ('reporter', 'keywords', 'cc'):
+            if col in cols:
+                cols.remove(col)
+                cols.append(col)
+
+        # Semi-intelligently remove columns that are restricted to a single
+        # value by a query constraint.
+        for col in [k for k in self.constraints.keys() if k in cols]:
+            constraint = self.constraints[col]
+            if len(constraint) == 1 and constraint[0] \
+                    and not constraint[0][0] in ('!', '~', '^', '$'):
+                if col in cols:
+                    cols.remove(col)
+            if col == 'status' and not 'closed' in constraint \
+                    and 'resolution' in cols:
+                cols.remove('resolution')
+        if self.group in cols:
+            cols.remove(self.group)
+
+        def sort_columns(col1, col2):
+            constrained_fields = self.constraints.keys()
+            # Ticket ID is always the first column
+            if 'id' in [col1, col2]:
+                return col1 == 'id' and -1 or 1
+            # Ticket summary is always the second column
+            elif 'summary' in [col1, col2]:
+                return col1 == 'summary' and -1 or 1
+            # Constrained columns appear before other columns
+            elif col1 in constrained_fields or col2 in constrained_fields:
+                return col1 in constrained_fields and -1 or 1
+            return 0
+        cols.sort(sort_columns)
+
+        # Only display the first eight columns by default
+        # FIXME: Make this configurable on a per-user and/or per-query basis
+        self.cols = cols[:7]
+        if not self.order in self.cols and not self.order == self.group:
+            # Make sure the column we order by is visible, if it isn't also
+            # the column we group by
+            self.cols[-1] = self.order
+
+        return self.cols
+
+    def execute(self, db=None):
+        if not self.cols:
+            self.get_columns()
+
+        sql, args = self.get_sql()
+        self.env.log.debug("Query SQL: " + sql % tuple([repr(a) for a in args]))
+
+        if not db:
+            db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute(sql, args)
+        columns = cursor.description
+        results = []
+        for row in cursor:
+            id = int(row[0])
+            result = {'id': id, 'href': self.env.href.ticket(id)}
+            for i in range(1, len(columns)):
+                name, val = columns[i][0], row[i]
+                if name == self.group:
+                    val = val or 'None'
+                elif name == 'reporter':
+                    val = val or 'anonymous'
+                elif name in ['changetime', 'time']:
+                    val = int(val)
+                elif val is None:
+                    val = '--'
+                result[name] = val
+            results.append(result)
+        cursor.close()
+        return results
+
+    def get_href(self, order=None, desc=None, format=None):
+        if desc is None:
+            desc = self.desc
+        if order is None:
+            order = self.order
+        return self.env.href.query(order=order, desc=desc and 1 or None,
+                                   group=self.group or None,
+                                   groupdesc=self.groupdesc and 1 or None,
+                                   verbose=self.verbose and 1 or None,
+                                   format=format, **self.constraints)
+
+    def get_sql(self):
+        """Return a (sql, params) tuple for the query."""
+        if not self.cols:
+            self.get_columns()
+
+        # Build the list of actual columns to query
+        cols = self.cols[:]
+        def add_cols(*args):
+            for col in args:
+                if not col in cols:
+                    cols.append(col)
+        if self.group and not self.group in cols:
+            add_cols(self.group)
+        if self.verbose:
+            add_cols('reporter', 'description')
+        add_cols('priority', 'time', 'changetime', self.order)
+        cols.extend([c for c in self.constraints.keys() if not c in cols])
+
+        custom_fields = [f['name'] for f in self.fields if f.has_key('custom')]
+
+        sql = []
+        sql.append("SELECT " + ",".join(['t.%s AS %s' % (c, c) for c in cols
+                                         if c not in custom_fields]))
+        sql.append(",priority.value AS priority_value")
+        for k in [k for k in cols if k in custom_fields]:
+            sql.append(",%s.value AS %s" % (k, k))
+        sql.append("\nFROM ticket AS t")
+
+        # Join with ticket_custom table as necessary
+        for k in [k for k in cols if k in custom_fields]:
+           sql.append("\n  LEFT OUTER JOIN ticket_custom AS %s ON " \
+                      "(id=%s.ticket AND %s.name='%s')" % (k, k, k, k))
+
+        # Join with the enum table for proper sorting
+        for col in [c for c in ('status', 'resolution', 'priority', 'severity')
+                    if c == self.order or c == self.group or c == 'priority']:
+            sql.append("\n  LEFT OUTER JOIN enum AS %s ON "
+                       "(%s.type='%s' AND %s.name=%s)"
+                       % (col, col, col, col, col))
+
+        # Join with the version/milestone tables for proper sorting
+        for col in [c for c in ['milestone', 'version']
+                    if c == self.order or c == self.group]:
+            sql.append("\n  LEFT OUTER JOIN %s ON (%s.name=%s)"
+                       % (col, col, col))
+
+        def get_constraint_sql(name, value, mode, neg):
+            if name not in custom_fields:
+                name = 't.' + name
+            else:
+                name = name + '.value'
+            value = value[len(mode) + neg:]
+
+            if mode == '':
+                return ("COALESCE(%s,'')%s=%%s" % (name, neg and '!' or ''),
+                        value)
+            if not value:
+                return None
+
+            if mode == '~':
+                value = '%' + value + '%'
+            elif mode == '^':
+                value = value + '%'
+            elif mode == '$':
+                value = '%' + value
+            return ("COALESCE(%s,'') %sLIKE %%s" % (name, neg and 'NOT ' or ''),
+                    value)
+
+        clauses = []
+        args = []
+        for k, v in self.constraints.items():
+            # Determine the match mode of the constraint (contains, starts-with,
+            # negation, etc)
+            neg = v[0].startswith('!')
+            mode = ''
+            if len(v[0]) > neg and v[0][neg] in ('~', '^', '$'):
+                mode = v[0][neg]
+
+            # Special case for exact matches on multiple values
+            if not mode and len(v) > 1:
+                if k not in custom_fields:
+                    col = 't.' + k
+                else:
+                    col = k + '.value'
+                clauses.append("COALESCE(%s,'') %sIN (%s)"
+                               % (col, neg and 'NOT ' or '',
+                                  ','.join(['%s' for val in v])))
+                args += [val[neg:] for val in v]
+            elif len(v) > 1:
+                constraint_sql = filter(None,
+                                        [get_constraint_sql(k, val, mode, neg)
+                                         for val in v])
+                if not constraint_sql:
+                    continue
+                if neg:
+                    clauses.append("(" + " AND ".join([item[0] for item in constraint_sql]) + ")")
+                else:
+                    clauses.append("(" + " OR ".join([item[0] for item in constraint_sql]) + ")")
+                args += [item[1] for item in constraint_sql]
+            elif len(v) == 1:
+                constraint_sql = get_constraint_sql(k, v[0], mode, neg)
+                if constraint_sql:
+                    clauses.append(constraint_sql[0])
+                    args.append(constraint_sql[1])
+
+        clauses = filter(None, clauses)
+        if clauses:
+            sql.append("\nWHERE " + " AND ".join(clauses))
+
+        sql.append("\nORDER BY ")
+        order_cols = [(self.order, self.desc)]
+        if self.group and self.group != self.order:
+            order_cols.insert(0, (self.group, self.groupdesc))
+        for name, desc in order_cols:
+            if name not in custom_fields:
+                col = 't.' + name
+            else:
+                col = name + '.value'
+            if name == 'id':
+                # FIXME: This is a somewhat ugly hack.  Can we also have the
+                #        column type for this?  If it's an integer, we do first
+                #        one, if text, we do 'else'
+                if desc:
+                    sql.append("COALESCE(%s,0)=0 DESC," % col)
+                else:
+                    sql.append("COALESCE(%s,0)=0," % col)
+            else:
+                if desc:
+                    sql.append("COALESCE(%s,'')='' DESC," % col)
+                else:
+                    sql.append("COALESCE(%s,'')=''," % col)
+            if name in ['status', 'resolution', 'priority', 'severity']:
+                if desc:
+                    sql.append("%s.value DESC" % name)
+                else:
+                    sql.append("%s.value" % name)
+            elif col in ['t.milestone', 't.version']:
+                time_col = name == 'milestone' and 'milestone.due' or 'version.time'
+                if desc:
+                    sql.append("COALESCE(%s,0)=0 DESC,%s DESC,%s DESC"
+                               % (time_col, time_col, col))
+                else:
+                    sql.append("COALESCE(%s,0)=0,%s,%s"
+                               % (time_col, time_col, col))
+            else:
+                if desc:
+                    sql.append("%s DESC" % col)
+                else:
+                    sql.append("%s" % col)
+            if name == self.group and not name == self.order:
+                sql.append(",")
+        if self.order != 'id':
+            sql.append(",t.id")
+
+        return "".join(sql), args
+
+
+class QueryModule(Component):
+
+    implements(IRequestHandler, INavigationContributor, IWikiSyntaxProvider)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'tickets'
+
+    def get_navigation_items(self, req):
+        from trac.ticket.report import ReportModule
+        if req.perm.has_permission('TICKET_VIEW') and \
+           not self.env.is_component_enabled(ReportModule):
+            yield 'mainnav', 'tickets', Markup('<a href="%s">View Tickets</a>',
+                                               self.env.href.query())
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        return req.path_info == '/query'
+
+    def process_request(self, req):
+        req.perm.assert_permission('TICKET_VIEW')
+
+        constraints = self._get_constraints(req)
+        if not constraints and not req.args.has_key('order'):
+            # avoid displaying all tickets when the query module is invoked
+            # with no parameters. Instead show only open tickets, possibly
+            # associated with the user
+            constraints = {'status': ('new', 'assigned', 'reopened')}
+            if req.authname and req.authname != 'anonymous':
+                constraints['owner'] = (req.authname,)
+            else:
+                email = req.session.get('email')
+                name = req.session.get('name')
+                if email or name:
+                    constraints['cc'] = ('~%s' % email or name,)
+
+        query = Query(self.env, constraints, req.args.get('order'),
+                      req.args.has_key('desc'), req.args.get('group'),
+                      req.args.has_key('groupdesc'),
+                      req.args.has_key('verbose'))
+
+        if req.args.has_key('update'):
+            # Reset session vars
+            for var in ('query_constraints', 'query_time', 'query_tickets'):
+                if req.session.has_key(var):
+                    del req.session[var]
+            req.redirect(query.get_href())
+
+        add_link(req, 'alternate', query.get_href(format='rss'), 'RSS Feed',
+                 'application/rss+xml', 'rss')
+        add_link(req, 'alternate', query.get_href(format='csv'),
+                 'Comma-delimited Text', 'text/plain')
+        add_link(req, 'alternate', query.get_href(format='tab'),
+                 'Tab-delimited Text', 'text/plain')
+
+        constraints = {}
+        for k, v in query.constraints.items():
+            constraint = {'values': [], 'mode': ''}
+            for val in v:
+                neg = val.startswith('!')
+                if neg:
+                    val = val[1:]
+                mode = ''
+                if val[:1] in ('~', '^', '$'):
+                    mode, val = val[:1], val[1:]
+                constraint['mode'] = (neg and '!' or '') + mode
+                constraint['values'].append(val)
+            constraints[k] = constraint
+        req.hdf['query.constraints'] = constraints
+
+        format = req.args.get('format')
+        if format == 'rss':
+            self.display_rss(req, query)
+            return 'query_rss.cs', 'application/rss+xml'
+        elif format == 'csv':
+            self.display_csv(req, query)
+        elif format == 'tab':
+            self.display_csv(req, query, '\t')
+        else:
+            self.display_html(req, query)
+            return 'query.cs', None
+
+    # Internal methods
+
+    def _get_constraints(self, req):
+        constraints = {}
+        ticket_fields = [f['name'] for f in
+                         TicketSystem(self.env).get_ticket_fields()]
+
+        # For clients without JavaScript, we remove constraints here if
+        # requested
+        remove_constraints = {}
+        to_remove = [k[10:] for k in req.args.keys()
+                     if k.startswith('rm_filter_')]
+        if to_remove: # either empty or containing a single element
+            match = re.match(r'(\w+?)_(\d+)$', to_remove[0])
+            if match:
+                remove_constraints[match.group(1)] = int(match.group(2))
+            else:
+                remove_constraints[to_remove[0]] = -1
+
+        for field in [k for k in req.args.keys() if k in ticket_fields]:
+            vals = req.args[field]
+            if not isinstance(vals, (list, tuple)):
+                vals = [vals]
+            if vals:
+                mode = req.args.get(field + '_mode')
+                if mode:
+                    vals = map(lambda x: mode + x, vals)
+                if remove_constraints.has_key(field):
+                    idx = remove_constraints[field]
+                    if idx >= 0:
+                        del vals[idx]
+                        if not vals:
+                            continue
+                    else:
+                        continue
+                constraints[field] = vals
+
+        return constraints
+
+    def _get_constraint_modes(self):
+        modes = {}
+        modes['text'] = [
+            {'name': "contains", 'value': "~"},
+            {'name': "doesn't contain", 'value': "!~"},
+            {'name': "begins with", 'value': "^"},
+            {'name': "ends with", 'value': "$"},
+            {'name': "is", 'value': ""},
+            {'name': "is not", 'value': "!"}
+        ]
+        modes['select'] = [
+            {'name': "is", 'value': ""},
+            {'name': "is not", 'value': "!"}
+        ]
+        return modes
+
+    def display_html(self, req, query):
+        req.hdf['title'] = 'Custom Query'
+        add_stylesheet(req, 'common/css/report.css')
+
+        db = self.env.get_db_cnx()
+
+        for field in query.fields:
+            if field['type'] == 'textarea':
+                continue
+            hdf = {}
+            hdf.update(field)
+            del hdf['name']
+            req.hdf['query.fields.' + field['name']] = hdf
+        req.hdf['query.modes'] = self._get_constraint_modes()
+
+        # For clients without JavaScript, we add a new constraint here if
+        # requested
+        if req.args.has_key('add'):
+            field = req.args.get('add_filter')
+            if field:
+                idx = 0
+                if query.constraints.has_key(field):
+                    idx = len(query.constraints[field])
+                req.hdf['query.constraints.%s.values.%d' % (field, idx)] = ''
+
+        cols = query.get_columns()
+        labels = dict([(f['name'], f['label']) for f in query.fields])
+        for idx, col in enumerate(cols):
+            req.hdf['query.headers.%d' % idx] = {
+                'name': col, 'label': labels.get(col, 'Ticket'),
+                'href': query.get_href(order=col, desc=(col == query.order and
+                                                        not query.desc))
+            }
+
+        href = self.env.href.query(group=query.group,
+                                   groupdesc=query.groupdesc and 1 or None,
+                                   verbose=query.verbose and 1 or None,
+                                   **query.constraints)
+        req.hdf['query.order'] = query.order
+        req.hdf['query.href'] = href
+        if query.desc:
+            req.hdf['query.desc'] = True
+        if query.group:
+            req.hdf['query.group'] = query.group
+            if query.groupdesc:
+                req.hdf['query.groupdesc'] = True
+        if query.verbose:
+            req.hdf['query.verbose'] = True
+
+        tickets = query.execute(db)
+        req.hdf['query.num_matches'] = len(tickets)
+
+        # The most recent query is stored in the user session
+        orig_list = rest_list = None
+        orig_time = int(time.time())
+        if str(query.constraints) != req.session.get('query_constraints'):
+            # New query, initialize session vars
+            req.session['query_constraints'] = str(query.constraints)
+            req.session['query_time'] = int(time.time())
+            req.session['query_tickets'] = ' '.join([str(t['id']) for t in tickets])
+        else:
+            orig_list = [int(id) for id in req.session.get('query_tickets', '').split()]
+            rest_list = orig_list[:]
+            orig_time = int(req.session.get('query_time', 0))
+        req.session['query_href'] = query.get_href()
+
+        # Find out which tickets originally in the query results no longer
+        # match the constraints
+        if rest_list:
+            for tid in [t['id'] for t in tickets if t['id'] in rest_list]:
+                rest_list.remove(tid)
+            for rest_id in rest_list:
+                try:
+                    ticket = Ticket(self.env, int(rest_id), db=db)
+                    data = {'id': ticket.id, 'time': ticket.time_created,
+                            'changetime': ticket.time_changed, 'removed': True,
+                            'href': self.env.href.ticket(ticket.id)}
+                    data.update(ticket.values)
+                except TracError, e:
+                    data = {'id': rest_id, 'time': 0, 'changetime': 0,
+                            'summary': Markup("<em>%s</em>", str(e))}
+                tickets.insert(orig_list.index(rest_id), data)
+
+        for ticket in tickets:
+            if orig_list:
+                # Mark tickets added or changed since the query was first
+                # executed
+                if int(ticket['time']) > orig_time:
+                    ticket['added'] = True
+                elif int(ticket['changetime']) > orig_time:
+                    ticket['changed'] = True
+            for field, value in ticket.items():
+                if field == 'time':
+                    ticket[field] = format_datetime(value)
+                elif field == 'description':
+                    ticket[field] = wiki_to_html(value or '', self.env, req, db)
+                else:
+                    ticket[field] = value
+
+        req.hdf['query.results'] = tickets
+        req.session['query_tickets'] = ' '.join([str(t['id']) for t in tickets])
+
+        # Kludge: only show link to available reports if the report module is
+        # actually enabled
+        from trac.ticket.report import ReportModule
+        if req.perm.has_permission('REPORT_VIEW') and \
+           self.env.is_component_enabled(ReportModule):
+            req.hdf['query.report_href'] = self.env.href.report()
+
+    def display_csv(self, req, query, sep=','):
+        req.send_response(200)
+        req.send_header('Content-Type', 'text/plain;charset=utf-8')
+        req.end_headers()
+
+        cols = query.get_columns()
+        req.write(sep.join([col for col in cols]) + CRLF)
+
+        results = query.execute(self.env.get_db_cnx())
+        for result in results:
+            req.write(sep.join([str(result[col]).replace(sep, '_')
+                                                .replace('\n', ' ')
+                                                .replace('\r', ' ')
+                                for col in cols]) + CRLF)
+
+    def display_rss(self, req, query):
+        query.verbose = True
+        db = self.env.get_db_cnx()
+        results = query.execute(db)
+        for result in results:
+            result['href'] = self.env.abs_href.ticket(result['id'])
+            if result['reporter'].find('@') == -1:
+                result['reporter'] = ''
+            if result['description']:
+                # str() cancels out the Markup() returned by wiki_to_html
+                descr = wiki_to_html(result['description'], self.env, req, db,
+                                     absurls=True)
+                result['description'] = str(descr)
+            if result['time']:
+                result['time'] = http_date(result['time'])
+        req.hdf['query.results'] = results
+        req.hdf['query.href'] = self.env.abs_href.query(group=query.group,
+                groupdesc=query.groupdesc and 1 or None,
+                verbose=query.verbose and 1 or None,
+                **query.constraints)
+
+    # IWikiSyntaxProvider methods
+    
+    def get_wiki_syntax(self):
+        return []
+    
+    def get_link_resolvers(self):
+        yield ('query', self._format_link)
+
+    def _format_link(self, formatter, ns, query, label):
+        if query[0] == '?':
+            return '<a class="query" href="%s">%s</a>' \
+                   % (escape(formatter.href.query() + query.replace(' ', '+')),
+                      label)
+        else:
+            from trac.ticket.query import Query, QuerySyntaxError
+            try:
+                query = Query.from_string(formatter.env, query)
+                return '<a class="query" href="%s">%s</a>' \
+                       % (escape(query.get_href()), label)
+            except QuerySyntaxError, e:
+                return '<em class="error">[Error: %s]</em>' % escape(e)
+
+
+class QueryWikiMacro(Component):
+    """Macro that lists tickets that match certain criteria.
+    
+    This macro accepts two parameters, the second of which is optional.
+
+    The first parameter is the query itself, and uses the same syntax as for
+    {{{query:}}} wiki links. The second parameter determines how the list of
+    tickets is presented: the default presentation is to list the ticket ID next
+    to the summary, with each ticket on a separate line. If the second parameter
+    is given and set to '''compact''' then the tickets are presented as a
+    comma-separated list of ticket IDs.
+    """
+    implements(IWikiMacroProvider)
+
+    def get_macros(self):
+        yield 'TicketQuery'
+
+    def get_macro_description(self, name):
+        import inspect
+        return inspect.getdoc(QueryWikiMacro)
+
+    def render_macro(self, req, name, content):
+        query_string = ''
+        compact = 0
+        argv = content.split(',')
+        if len(argv) > 0:
+            query_string = argv[0]
+            if len(argv) > 1:
+                if argv[1].strip().lower() == 'compact':
+                    compact = 1
+        
+        try:
+            from cStringIO import StringIO
+        except NameError:
+            from StringIO import StringIO
+        buf = StringIO()
+
+        query = Query.from_string(self.env, query_string)
+        query.order = 'id'
+        tickets = query.execute()
+        if tickets:
+            if compact:
+                links = []
+                for ticket in tickets:
+                    href = self.env.href.ticket(int(ticket['id']))
+                    summary = escape(shorten_line(ticket['summary']))
+                    a = '<a class="%s ticket" href="%s" title="%s">#%s</a>' % \
+                        (ticket['status'], href, summary, ticket['id'])
+                    links.append(a)
+                buf.write(', '.join(links))
+            else:
+                buf.write('<dl class="wiki compact">')
+                for ticket in tickets:
+                    href = self.env.href.ticket(int(ticket['id']))
+                    dt = '<dt><a class="%s ticket" href="%s">#%s</a></dt>' % \
+                         (ticket['status'], href, ticket['id'])
+                    buf.write(dt)
+                    buf.write('<dd>%s</dd>' % (escape(ticket['summary'])))
+                buf.write('</dl>')
+
+        return buf.getvalue()
diff -urN trac-trunk/build/lib/trac/ticket/report.py aw-trac/build/lib/trac/ticket/report.py
--- trac-trunk/build/lib/trac/ticket/report.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/ticket/report.py	2006-03-02 20:55:21.000000000 -0800
@@ -0,0 +1,507 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2004 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2006 Christian Boos <cboos@neuf.fr>
+# Copyright (C) 2006 Matthew Good <trac@matt-good.net>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+import re
+import urllib
+
+from trac import util
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.util import sorted
+from trac.web import IRequestHandler
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.wiki import wiki_to_html, IWikiSyntaxProvider, Formatter
+
+try:
+    from cStringIO import StringIO
+except ImportError:
+    from StringIO import StringIO
+
+
+class ReportModule(Component):
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
+               IWikiSyntaxProvider)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'tickets'
+
+    def get_navigation_items(self, req):
+        if not req.perm.has_permission('REPORT_VIEW'):
+            return
+        yield ('mainnav', 'tickets',
+               util.Markup('<a href="%s">View Tickets</a>',
+                           self.env.href.report()))
+
+    # IPermissionRequestor methods  
+
+    def get_permission_actions(self):  
+        actions = ['REPORT_CREATE', 'REPORT_DELETE', 'REPORT_MODIFY',  
+                   'REPORT_SQL_VIEW', 'REPORT_VIEW']  
+        return actions + [('REPORT_ADMIN', actions)]  
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        match = re.match(r'/report(?:/([0-9]+))?', req.path_info)
+        if match:
+            if match.group(1):
+                req.args['id'] = match.group(1)
+            return 1
+
+    def process_request(self, req):
+        req.perm.assert_permission('REPORT_VIEW')
+
+        # did the user ask for any special report?
+        id = int(req.args.get('id', -1))
+        action = req.args.get('action', 'list')
+
+        db = self.env.get_db_cnx()
+
+        if req.method == 'POST':
+            if action == 'new':
+                self._do_create(req, db)
+            elif action == 'delete':
+                self._do_delete(req, db, id)
+            elif action == 'edit':
+                self._do_save(req, db, id)
+        elif action in ('copy', 'edit', 'new'):
+            self._render_editor(req, db, id, action == 'copy')
+        elif action == 'delete':
+            self._render_confirm_delete(req, db, id)
+        else:
+            resp = self._render_view(req, db, id)
+            if not resp:
+               return None
+            template, content_type = resp
+            if content_type:
+               return resp
+
+        if id != -1 or action == 'new':
+            add_link(req, 'up', self.env.href.report(), 'Available Reports')
+
+            # Kludge: Reset session vars created by query module so that the
+            # query navigation links on the ticket page don't confuse the user
+            for var in ('query_constraints', 'query_time', 'query_tickets'):
+                if req.session.has_key(var):
+                    del req.session[var]
+
+        # Kludge: only show link to custom query if the query module is actually
+        # enabled
+        from trac.ticket.query import QueryModule
+        if req.perm.has_permission('TICKET_VIEW') and \
+           self.env.is_component_enabled(QueryModule):
+            req.hdf['report.query_href'] = self.env.href.query()
+
+        add_stylesheet(req, 'common/css/report.css')
+        return 'report.cs', None
+
+    # Internal methods
+
+    def _do_create(self, req, db):
+        req.perm.assert_permission('REPORT_CREATE')
+
+        if req.args.has_key('cancel'):
+            req.redirect(self.env.href.report())
+
+        title = req.args.get('title', '')
+        sql = req.args.get('sql', '')
+        description = req.args.get('description', '')
+        cursor = db.cursor()
+        cursor.execute("INSERT INTO report (title,sql,description) "
+                       "VALUES (%s,%s,%s)", (title, sql, description))
+        id = db.get_last_id(cursor, 'report')
+        db.commit()
+        req.redirect(self.env.href.report(id))
+
+    def _do_delete(self, req, db, id):
+        req.perm.assert_permission('REPORT_DELETE')
+
+        if req.args.has_key('cancel'):
+            req.redirect(self.env.href.report(id))
+
+        cursor = db.cursor()
+        cursor.execute("DELETE FROM report WHERE id=%s", (id,))
+        db.commit()
+        req.redirect(self.env.href.report())
+
+    def _do_save(self, req, db, id):
+        """
+        Saves report changes to the database
+        """
+        req.perm.assert_permission('REPORT_MODIFY')
+
+        if not req.args.has_key('cancel'):
+            title = req.args.get('title', '')
+            sql = req.args.get('sql', '')
+            description = req.args.get('description', '')
+            cursor = db.cursor()
+            cursor.execute("UPDATE report SET title=%s,sql=%s,description=%s "
+                           "WHERE id=%s", (title, sql, description, id))
+            db.commit()
+        req.redirect(self.env.href.report(id))
+
+    def _render_confirm_delete(self, req, db, id):
+        req.perm.assert_permission('REPORT_DELETE')
+
+        cursor = db.cursor()
+        cursor.execute("SELECT title FROM report WHERE id = %s", (id,))
+        row = cursor.fetchone()
+        if not row:
+            raise util.TracError('Report %s does not exist.' % id,
+                                 'Invalid Report Number')
+        req.hdf['title'] = 'Delete Report {%s} %s' % (id, row[0])
+        req.hdf['report'] = {
+            'id': id,
+            'mode': 'delete',
+            'title': row[0],
+            'href': self.env.href.report(id)
+        }
+
+    def _render_editor(self, req, db, id, copy=False):
+        if id == -1:
+            req.perm.assert_permission('REPORT_CREATE')
+            title = sql = description = ''
+        else:
+            req.perm.assert_permission('REPORT_MODIFY')
+            cursor = db.cursor()
+            cursor.execute("SELECT title,description,sql FROM report "
+                           "WHERE id=%s", (id,))
+            row = cursor.fetchone()
+            if not row:
+                raise util.TracError('Report %s does not exist.' % id,
+                                     'Invalid Report Number')
+            title = row[0] or ''
+            description = row[1] or ''
+            sql = row[2] or ''
+
+        if copy:
+            title += ' (copy)'
+
+        if copy or id == -1:
+            req.hdf['title'] = 'Create New Report'
+            req.hdf['report.href'] = self.env.href.report()
+            req.hdf['report.action'] = 'new'
+        else:
+            req.hdf['title'] = 'Edit Report {%d} %s' % (id, title)
+            req.hdf['report.href'] = self.env.href.report(id)
+            req.hdf['report.action'] = 'edit'
+
+        req.hdf['report.id'] = id
+        req.hdf['report.mode'] = 'edit'
+        req.hdf['report.title'] = title
+        req.hdf['report.sql'] = sql
+        req.hdf['report.description'] = description
+
+    def _render_view(self, req, db, id):
+        """
+        uses a user specified sql query to extract some information
+        from the database and presents it as a html table.
+        """
+        actions = {'create': 'REPORT_CREATE', 'delete': 'REPORT_DELETE',
+                   'modify': 'REPORT_MODIFY'}
+        for action in [k for k,v in actions.items()
+                       if req.perm.has_permission(v)]:
+            req.hdf['report.can_' + action] = True
+        req.hdf['report.href'] = self.env.href.report(id)
+
+        try:
+            args = self.get_var_args(req)
+        except ValueError,e:
+            raise TracError, 'Report failed: %s' % e
+
+        title, description, sql = self.get_info(db, id, args)
+
+        format = req.args.get('format')
+        if format == 'sql':
+            self._render_sql(req, id, title, description, sql)
+            return
+
+        req.hdf['report.mode'] = 'list'
+        if id > 0:
+            title = '{%i} %s' % (id, title)
+        req.hdf['title'] = title
+        req.hdf['report.title'] = title
+        req.hdf['report.id'] = id
+        req.hdf['report.description'] = wiki_to_html(description, self.env, req)
+        if id != -1:
+            self.add_alternate_links(req, args)
+
+        try:
+            cols, rows = self.execute_report(req, db, id, sql, args)
+        except Exception, e:
+            req.hdf['report.message'] = 'Report execution failed: %s' % e
+            return 'report.cs', None
+
+        # Convert the header info to HDF-format
+        idx = 0
+        for col in cols:
+            title=col[0].capitalize()
+            prefix = 'report.headers.%d' % idx
+            req.hdf['%s.real' % prefix] = col[0]
+            if title.startswith('__') and title.endswith('__'):
+                continue
+            elif title[0] == '_' and title[-1] == '_':
+                title = title[1:-1].capitalize()
+                req.hdf[prefix + '.fullrow'] = 1
+            elif title[0] == '_':
+                continue
+            elif title[-1] == '_':
+                title = title[:-1]
+                req.hdf[prefix + '.breakrow'] = 1
+            req.hdf[prefix] = title
+            idx = idx + 1
+
+        if req.args.has_key('sort'):
+            sortCol = req.args.get('sort')
+            colIndex = None
+            hiddenCols = 0
+            for x in range(len(cols)):
+                colName = cols[x][0]
+                if colName == sortCol:
+                    colIndex = x
+                if colName.startswith('__') and colName.endswith('__'):
+                    hiddenCols += 1
+            if colIndex != None:
+                k = 'report.headers.%d.asc' % (colIndex - hiddenCols)
+                asc = req.args.get('asc', None)
+                if asc:
+                    asc = int(asc) # string '0' or '1' to int/boolean
+                else:
+                    asc = 1
+                req.hdf[k] = asc
+                def sortkey(row):
+                    val = row[colIndex]
+                    if isinstance(val, basestring):
+                        val = val.lower()
+                    return val
+                rows = sorted(rows, key=sortkey, reverse=(not asc))
+
+        # Convert the rows and cells to HDF-format
+        row_idx = 0
+        for row in rows:
+            col_idx = 0
+            numrows = len(row)
+            for cell in row:
+                cell = str(cell)
+                column = cols[col_idx][0]
+                value = {}
+                # Special columns begin and end with '__'
+                if column.startswith('__') and column.endswith('__'):
+                    value['hidden'] = 1
+                elif (column[0] == '_' and column[-1] == '_'):
+                    value['fullrow'] = 1
+                    column = column[1:-1]
+                    req.hdf[prefix + '.breakrow'] = 1
+                elif column[-1] == '_':
+                    value['breakrow'] = 1
+                    value['breakafter'] = 1
+                    column = column[:-1]
+                elif column[0] == '_':
+                    value['hidehtml'] = 1
+                    column = column[1:]
+                if column in ('ticket', 'id', '_id', '#', 'summary'):
+                    id_cols = [idx for idx, col in enumerate(cols)
+                               if col[0] in ('ticket', 'id', '_id')]
+                    if id_cols:
+                        id_val = row[id_cols[0]]
+                        value['ticket_href'] = self.env.href.ticket(id_val)
+                elif column == 'description':
+                    descr = wiki_to_html(cell, self.env, req, db,
+                                         absurls=(format == 'rss'))
+                    value['parsed'] = format == 'rss' and str(descr) or descr
+                elif column == 'reporter' and cell.find('@') != -1:
+                    value['rss'] = cell
+                elif column == 'report':
+                    value['report_href'] = self.env.href.report(cell)
+                elif column in ('time', 'date','changetime', 'created', 'modified'):
+                    value['date'] = util.format_date(cell)
+                    value['time'] = util.format_time(cell)
+                    value['datetime'] = util.format_datetime(cell)
+                    value['gmt'] = util.http_date(cell)
+                prefix = 'report.items.%d.%s' % (row_idx, str(column))
+                req.hdf[prefix] = str(cell)
+                for key in value.keys():
+                    req.hdf[prefix + '.' + key] = value[key]
+
+                col_idx += 1
+            row_idx += 1
+        req.hdf['report.numrows'] = row_idx
+
+        if format == 'rss':
+            return 'report_rss.cs', 'application/rss+xml'
+        elif format == 'csv':
+            self._render_csv(req, cols, rows)
+            return None
+        elif format == 'tab':
+            self._render_csv(req, cols, rows, '\t')
+            return None
+
+        return 'report.cs', None
+
+    def add_alternate_links(self, req, args):
+        params = args
+        if req.args.has_key('sort'):
+            params['sort'] = req.args['sort']
+        if req.args.has_key('asc'):
+            params['asc'] = req.args['asc']
+        href = ''
+        if params:
+            href = '&' + urllib.urlencode(params)
+        add_link(req, 'alternate', '?format=rss' + href, 'RSS Feed',
+                 'application/rss+xml', 'rss')
+        add_link(req, 'alternate', '?format=csv' + href,
+                 'Comma-delimited Text', 'text/plain')
+        add_link(req, 'alternate', '?format=tab' + href,
+                 'Tab-delimited Text', 'text/plain')
+        if req.perm.has_permission('REPORT_SQL_VIEW'):
+            add_link(req, 'alternate', '?format=sql', 'SQL Query',
+                     'text/plain')
+
+    def execute_report(self, req, db, id, sql, args):
+        sql, args = self.sql_sub_vars(req, sql, args)
+        if not sql:
+            raise util.TracError('Report %s has no SQL query.' % id)
+        if sql.find('__group__') == -1:
+            req.hdf['report.sorting.enabled'] = 1
+
+        self.log.debug('Executing report with SQL "%s" (%s)', sql, args)
+
+        cursor = db.cursor()
+        cursor.execute(sql, args)
+
+        # FIXME: fetchall should probably not be used.
+        info = cursor.fetchall() or []
+        cols = cursor.description or []
+
+        db.rollback()
+
+        return cols, info
+
+    def get_info(self, db, id, args):
+        if id == -1:
+            # If no particular report was requested, display
+            # a list of available reports instead
+            title = 'Available Reports'
+            sql = 'SELECT id AS report, title FROM report ORDER BY report'
+            description = 'This is a list of reports available.'
+        else:
+            cursor = db.cursor()
+            cursor.execute("SELECT title,sql,description from report "
+                           "WHERE id=%s", (id,))
+            row = cursor.fetchone()
+            if not row:
+                raise util.TracError('Report %d does not exist.' % id,
+                                     'Invalid Report Number')
+            title = row[0] or ''
+            sql = row[1]
+            description = row[2] or ''
+
+        return [title, description, sql]
+
+    def get_var_args(self, req):
+        report_args = {}
+        for arg in req.args.keys():
+            if not arg == arg.upper():
+                continue
+            report_args[arg] = req.args.get(arg)
+
+        # Set some default dynamic variables
+        if not report_args.has_key('USER'):
+            report_args['USER'] = req.authname
+
+        return report_args
+
+    def sql_sub_vars(self, req, sql, args):
+        values = []
+        def add_value(aname):
+            try:
+                arg = args[aname]
+            except KeyError:
+                raise util.TracError("Dynamic variable '$%s' not defined." % aname)
+            req.hdf['report.var.' + aname] = arg
+            values.append(arg)
+
+        # simple parameter substitution outside literal
+        def repl(match):
+            add_value(match.group(1))
+            return '%s'
+
+        # inside a literal break it and concatenate with the parameter
+        def repl_literal(match):
+            add_value(match.group(1))
+            return "' || %s || '"
+
+        var_re = re.compile("[$]([A-Z]+)")
+        sql_io = StringIO()
+
+        # break SQL into literals and non-literals to handle replacing
+        # variables within them with query parameters
+        for expr in re.split("('(?:[^']|(?:''))*')", sql):
+            if expr.startswith("'"):
+                sql_io.write(var_re.sub(repl_literal, expr))
+            else:
+                sql_io.write(var_re.sub(repl, expr))
+        return sql_io.getvalue(), values
+
+    def _render_csv(self, req, cols, rows, sep=','):
+        req.send_response(200)
+        req.send_header('Content-Type', 'text/plain;charset=utf-8')
+        req.end_headers()
+
+        req.write(sep.join([c[0] for c in cols]) + '\r\n')
+        for row in rows:
+            sanitize = lambda x: str(x).replace(sep,"_") \
+                                       .replace('\n',' ') \
+                                       .replace('\r',' ')
+            req.write(sep.join(map(sanitize, row)) + '\r\n')
+
+    def _render_sql(self, req, id, title, description, sql):
+        req.perm.assert_permission('REPORT_SQL_VIEW')
+        req.send_response(200)
+        req.send_header('Content-Type', 'text/plain;charset=utf-8')
+        req.end_headers()
+
+        req.write('-- ## %s: %s ## --\n\n' % (id, title))
+        if description:
+            req.write('-- %s\n\n' % '\n-- '.join(description.splitlines()))
+        req.write(sql)
+        
+    # IWikiSyntaxProvider methods
+    
+    def get_link_resolvers(self):
+        yield ('report', self._format_link)
+
+    def get_wiki_syntax(self):
+        yield (r"!?\{(?P<it_report>%s\s*)?\d+\}" % Formatter.INTERTRAC_SCHEME,
+               lambda x, y, z: self._format_link(x, 'report', y[1:-1], y, z))
+
+    def _format_link(self, formatter, ns, target, label, fullmatch=None):
+        intertrac = formatter.shorthand_intertrac_helper(ns, target, label,
+                                                         fullmatch)
+        if intertrac:
+            return intertrac
+        report, args = target, ''
+        if '?' in target:
+            report, args = target.split('?')
+            args = '?' + args
+        return '<a class="report" href="%s">%s</a>' % (
+               formatter.href.report(report) + args, label)
+
diff -urN trac-trunk/build/lib/trac/ticket/roadmap.py aw-trac/build/lib/trac/ticket/roadmap.py
--- trac-trunk/build/lib/trac/ticket/roadmap.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/ticket/roadmap.py	2006-02-10 06:37:01.000000000 -0800
@@ -0,0 +1,508 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2006 Edgewall Software
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+import re
+from time import localtime, strftime, time
+
+from trac import __version__
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.util import escape, format_date, format_datetime, parse_date, \
+                      pretty_timedelta, shorten_line, unescape, CRLF, Markup
+from trac.ticket import Milestone, Ticket, TicketSystem
+from trac.Timeline import ITimelineEventProvider
+from trac.web import IRequestHandler
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.wiki import wiki_to_html, wiki_to_oneliner, IWikiSyntaxProvider
+
+
+def get_tickets_for_milestone(env, db, milestone, field='component'):
+    cursor = db.cursor()
+    fields = TicketSystem(env).get_ticket_fields()
+    if field in [f['name'] for f in fields if not f.get('custom')]:
+        cursor.execute("SELECT id,status,%s FROM ticket WHERE milestone=%%s "
+                       "ORDER BY %s" % (field, field), (milestone,))
+    else:
+        cursor.execute("SELECT id,status,value FROM ticket LEFT OUTER "
+                       "JOIN ticket_custom ON (id=ticket AND name=%s) "
+                       "WHERE milestone=%s ORDER BY value", (field, milestone))
+    tickets = []
+    for tkt_id, status, fieldval in cursor:
+        tickets.append({'id': tkt_id, 'status': status, field: fieldval})
+    return tickets
+
+def get_query_links(env, milestone, grouped_by='component', group=None):
+    q = {}
+    if not group:
+        q['all_tickets'] = env.href.query(milestone=milestone)
+        q['active_tickets'] = env.href.query(milestone=milestone,
+                                             status=('new', 'assigned', 'reopened'))
+        q['closed_tickets'] = env.href.query(milestone=milestone, status='closed')
+    else:
+        q['all_tickets'] = env.href.query({grouped_by: group},
+                                          milestone=milestone)
+        q['active_tickets'] = env.href.query({grouped_by: group},
+                                             milestone=milestone,
+                                             status=('new', 'assigned', 'reopened'))
+        q['closed_tickets'] = env.href.query({grouped_by: group},
+                                             milestone=milestone,
+                                             status='closed')
+    return q
+
+def calc_ticket_stats(tickets):
+    total_cnt = len(tickets)
+    active = [ticket for ticket in tickets if ticket['status'] != 'closed']
+    active_cnt = len(active)
+    closed_cnt = total_cnt - active_cnt
+
+    percent_active, percent_closed = 0, 0
+    if total_cnt > 0:
+        percent_active = round(float(active_cnt) / float(total_cnt) * 100)
+        percent_closed = round(float(closed_cnt) / float(total_cnt) * 100)
+        if percent_active + percent_closed > 100:
+            percent_closed -= 1
+
+    return {
+        'total_tickets': total_cnt,
+        'active_tickets': active_cnt,
+        'percent_active': percent_active,
+        'closed_tickets': closed_cnt,
+        'percent_closed': percent_closed
+    }
+
+def milestone_to_hdf(env, db, req, milestone):
+    safe_name = None
+    if milestone.exists:
+        safe_name = milestone.name.replace('/', '%2F')
+    hdf = {'name': milestone.name,
+           'href': env.href.milestone(safe_name)}
+    if milestone.description:
+        hdf['description_source'] = milestone.description
+        hdf['description'] = wiki_to_html(milestone.description, env, req, db)
+    if milestone.due:
+        hdf['due'] = milestone.due
+        hdf['due_date'] = format_date(milestone.due)
+        hdf['due_delta'] = pretty_timedelta(milestone.due + 86400)
+        hdf['late'] = milestone.is_late
+    if milestone.completed:
+        hdf['completed'] = milestone.completed
+        hdf['completed_date'] = format_datetime(milestone.completed)
+        hdf['completed_delta'] = pretty_timedelta(milestone.completed)
+    return hdf
+
+def _get_groups(env, db, by='component'):
+    for field in TicketSystem(env).get_ticket_fields():
+        if field['name'] == by:
+            if field.has_key('options'):
+                return field['options']
+            else:
+                cursor = db.cursor()
+                cursor.execute("SELECT DISTINCT %s FROM ticket ORDER BY %s"
+                               % (by, by))
+                return [row[0] for row in cursor]
+    return []
+
+
+class RoadmapModule(Component):
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'roadmap'
+
+    def get_navigation_items(self, req):
+        if not req.perm.has_permission('ROADMAP_VIEW'):
+            return
+        yield ('mainnav', 'roadmap',
+               Markup('<a href="%s" accesskey="3">Roadmap</a>',
+                      self.env.href.roadmap()))
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        return ['ROADMAP_VIEW']
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        return re.match(r'/roadmap/?', req.path_info) is not None
+
+    def process_request(self, req):
+        req.perm.assert_permission('ROADMAP_VIEW')
+        req.hdf['title'] = 'Roadmap'
+
+        showall = req.args.get('show') == 'all'
+        req.hdf['roadmap.showall'] = showall
+
+        db = self.env.get_db_cnx()
+        milestones = [milestone_to_hdf(self.env, db, req, m)
+                      for m in Milestone.select(self.env, showall, db)]
+        req.hdf['roadmap.milestones'] = milestones        
+
+        for idx,milestone in enumerate(milestones):
+            milestone_name = unescape(milestone['name']) # Kludge
+            prefix = 'roadmap.milestones.%d.' % idx
+            tickets = get_tickets_for_milestone(self.env, db, milestone_name,
+                                                'owner')
+            req.hdf[prefix + 'stats'] = calc_ticket_stats(tickets)
+            for k, v in get_query_links(self.env, milestone_name).items():
+                req.hdf[prefix + 'queries.' + k] = v
+            milestone['tickets'] = tickets # for the iCalendar view
+
+        if req.args.get('format') == 'ics':
+            self.render_ics(req, db, milestones)
+            return
+
+        add_stylesheet(req, 'common/css/roadmap.css')
+
+        # FIXME should use the 'webcal:' scheme, probably
+        username = None
+        if req.authname and req.authname != 'anonymous':
+            username = req.authname
+        icshref = self.env.href.roadmap(show=req.args.get('show'),
+                                        user=username, format='ics')
+        add_link(req, 'alternate', icshref, 'iCalendar', 'text/calendar', 'ics')
+
+        return 'roadmap.cs', None
+
+    # Internal methods
+
+    def render_ics(self, req, db, milestones):
+        req.send_response(200)
+        req.send_header('Content-Type', 'text/calendar;charset=utf-8')
+        req.end_headers()
+
+        from trac.ticket import Priority
+        priorities = {}
+        for priority in Priority.select(self.env):
+            priorities[priority.name] = float(priority.value)
+        def get_priority(ticket):
+            value = priorities.get(ticket['priority'])
+            if value:
+                return int(value * 9 / len(priorities))
+
+        def get_status(ticket):
+            status = ticket['status']
+            if status == 'new' or status == 'reopened' and not ticket['owner']:
+                return 'NEEDS-ACTION'
+            elif status == 'assigned' or status == 'reopened':
+                return 'IN-PROCESS'
+            elif status == 'closed':
+                if ticket['resolution'] == 'fixed': return 'COMPLETED'
+                else: return 'CANCELLED'
+            else: return ''
+
+        def write_prop(name, value, params={}):
+            text = ';'.join([name] + [k + '=' + v for k, v in params.items()]) \
+                 + ':' + '\\n'.join(re.split(r'[\r\n]+', value))
+            firstline = 1
+            while text:
+                if not firstline: text = ' ' + text
+                else: firstline = 0
+                req.write(text[:75] + CRLF)
+                text = text[75:]
+
+        def write_date(name, value, params={}):
+            params['VALUE'] = 'DATE'
+            write_prop(name, strftime('%Y%m%d', value), params)
+
+        def write_utctime(name, value, params={}):
+            write_prop(name, strftime('%Y%m%dT%H%M%SZ', value), params)
+
+        host = req.base_url[req.base_url.find('://') + 3:]
+        user = req.args.get('user', 'anonymous')
+
+        write_prop('BEGIN', 'VCALENDAR')
+        write_prop('VERSION', '2.0')
+        write_prop('PRODID', '-//Edgewall Software//NONSGML Trac %s//EN'
+                   % __version__)
+        write_prop('METHOD', 'PUBLISH')
+        write_prop('X-WR-CALNAME',
+                   self.config.get('project', 'name') + ' - Roadmap')
+        for milestone in milestones:
+            uid = '<%s/milestone/%s@%s>' % (req.cgi_location,
+                                            milestone['name'], host)
+            if milestone.has_key('due'):
+                write_prop('BEGIN', 'VEVENT')
+                write_prop('UID', uid)
+                write_date('DTSTAMP', localtime(milestone['due']))
+                write_date('DTSTART', localtime(milestone['due']))
+                write_prop('SUMMARY', 'Milestone %s' % milestone['name'])
+                write_prop('URL', req.base_url + '/milestone/' +
+                           milestone['name'])
+                if milestone.has_key('description_source'):
+                    write_prop('DESCRIPTION', milestone['description_source'])
+                write_prop('END', 'VEVENT')
+            for tkt_id in [ticket['id'] for ticket in milestone['tickets']
+                           if ticket['owner'] == user]:
+                ticket = Ticket(self.env, tkt_id)
+                write_prop('BEGIN', 'VTODO')
+                if milestone.has_key('due'):
+                    write_prop('RELATED-TO', uid)
+                    write_date('DUE', localtime(milestone['due']))
+                write_prop('SUMMARY', 'Ticket #%i: %s' % (ticket.id,
+                                                          ticket['summary']))
+                write_prop('URL', self.env.abs_href.ticket(ticket.id))
+                write_prop('DESCRIPTION', ticket['description'])
+                priority = get_priority(ticket)
+                if priority:
+                    write_prop('PRIORITY', str(priority))
+                write_prop('STATUS', get_status(ticket))
+                if ticket['status'] == 'closed':
+                    cursor = db.cursor()
+                    cursor.execute("SELECT time FROM ticket_change "
+                                   "WHERE ticket=%s AND field='status' "
+                                   "ORDER BY time desc LIMIT 1",
+                                   (ticket.id,))
+                    row = cursor.fetchone()
+                    if row:
+                        write_utctime('COMPLETED', localtime(row[0]))
+                write_prop('END', 'VTODO')
+        write_prop('END', 'VCALENDAR')
+
+
+class MilestoneModule(Component):
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
+               ITimelineEventProvider, IWikiSyntaxProvider)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'roadmap'
+
+    def get_navigation_items(self, req):
+        return []
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        actions = ['MILESTONE_CREATE', 'MILESTONE_DELETE', 'MILESTONE_MODIFY',
+                   'MILESTONE_VIEW']
+        return actions + [('MILESTONE_ADMIN', actions),
+                          ('ROADMAP_ADMIN', actions)]
+
+    # ITimelineEventProvider methods
+
+    def get_timeline_filters(self, req):
+        if req.perm.has_permission('MILESTONE_VIEW'):
+            yield ('milestone', 'Milestones')
+
+    def get_timeline_events(self, req, start, stop, filters):
+        if 'milestone' in filters:
+            format = req.args.get('format')
+            db = self.env.get_db_cnx()
+            cursor = db.cursor()
+            cursor.execute("SELECT completed,name,description FROM milestone "
+                           "WHERE completed>=%s AND completed<=%s",
+                           (start, stop,))
+            for completed, name, description in cursor:
+                title = Markup('Milestone <em>%s</em> completed', name)
+                if format == 'rss':
+                    href = self.env.abs_href.milestone(name)
+                    message = wiki_to_html(description, self.env, db,
+                                           absurls=True)
+                else:
+                    href = self.env.href.milestone(name)
+                    message = wiki_to_oneliner(description, self.env, db,
+                                               shorten=True)
+                yield 'milestone', href, title, completed, None, message or '--'
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        import re, urllib
+        match = re.match(r'/milestone(?:/(.+))?', req.path_info)
+        if match:
+            if match.group(1):
+                req.args['id'] = urllib.unquote(match.group(1))
+            return True
+
+    def process_request(self, req):
+        req.perm.assert_permission('MILESTONE_VIEW')
+
+        add_link(req, 'up', self.env.href.roadmap(), 'Roadmap')
+
+        db = self.env.get_db_cnx()
+        milestone = Milestone(self.env, req.args.get('id'), db)
+        action = req.args.get('action', 'view')
+
+        if req.method == 'POST':
+            if req.args.has_key('cancel'):
+                if milestone.exists:
+                    safe_name = milestone.name.replace('/', '%2F')
+                    req.redirect(self.env.href.milestone(safe_name))
+                else:
+                    req.redirect(self.env.href.roadmap())
+            elif action == 'edit':
+                self._do_save(req, db, milestone)
+            elif action == 'delete':
+                self._do_delete(req, db, milestone)
+        elif action in ('new', 'edit'):
+            self._render_editor(req, db, milestone)
+        elif action == 'delete':
+            self._render_confirm(req, db, milestone)
+        else:
+            self._render_view(req, db, milestone)
+
+        add_stylesheet(req, 'common/css/roadmap.css')
+        return 'milestone.cs', None
+
+    # Internal methods
+
+    def _do_delete(self, req, db, milestone):
+        req.perm.assert_permission('MILESTONE_DELETE')
+
+        retarget_to = None
+        if req.args.has_key('retarget'):
+            retarget_to = req.args.get('target')
+        milestone.delete(retarget_to, req.authname)
+        db.commit()
+        req.redirect(self.env.href.roadmap())
+
+    def _do_save(self, req, db, milestone):
+        if milestone.exists:
+            req.perm.assert_permission('MILESTONE_MODIFY')
+        else:
+            req.perm.assert_permission('MILESTONE_CREATE')
+
+        if not req.args.has_key('name'):
+            raise TracError('You must provide a name for the milestone.',
+                            'Required Field Missing')
+        milestone.name = req.args.get('name')
+
+        due = req.args.get('duedate', '')
+        try:
+            milestone.due = due and parse_date(due) or 0
+        except ValueError, e:
+            raise TracError(e, 'Invalid Date Format')
+        if req.args.has_key('completed'):
+            completed = req.args.get('completeddate', '')
+            try:
+                milestone.completed = completed and parse_date(completed) or 0
+            except ValueError, e:
+                raise TracError(e, 'Invalid Date Format')
+            if milestone.completed > time():
+                raise TracError('Completion date may not be in the future',
+                                'Invalid Completion Date')
+        else:
+            milestone.completed = 0
+
+        milestone.description = req.args.get('description', '')
+
+        if milestone.exists:
+            milestone.update()
+        else:
+            milestone.insert()
+        db.commit()
+
+        safe_name = milestone.name.replace('/', '%2F')
+        req.redirect(self.env.href.milestone(safe_name))
+
+    def _render_confirm(self, req, db, milestone):
+        req.perm.assert_permission('MILESTONE_DELETE')
+
+        req.hdf['title'] = 'Milestone %s' % milestone.name
+        req.hdf['milestone'] = milestone_to_hdf(self.env, db, req, milestone)
+        req.hdf['milestone.mode'] = 'delete'
+
+        for idx,other in enumerate(Milestone.select(self.env, False, db)):
+            if other.name == milestone.name:
+                continue
+            req.hdf['milestones.%d' % idx] = other.name
+
+    def _render_editor(self, req, db, milestone):
+        if milestone.exists:
+            req.perm.assert_permission('MILESTONE_MODIFY')
+            req.hdf['title'] = 'Milestone %s' % milestone.name
+            req.hdf['milestone.mode'] = 'edit'
+        else:
+            req.perm.assert_permission('MILESTONE_CREATE')
+            req.hdf['title'] = 'New Milestone'
+            req.hdf['milestone.mode'] = 'new'
+
+        from trac.util import get_date_format_hint, get_datetime_format_hint
+        req.hdf['milestone'] = milestone_to_hdf(self.env, db, req, milestone)
+        req.hdf['milestone.date_hint'] = get_date_format_hint()
+        req.hdf['milestone.datetime_hint'] = get_datetime_format_hint()
+        req.hdf['milestone.datetime_now'] = format_datetime()
+
+    def _render_view(self, req, db, milestone):
+        req.hdf['title'] = 'Milestone %s' % milestone.name
+        req.hdf['milestone.mode'] = 'view'
+
+        req.hdf['milestone'] = milestone_to_hdf(self.env, db, req, milestone)
+
+        available_groups = []
+        component_group_available = False
+        for field in TicketSystem(self.env).get_ticket_fields():
+            if field['type'] == 'select' and field['name'] != 'milestone' \
+                    or field['name'] == 'owner':
+                available_groups.append({'name': field['name'],
+                                         'label': field['label']})
+                if field['name'] == 'component':
+                    component_group_available = True
+        req.hdf['milestone.stats.available_groups'] = available_groups
+
+        if component_group_available:
+            by = req.args.get('by', 'component')
+        else:
+            by = req.args.get('by', available_groups[0]['name'])
+        req.hdf['milestone.stats.grouped_by'] = by
+
+        tickets = get_tickets_for_milestone(self.env, db, milestone.name, by)
+        stats = calc_ticket_stats(tickets)
+        req.hdf['milestone.stats'] = stats
+        for key, value in get_query_links(self.env, milestone.name).items():
+            req.hdf['milestone.queries.' + key] = value
+
+        groups = _get_groups(self.env, db, by)
+        group_no = 0
+        max_percent_total = 0
+        for group in groups:
+            group_tickets = [t for t in tickets if t[by] == group]
+            if not group_tickets:
+                continue
+            prefix = 'milestone.stats.groups.%s' % group_no
+            req.hdf['%s.name' % prefix] = group
+            percent_total = 0
+            if len(tickets) > 0:
+                percent_total = float(len(group_tickets)) / float(len(tickets))
+                if percent_total > max_percent_total:
+                    max_percent_total = percent_total
+            req.hdf['%s.percent_total' % prefix] = percent_total * 100
+            stats = calc_ticket_stats(group_tickets)
+            req.hdf[prefix] = stats
+            for key, value in get_query_links(self.env, milestone.name,
+                                              by, group).items():
+                req.hdf['%s.queries.%s' % (prefix, key)] = value
+            group_no += 1
+        req.hdf['milestone.stats.max_percent_total'] = max_percent_total * 100
+
+    # IWikiSyntaxProvider methods
+
+    def get_wiki_syntax(self):
+        return []
+
+    def get_link_resolvers(self):
+        yield ('milestone', self._format_link)
+
+    def _format_link(self, formatter, ns, name, label):
+        return '<a class="milestone" href="%s">%s</a>' \
+               % (formatter.href.milestone(name), label)
diff -urN trac-trunk/build/lib/trac/ticket/web_ui.py aw-trac/build/lib/trac/ticket/web_ui.py
--- trac-trunk/build/lib/trac/ticket/web_ui.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/ticket/web_ui.py	2006-01-20 06:56:48.000000000 -0800
@@ -0,0 +1,450 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+import os
+import re
+import time
+
+from trac import util
+from trac.attachment import attachment_to_hdf, Attachment
+from trac.core import *
+from trac.env import IEnvironmentSetupParticipant
+from trac.ticket import Milestone, Ticket, TicketSystem
+from trac.ticket.notification import TicketNotifyEmail
+from trac.Timeline import ITimelineEventProvider
+from trac.web import IRequestHandler
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.wiki import wiki_to_html, wiki_to_oneliner
+
+
+class NewticketModule(Component):
+
+    implements(IEnvironmentSetupParticipant, INavigationContributor,
+               IRequestHandler)
+
+    # IEnvironmentSetupParticipant methods
+
+    def environment_created(self):
+        """Create the `site_newticket.cs` template file in the environment."""
+        if self.env.path:
+            templates_dir = os.path.join(self.env.path, 'templates')
+            if not os.path.exists(templates_dir):
+                os.mkdir(templates_dir)
+            template_name = os.path.join(templates_dir, 'site_newticket.cs')
+            template_file = file(template_name, 'w')
+            template_file.write("""<?cs
+####################################################################
+# New ticket prelude - Included directly above the new ticket form
+?>
+""")
+
+    def environment_needs_upgrade(self, db):
+        return False
+
+    def upgrade_environment(self, db):
+        pass
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'newticket'
+
+    def get_navigation_items(self, req):
+        if not req.perm.has_permission('TICKET_CREATE'):
+            return
+        yield ('mainnav', 'newticket', 
+               util.Markup('<a href="%s" accesskey="7">New Ticket</a>',
+                           self.env.href.newticket()))
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        return re.match(r'/newticket/?', req.path_info) is not None
+
+    def process_request(self, req):
+        req.perm.assert_permission('TICKET_CREATE')
+
+        db = self.env.get_db_cnx()
+
+        if req.method == 'POST' and not req.args.has_key('preview'):
+            self._do_create(req, db)
+
+        ticket = Ticket(self.env, db=db)
+        ticket.populate(req.args)
+        ticket.values.setdefault('reporter', util.get_reporter_id(req))
+
+        if ticket.values.has_key('description'):
+            description = wiki_to_html(ticket['description'], self.env, req, db)
+            req.hdf['newticket.description_preview'] = description
+
+        req.hdf['title'] = 'New Ticket'
+        req.hdf['newticket'] = ticket.values
+
+        field_names = [field['name'] for field in ticket.fields
+                       if not field.get('custom')]
+        if 'owner' in field_names:
+            curr_idx = field_names.index('owner')
+            if 'cc' in field_names:
+                insert_idx = field_names.index('cc')
+            else:
+                insert_idx = len(field_names)
+            if curr_idx < insert_idx:
+                ticket.fields.insert(insert_idx, ticket.fields[curr_idx])
+                del ticket.fields[curr_idx]
+
+        for field in ticket.fields:
+            name = field['name']
+            del field['name']
+            if name in ('summary', 'reporter', 'description', 'type', 'status',
+                        'resolution'):
+                field['skip'] = True
+            elif name == 'owner':
+                field['label'] = 'Assign to'
+            elif name == 'milestone':
+                # Don't make completed milestones available for selection
+                options = field['options'][:]
+                for option in field['options']:
+                    milestone = Milestone(self.env, option, db=db)
+                    if milestone.is_completed:
+                        options.remove(option)
+                field['options'] = options
+            req.hdf['newticket.fields.' + name] = field
+
+        add_stylesheet(req, 'common/css/ticket.css')
+        return 'newticket.cs', None
+
+    # Internal methods
+
+    def _do_create(self, req, db):
+        if not req.args.get('summary'):
+            raise TracError('Tickets must contain a summary.')
+
+        ticket = Ticket(self.env, db=db)
+        ticket.values.setdefault('reporter', util.get_reporter_id(req))
+        ticket.populate(req.args)
+        ticket.insert(db=db)
+        db.commit()
+
+        # Notify
+        try:
+            tn = TicketNotifyEmail(self.env)
+            tn.notify(ticket, newticket=True)
+        except Exception, e:
+            self.log.exception("Failure sending notification on creation of "
+                               "ticket #%s: %s" % (ticket.id, e))
+
+        # Redirect the user to the newly created ticket
+        req.redirect(self.env.href.ticket(ticket.id))
+
+
+class TicketModule(Component):
+
+    implements(INavigationContributor, IRequestHandler, ITimelineEventProvider)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'tickets'
+
+    def get_navigation_items(self, req):
+        return []
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        match = re.match(r'/ticket/([0-9]+)', req.path_info)
+        if match:
+            req.args['id'] = match.group(1)
+            return True
+
+    def process_request(self, req):
+        req.perm.assert_permission('TICKET_VIEW')
+
+        action = req.args.get('action', 'view')
+
+        if not req.args.has_key('id'):
+            req.redirect(self.env.href.wiki())
+
+        db = self.env.get_db_cnx()
+        id = int(req.args.get('id'))
+
+        ticket = Ticket(self.env, id, db=db)
+        reporter_id = util.get_reporter_id(req)
+
+        if req.method == 'POST':
+            if not req.args.has_key('preview'):
+                self._do_save(req, db, ticket)
+            else:
+                # Use user supplied values
+                ticket.populate(req.args)
+                req.hdf['ticket.action'] = action
+                req.hdf['ticket.ts'] = req.args.get('ts')
+                req.hdf['ticket.reassign_owner'] = req.args.get('reassign_owner') \
+                                                   or req.authname
+                req.hdf['ticket.resolve_resolution'] = req.args.get('resolve_resolution')
+                reporter_id = req.args.get('author')
+                comment = req.args.get('comment')
+                if comment:
+                    req.hdf['ticket.comment'] = comment
+                    # Wiki format a preview of comment
+                    req.hdf['ticket.comment_preview'] = wiki_to_html(comment,
+                                                                     self.env,
+                                                                     req, db)
+        else:
+            req.hdf['ticket.reassign_owner'] = req.authname
+            # Store a timestamp in order to detect "mid air collisions"
+            req.hdf['ticket.ts'] = ticket.time_changed
+
+        self._insert_ticket_data(req, db, ticket, reporter_id)
+
+        # If the ticket is being shown in the context of a query, add
+        # links to help navigate in the query result set
+        if 'query_tickets' in req.session:
+            tickets = req.session['query_tickets'].split()
+            if str(id) in tickets:
+                idx = tickets.index(str(ticket.id))
+                if idx > 0:
+                    add_link(req, 'first', self.env.href.ticket(tickets[0]),
+                             'Ticket #%s' % tickets[0])
+                    add_link(req, 'prev', self.env.href.ticket(tickets[idx - 1]),
+                             'Ticket #%s' % tickets[idx - 1])
+                if idx < len(tickets) - 1:
+                    add_link(req, 'next', self.env.href.ticket(tickets[idx + 1]),
+                             'Ticket #%s' % tickets[idx + 1])
+                    add_link(req, 'last', self.env.href.ticket(tickets[-1]),
+                             'Ticket #%s' % tickets[-1])
+                add_link(req, 'up', req.session['query_href'])
+
+        add_stylesheet(req, 'common/css/ticket.css')
+        return 'ticket.cs', None
+
+    # ITimelineEventProvider methods
+
+    def get_timeline_filters(self, req):
+        if req.perm.has_permission('TICKET_VIEW'):
+            yield ('ticket', 'Ticket changes')
+            if self.config.getbool('timeline', 'ticket_show_details'):
+                yield ('ticket_details', 'Ticket details', False)
+
+    def get_timeline_events(self, req, start, stop, filters):
+        format = req.args.get('format')
+
+        status_map = {'new': ('newticket', 'created'),
+                      'reopened': ('newticket', 'reopened'),
+                      'closed': ('closedticket', 'closed'),
+                      'edit': ('editedticket', 'updated')}
+
+        def produce((id, t, author, type, summary), status, fields, comment):
+            if status == 'edit':
+                if 'ticket_details' in filters:
+                    info = ''
+                    if len(fields) > 0:
+                        info = ', '.join(['<i>%s</i>' % f for f in \
+                                          fields.keys()]) + ' changed<br />'
+                else:
+                    return None
+            elif 'ticket' in filters:
+                if status == 'closed' and fields.has_key('resolution'):
+                    info = fields['resolution']
+                    if info and comment:
+                        info = '%s: ' % info
+                else:
+                    info = ''
+            else:
+                return None
+            kind, verb = status_map[status]
+            title = util.Markup('Ticket <em title="%s">#%s</em> (%s) %s by %s',
+                                summary, id, type, verb, author)
+            href = format == 'rss' and self.env.abs_href.ticket(id) or \
+                   self.env.href.ticket(id)
+
+            if status == 'new':
+                message = summary
+            else:
+                message = util.Markup(info)
+                if comment:
+                    if format == 'rss':
+                        message += wiki_to_html(comment, self.env, req, db,
+                                                absurls=True)
+                    else:
+                        message += wiki_to_oneliner(comment, self.env, db,
+                                                    shorten=True)
+            return kind, href, title, t, author, message
+
+        # Ticket changes
+        if 'ticket' in filters or 'ticket_details' in filters:
+            db = self.env.get_db_cnx()
+            cursor = db.cursor()
+
+            cursor.execute("SELECT t.id,tc.time,tc.author,t.type,t.summary, "
+                           "       tc.field,tc.oldvalue,tc.newvalue "
+                           "  FROM ticket_change tc "
+                           "    INNER JOIN ticket t ON t.id = tc.ticket "
+                           "      AND tc.time>=%s AND tc.time<=%s "
+                           "ORDER BY tc.time"
+                           % (start, stop))
+            previous_update = None
+            for id,t,author,type,summary,field,oldvalue,newvalue in cursor:
+                if not previous_update or (id,t,author) != previous_update[:3]:
+                    if previous_update:
+                        ev = produce(previous_update, status, fields, comment)
+                        if ev:
+                            yield ev
+                    status, fields, comment = 'edit', {}, ''
+                    previous_update = (id,t,author, type, summary)
+                if field == 'comment':
+                    comment = newvalue
+                elif field == 'status' and newvalue in ('reopened', 'closed'):
+                    status = newvalue
+                else:
+                    fields[field] = newvalue
+            if previous_update:
+                ev = produce(previous_update, status, fields, comment)
+                if ev:
+                    yield ev
+            
+            # New tickets
+            if 'ticket' in filters:
+                cursor.execute("SELECT id,time,reporter,type,summary"
+                               "  FROM ticket WHERE time>=%s AND time<=%s",
+                               (start, stop))
+                for row in cursor:
+                    yield produce(row, 'new', {}, None)
+ 
+
+    # Internal methods
+
+    def _do_save(self, req, db, ticket):
+        if req.perm.has_permission('TICKET_CHGPROP'):
+            # TICKET_CHGPROP gives permission to edit the ticket
+            if not req.args.get('summary'):
+                raise TracError('Tickets must contain summary.')
+
+            if req.args.has_key('description') or req.args.has_key('reporter'):
+                req.perm.assert_permission('TICKET_ADMIN')
+
+            ticket.populate(req.args)
+        else:
+            req.perm.assert_permission('TICKET_APPEND')
+
+        # Mid air collision?
+        if int(req.args.get('ts')) != ticket.time_changed:
+            raise TracError("Sorry, can not save your changes. "
+                            "This ticket has been modified by someone else "
+                            "since you started", 'Mid Air Collision')
+
+        # Do any action on the ticket?
+        action = req.args.get('action')
+        actions = TicketSystem(self.env).get_available_actions(ticket, req.perm)
+        if action not in actions:
+            raise TracError('Invalid action')
+
+        # TODO: this should not be hard-coded like this
+        if action == 'accept':
+            ticket['status'] =  'assigned'
+            ticket['owner'] = req.authname
+        if action == 'resolve':
+            ticket['status'] = 'closed'
+            ticket['resolution'] = req.args.get('resolve_resolution')
+        elif action == 'reassign':
+            ticket['owner'] = req.args.get('reassign_owner')
+            ticket['status'] = 'new'
+        elif action == 'reopen':
+            ticket['status'] = 'reopened'
+            ticket['resolution'] = ''
+
+        now = int(time.time())
+        ticket.save_changes(req.args.get('author', req.authname),
+                            req.args.get('comment'), when=now, db=db)
+        db.commit()
+
+        try:
+            tn = TicketNotifyEmail(self.env)
+            tn.notify(ticket, newticket=False, modtime=now)
+        except Exception, e:
+            self.log.exception("Failure sending notification on change to "
+                               "ticket #%s: %s" % (ticket.id, e))
+
+        req.redirect(self.env.href.ticket(ticket.id))
+
+    def _insert_ticket_data(self, req, db, ticket, reporter_id):
+        """Insert ticket data into the hdf"""
+        req.hdf['ticket'] = ticket.values
+        req.hdf['ticket.id'] = ticket.id
+        req.hdf['ticket.href'] = self.env.href.ticket(ticket.id)
+
+        for field in TicketSystem(self.env).get_ticket_fields():
+            if field['type'] in ('radio', 'select'):
+                value = ticket.values.get(field['name'])
+                options = field['options']
+                if value and not value in options:
+                    # Current ticket value must be visible even if its not in the
+                    # possible values
+                    options.append(value)
+                field['options'] = options
+            name = field['name']
+            del field['name']
+            if name in ('summary', 'reporter', 'description', 'type', 'status',
+                        'resolution', 'owner'):
+                field['skip'] = True
+            req.hdf['ticket.fields.' + name] = field
+
+        req.hdf['ticket.reporter_id'] = reporter_id
+        req.hdf['title'] = '#%d (%s)' % (ticket.id, ticket['summary'])
+        req.hdf['ticket.description.formatted'] = wiki_to_html(ticket['description'],
+                                                               self.env, req, db)
+
+        req.hdf['ticket.opened'] = util.format_datetime(ticket.time_created)
+        req.hdf['ticket.opened_delta'] = util.pretty_timedelta(ticket.time_created)
+        if ticket.time_changed != ticket.time_created:
+            req.hdf['ticket.lastmod'] = util.format_datetime(ticket.time_changed)
+            req.hdf['ticket.lastmod_delta'] = util.pretty_timedelta(ticket.time_changed)
+
+        changelog = ticket.get_changelog(db=db)
+        curr_author = None
+        curr_date   = 0
+        changes = []
+        for date, author, field, old, new in changelog:
+            if date != curr_date or author != curr_author:
+                changes.append({
+                    'date': util.format_datetime(date),
+                    'author': author,
+                    'fields': {}
+                })
+                curr_date = date
+                curr_author = author
+            if field == 'comment':
+                changes[-1]['comment'] = wiki_to_html(new, self.env, req, db)
+            elif field == 'description':
+                changes[-1]['fields'][field] = ''
+            else:
+                changes[-1]['fields'][field] = {'old': old,
+                                                'new': new}
+        req.hdf['ticket.changes'] = changes
+
+        # List attached files
+        for idx, attachment in enumerate(Attachment.select(self.env, 'ticket',
+                                                           ticket.id)):
+            hdf = attachment_to_hdf(self.env, db, req, attachment)
+            req.hdf['ticket.attachments.%s' % idx] = hdf
+        if req.perm.has_permission('TICKET_APPEND'):
+            req.hdf['ticket.attach_href'] = self.env.href.attachment('ticket',
+                                                                     ticket.id)
+
+        # Add the possible actions to hdf
+        actions = TicketSystem(self.env).get_available_actions(ticket, req.perm)
+        for action in actions:
+            req.hdf['ticket.actions.' + action] = '1'
diff -urN trac-trunk/build/lib/trac/upgrades/db10.py aw-trac/build/lib/trac/upgrades/db10.py
--- trac-trunk/build/lib/trac/upgrades/db10.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db10.py	2005-07-24 15:18:30.000000000 -0700
@@ -0,0 +1,25 @@
+sql = [
+#-- Make the node_change table contain more information, and force a resync
+"""DROP TABLE revision;""",
+"""DROP TABLE node_change;""",
+"""CREATE TABLE revision (
+    rev             text PRIMARY KEY,
+    time            integer,
+    author          text,
+    message         text
+);""",
+"""CREATE TABLE node_change (
+    rev             text,
+    path            text,
+    kind            char(1), -- 'D' for directory, 'F' for file
+    change          char(1),
+    base_path       text,
+    base_rev        text,
+    UNIQUE(rev, path, change)
+);"""
+]
+
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
+    print 'Please perform a "resync" after this upgrade.'
diff -urN trac-trunk/build/lib/trac/upgrades/db11.py aw-trac/build/lib/trac/upgrades/db11.py
--- trac-trunk/build/lib/trac/upgrades/db11.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db11.py	2005-07-24 15:18:30.000000000 -0700
@@ -0,0 +1,32 @@
+import os.path
+
+sql = [
+#-- Remove empty values from the milestone list
+"""DELETE FROM milestone WHERE COALESCE(name,'')='';""",
+#-- Add a description column to the version table, and remove unnamed versions
+"""CREATE TEMP TABLE version_old AS SELECT * FROM version;""",
+"""DROP TABLE version;""",
+"""CREATE TABLE version (
+        name            text PRIMARY KEY,
+        time            integer,
+        description     text
+);""",
+"""INSERT INTO version(name,time,description)
+    SELECT name,time,'' FROM version_old WHERE COALESCE(name,'')<>'';""",
+#-- Add a description column to the component table, and remove unnamed components
+"""CREATE TEMP TABLE component_old AS SELECT * FROM component;""",
+"""DROP TABLE component;""",
+"""CREATE TABLE component (
+        name            text PRIMARY KEY,
+        owner           text,
+        description     text
+);""",
+"""INSERT INTO component(name,owner,description)
+    SELECT name,owner,'' FROM component_old WHERE COALESCE(name,'')<>'';""",
+"""DROP TABLE version_old;""",
+"""DROP TABLE component_old;"""
+]
+
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
diff -urN trac-trunk/build/lib/trac/upgrades/db12.py aw-trac/build/lib/trac/upgrades/db12.py
--- trac-trunk/build/lib/trac/upgrades/db12.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db12.py	2005-07-24 15:18:30.000000000 -0700
@@ -0,0 +1,26 @@
+sql = [
+#-- Some anonymous session might have been left over
+"""DELETE FROM session WHERE username='anonymous';""",
+#-- Schema change: use an authenticated flag instead of separate sid/username
+#-- columns
+"""CREATE TEMP TABLE session_old AS SELECT * FROM session;""",
+"""DROP TABLE session;""",
+"""CREATE TABLE session (
+        sid             text,
+        authenticated   int,
+        var_name        text,
+        var_value       text,
+        UNIQUE(sid, var_name)
+);""",
+"""INSERT INTO session(sid,authenticated,var_name,var_value)
+    SELECT DISTINCT sid,0,var_name,var_value FROM session_old
+    WHERE sid IS NULL;""",
+"""INSERT INTO session(sid,authenticated,var_name,var_value)
+    SELECT DISTINCT username,1,var_name,var_value FROM session_old
+    WHERE sid IS NULL;""",
+"""DROP TABLE session_old;"""
+]
+
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
diff -urN trac-trunk/build/lib/trac/upgrades/db13.py aw-trac/build/lib/trac/upgrades/db13.py
--- trac-trunk/build/lib/trac/upgrades/db13.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db13.py	2006-01-02 13:45:52.000000000 -0800
@@ -0,0 +1,60 @@
+sql = [
+#-- Add ticket_type to 'ticket', remove the unused 'url' column
+"""CREATE TEMP TABLE ticket_old AS SELECT * FROM ticket;""",
+"""DROP TABLE ticket;""",
+"""CREATE TABLE ticket (
+        id              integer PRIMARY KEY,
+        type            text,           -- the nature of the ticket
+        time            integer,        -- the time it was created
+        changetime      integer,
+        component       text,
+        severity        text,
+        priority        text,
+        owner           text,           -- who is this ticket assigned to
+        reporter        text,
+        cc              text,           -- email addresses to notify
+        version         text,           --
+        milestone       text,           --
+        status          text,
+        resolution      text,
+        summary         text,           -- one-line summary
+        description     text,           -- problem description (long)
+        keywords        text
+);""",
+"""INSERT INTO ticket(id, type, time, changetime, component, severity, priority,
+                   owner, reporter, cc, version, milestone, status, resolution,
+                   summary, description, keywords)
+  SELECT id, 'defect', time, changetime, component, severity, priority, owner,
+         reporter, cc, version, milestone, status, resolution, summary,
+         description, keywords FROM ticket_old
+  WHERE COALESCE(severity,'') <> 'enhancement';""",
+"""INSERT INTO ticket(id, type, time, changetime, component, severity, priority,
+                   owner, reporter, cc, version, milestone, status, resolution,
+                   summary, description, keywords)
+  SELECT id, 'enhancement', time, changetime, component, 'normal', priority,
+         owner, reporter, cc, version, milestone, status, resolution, summary,
+         description, keywords FROM ticket_old
+  WHERE severity = 'enhancement';""",
+"""INSERT INTO enum (type, name, value) VALUES ('ticket_type', 'defect', '1');""",
+"""INSERT INTO enum (type, name, value) VALUES ('ticket_type', 'enhancement', '2');""",
+"""INSERT INTO enum (type, name, value) VALUES ('ticket_type', 'task', '3');""",
+"""DELETE FROM enum WHERE type = 'severity' AND name = 'enhancement';""",
+"""DROP TABLE ticket_old;""",
+]
+
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
+
+    # -- upgrade reports (involve a rename)
+    cursor.execute("SELECT id,sql FROM report")
+    reports = {}
+    for id, rsql in cursor:
+        reports[id] = rsql
+    for id, rsql in reports.items():
+        parts = rsql.split('ORDER BY', 1)
+        ending = len(parts)>1 and 'ORDER BY'+parts[1] or ''
+        cursor.execute("UPDATE report SET sql=%s WHERE id=%s",
+                       (parts[0].replace('severity,',
+                                         't.type AS type, severity,') + ending,
+                        id))
diff -urN trac-trunk/build/lib/trac/upgrades/db14.py aw-trac/build/lib/trac/upgrades/db14.py
--- trac-trunk/build/lib/trac/upgrades/db14.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db14.py	2005-09-05 13:29:44.000000000 -0700
@@ -0,0 +1,32 @@
+sql = [
+"""CREATE TEMP TABLE node_change_old AS SELECT * FROM node_change;""",
+"""DROP TABLE node_change;""",
+"""CREATE TABLE node_change (
+    rev             text,
+    path            text,
+    kind            char(1),
+    change          char(1),
+    base_path       text,
+    base_rev        text,
+    UNIQUE(rev, path, change)
+);""",
+"""INSERT INTO node_change (rev,path,kind,change,base_path,base_rev)
+    SELECT rev,path,kind,change,base_path,base_rev FROM node_change_old;"""
+]
+
+def do_upgrade(env, ver, cursor):
+    # Wiki pages were accidentially created with the version number starting at
+    # 0 instead of 1; This should fix that
+    cursor.execute("SELECT name, version FROM wiki WHERE name IN "
+                   "(SELECT name FROM wiki WHERE version=0) ORDER BY name,"
+                   "version DESC")
+    result = cursor.fetchall()
+    if result:
+        cursor.executemany("UPDATE wiki SET version=version+1 WHERE name=%s " 
+                           "and version=%s",
+                           [tuple(row) for row in result])
+
+    # Correct difference between db_default.py and upgrades/db10.py: The
+    # 'change' was missing from the uniqueness constraint
+    for s in sql:
+        cursor.execute(s)
diff -urN trac-trunk/build/lib/trac/upgrades/db15.py aw-trac/build/lib/trac/upgrades/db15.py
--- trac-trunk/build/lib/trac/upgrades/db15.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db15.py	2005-11-27 09:20:19.000000000 -0800
@@ -0,0 +1,19 @@
+from trac.db import Table, Column, Index, DatabaseManager
+
+def do_upgrade(env, ver, cursor):
+    cursor.execute("CREATE TEMP TABLE session_old AS SELECT * FROM session")
+    cursor.execute("DROP TABLE session")
+
+    db = env.get_db_cnx()
+    session_table = Table('session', key=('sid', 'authenticated', 'var_name'))[
+        Column('sid'),
+        Column('authenticated', type='int'),
+        Column('var_name'),
+        Column('var_value')]
+    db_backend, _ = DatabaseManager(env)._get_connector()
+    for stmt in db_backend.to_sql(session_table):
+        cursor.execute(stmt)
+
+    cursor.execute("INSERT INTO session (sid,authenticated,var_name,var_value) "
+                   "SELECT sid,authenticated,var_name,var_value "
+                   "FROM session_old")
diff -urN trac-trunk/build/lib/trac/upgrades/db16.py aw-trac/build/lib/trac/upgrades/db16.py
--- trac-trunk/build/lib/trac/upgrades/db16.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db16.py	2005-10-30 13:20:55.000000000 -0800
@@ -0,0 +1,18 @@
+from trac.db import Table, Column, Index
+
+def do_upgrade(env, ver, cursor):
+    # Add a few new indices to speed things up
+    cursor.execute("CREATE INDEX wiki_time_idx ON wiki (time)")
+    cursor.execute("CREATE INDEX revision_time_idx ON revision (time)")
+    cursor.execute("CREATE INDEX ticket_status_idx ON ticket (status)")
+    cursor.execute("CREATE INDEX ticket_time_idx ON ticket (time)")
+
+    # Fix missing single column primary key constraints
+    if env.config.get('trac', 'database').startswith('postgres'):
+        cursor.execute("ALTER TABLE system ADD CONSTRAINT system_pkey PRIMARY KEY (name)")
+        cursor.execute("ALTER TABLE revision ADD CONSTRAINT revision_pkey PRIMARY KEY (rev)")
+        cursor.execute("ALTER TABLE ticket ADD CONSTRAINT ticket_pkey PRIMARY KEY (id)")
+        cursor.execute("ALTER TABLE component ADD CONSTRAINT component_pkey PRIMARY KEY (name)")
+        cursor.execute("ALTER TABLE milestone ADD CONSTRAINT milestone_pkey PRIMARY KEY (name)")
+        cursor.execute("ALTER TABLE version ADD CONSTRAINT version_pkey PRIMARY KEY (name)")
+        cursor.execute("ALTER TABLE report ADD CONSTRAINT report_pkey PRIMARY KEY (id)")
diff -urN trac-trunk/build/lib/trac/upgrades/db17.py aw-trac/build/lib/trac/upgrades/db17.py
--- trac-trunk/build/lib/trac/upgrades/db17.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db17.py	2006-02-10 01:37:26.000000000 -0800
@@ -0,0 +1,25 @@
+from trac.db import Table, Column, Index, DatabaseManager
+
+def do_upgrade(env, ver, cursor):
+    """Rename the columns `kind` and `change` in the `node_change` table for
+    compatibity with MySQL.
+    """
+    cursor.execute("CREATE TEMP TABLE nc_old AS SELECT * FROM node_change")
+    cursor.execute("DROP TABLE node_change")
+
+    table = Table('node_change', key=('rev', 'path', 'change_type'))[
+        Column('rev'),
+        Column('path'),
+        Column('node_type', size=1),
+        Column('change_type', size=1),
+        Column('base_path'),
+        Column('base_rev'),
+        Index(['rev'])
+    ]
+    db_connector, _ = DatabaseManager(env)._get_connector()
+    for stmt in db_connector.to_sql(table):
+        cursor.execute(stmt)
+
+    cursor.execute("INSERT INTO node_change (rev,path,node_type,change_type,"
+                   "base_path,base_rev) SELECT rev,path,kind,change,"
+                   "base_path,base_rev FROM nc_old")
diff -urN trac-trunk/build/lib/trac/upgrades/db3.py aw-trac/build/lib/trac/upgrades/db3.py
--- trac-trunk/build/lib/trac/upgrades/db3.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db3.py	2005-04-04 10:00:51.000000000 -0700
@@ -0,0 +1,18 @@
+sql = """
+CREATE TABLE attachment (
+         type            text,
+         id              text,
+         filename        text,
+         size            integer,
+         time            integer,
+         description     text,
+         author          text,
+         ipnr            text,
+         UNIQUE(type,id,filename)
+);
+"""
+
+def do_upgrade(env, ver, cursor):
+    cursor.execute(sql)
+    env.config.set('attachment', 'max_size', '262144')
+    env.config.save()
diff -urN trac-trunk/build/lib/trac/upgrades/db4.py aw-trac/build/lib/trac/upgrades/db4.py
--- trac-trunk/build/lib/trac/upgrades/db4.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db4.py	2005-07-24 15:18:30.000000000 -0700
@@ -0,0 +1,14 @@
+sql = [
+"""CREATE TABLE session (
+         sid             text,
+         username        text,
+         var_name        text,
+         var_value       text,
+         UNIQUE(sid,var_name)
+);""",
+"""CREATE INDEX session_idx ON session(sid,var_name);"""
+]
+
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
diff -urN trac-trunk/build/lib/trac/upgrades/db5.py aw-trac/build/lib/trac/upgrades/db5.py
--- trac-trunk/build/lib/trac/upgrades/db5.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db5.py	2005-07-24 15:18:30.000000000 -0700
@@ -0,0 +1,18 @@
+sql = [
+#-- Add unique id, descr to 'milestone'
+"""CREATE TEMP TABLE milestone_old AS SELECT * FROM milestone;""",
+"""DROP TABLE milestone;""",
+"""CREATE TABLE milestone (
+         id              integer PRIMARY KEY,
+         name            text,
+         time            integer,
+         descr           text,
+         UNIQUE(name)
+);""",
+"""
+INSERT INTO milestone(name,time, descr) SELECT name,time,'' FROM milestone_old;""",
+"""DROP TABLE milestone_old;""",
+]
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
diff -urN trac-trunk/build/lib/trac/upgrades/db6.py aw-trac/build/lib/trac/upgrades/db6.py
--- trac-trunk/build/lib/trac/upgrades/db6.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db6.py	2004-05-31 14:13:06.000000000 -0700
@@ -0,0 +1,12 @@
+sql = """
+CREATE TABLE ticket_custom (
+       ticket               integer,
+       name             text,
+       value            text,
+       UNIQUE(ticket,name)
+);
+"""
+
+def do_upgrade(env, ver, cursor):
+    cursor.execute(sql)
+
diff -urN trac-trunk/build/lib/trac/upgrades/db7.py aw-trac/build/lib/trac/upgrades/db7.py
--- trac-trunk/build/lib/trac/upgrades/db7.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db7.py	2005-07-24 15:18:30.000000000 -0700
@@ -0,0 +1,21 @@
+sql = [
+#-- Add readonly flag to 'wiki'
+"""CREATE TEMP TABLE wiki_old AS SELECT * FROM wiki;""",
+"""DROP TABLE wiki;""",
+"""CREATE TABLE wiki (
+         name            text,
+         version         integer,
+         time            integer,
+         author          text,
+         ipnr            text,
+         text            text,
+         comment         text,
+         readonly        integer,
+         UNIQUE(name,version)
+);""",
+"""INSERT INTO wiki(name,version,time,author,ipnr,text,comment,readonly) SELECT name,version,time,author,ipnr,text,comment,0 FROM wiki_old;"""
+]
+
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
diff -urN trac-trunk/build/lib/trac/upgrades/db8.py aw-trac/build/lib/trac/upgrades/db8.py
--- trac-trunk/build/lib/trac/upgrades/db8.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db8.py	2005-07-24 15:18:30.000000000 -0700
@@ -0,0 +1,22 @@
+import time
+
+d = {'now':time.time()}
+sql = [
+#-- Separate between due and completed time for milestones.
+"""CREATE TEMP TABLE milestone_old AS SELECT * FROM milestone;""",
+"""DROP TABLE milestone;""",
+"""CREATE TABLE milestone (
+         name            text PRIMARY KEY,
+         due             integer, -- Due date/time
+         completed       integer, -- Completed date/time
+         description     text
+);""",
+"""INSERT INTO milestone(name,due,completed,description)
+SELECT name,time,time,descr FROM milestone_old WHERE time <= %(now)s;""" % d,
+"""INSERT INTO milestone(name,due,description)
+SELECT name,time,descr FROM milestone_old WHERE time > %(now)s;""" % d
+]
+
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
diff -urN trac-trunk/build/lib/trac/upgrades/db9.py aw-trac/build/lib/trac/upgrades/db9.py
--- trac-trunk/build/lib/trac/upgrades/db9.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/upgrades/db9.py	2005-07-24 15:18:30.000000000 -0700
@@ -0,0 +1,22 @@
+import time
+
+sql = [
+#-- Remove the unused lock table
+"""DROP TABLE lock;""",
+#-- Separate anonymous from authenticated sessions.
+"""CREATE TEMP TABLE session_old AS SELECT * FROM session;""",
+"""DELETE FROM session;""",
+"""INSERT INTO session (username,var_name,var_value)
+  SELECT username,var_name,var_value FROM session_old
+  WHERE sid IN (SELECT DISTINCT sid FROM session_old
+    WHERE username!='anonymous' AND var_name='last_visit'
+    GROUP BY username ORDER BY var_value DESC);""",
+"""INSERT INTO session (sid,username,var_name,var_value)
+  SELECT sid,username,var_name,var_value FROM session_old
+  WHERE username='anonymous';""",
+"""DROP TABLE session_old;"""
+]
+
+def do_upgrade(env, ver, cursor):
+    for s in sql:
+        cursor.execute(s)
diff -urN trac-trunk/build/lib/trac/util.py aw-trac/build/lib/trac/util.py
--- trac-trunk/build/lib/trac/util.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/util.py	2006-03-08 01:34:50.000000000 -0800
@@ -0,0 +1,603 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2004 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2006 Matthew Good <trac@matt-good.net>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Matthew Good <trac@matt-good.net>
+
+import cgi
+import md5
+import os
+import re
+try:
+    frozenset
+except NameError:
+    from sets import ImmutableSet as frozenset
+import sys
+import time
+import tempfile
+
+# Imports for backward compatibility
+from trac.core import TracError
+
+CRLF = '\r\n'
+
+try:
+    reversed = reversed
+except NameError:
+    def reversed(x):
+        if hasattr(x, 'keys'):
+            raise ValueError('mappings do not support reverse iteration')
+        i = len(x)
+        while i > 0:
+            i -= 1
+            yield x[i]
+
+try:
+    sorted = sorted
+except NameError:
+    def sorted(iterable, cmp=None, key=None, reverse=False):
+        """Partial implementation of the "sorted" function from Python 2.4"""
+        lst = [(key(i), i) for i in iterable]
+        lst.sort()
+        if reverse:
+            lst = reversed(lst)
+        return [i for __, i in lst]
+
+class Markup(str):
+    """Marks a string as being safe for inclusion in XML output without needing
+    to be escaped.
+    
+    Strings are normally automatically escaped when added to the HDF.
+    `Markup`-strings are however an exception. Use with care.
+    
+    (since Trac 0.9.3)
+    """
+    def __new__(self, text='', *args):
+        if args:
+            text %= tuple([escape(arg) for arg in args])
+        return str.__new__(self, text)
+
+    def __add__(self, other):
+        return Markup(str(self) + Markup.escape(other))
+
+    def __mul__(self, num):
+        return Markup(str(self) * num)
+
+    def join(self, seq):
+        return Markup(str(self).join([Markup.escape(item) for item in seq]))
+
+    def striptags(self):
+        """Return a copy of the text with all XML/HTML tags removed."""
+        return Markup(re.sub(r'<[^>]*?>', '', self))
+
+    def escape(cls, text, quotes=True):
+        """Create a Markup instance from a string and escape special characters
+        it may contain (<, >, & and ").
+        
+        If the `quotes` parameter is set to `False`, the " character is left as
+        is. Escaping quotes is generally only required for strings that are to
+        be used in attribute values.
+        """
+        if isinstance(text, cls):
+            return text
+        if not text:
+            return cls()
+        text = str(text).replace('&', '&amp;') \
+                        .replace('<', '&lt;') \
+                        .replace('>', '&gt;')
+        if quotes:
+            text = text.replace('"', '&#34;')
+        return cls(text)
+    escape = classmethod(escape)
+
+    def unescape(self):
+        """Reverse-escapes &, <, > and " and returns a `str`."""
+        if not self:
+            return ''
+        return str(self).replace('&#34;', '"') \
+                        .replace('&gt;', '>') \
+                        .replace('&lt;', '<') \
+                        .replace('&amp;', '&')
+
+    def sanitize(self):
+        """Parse the text as HTML and return a cleaned up XHTML representation.
+        
+        This will remove any javascript code or other potentially dangerous
+        elements.
+        
+        If the HTML cannot be parsed, an `HTMLParseError` will be raised by the
+        underlying `HTMLParser` module, which should be handled by the caller of
+        this function.
+        """
+        import htmlentitydefs
+        from HTMLParser import HTMLParser, HTMLParseError
+        from StringIO import StringIO
+
+        buf = StringIO()
+
+        class HTMLSanitizer(HTMLParser):
+            # FIXME: move this out into a top-level class
+            safe_tags = frozenset(['a', 'abbr', 'acronym', 'address', 'area',
+                'b', 'big', 'blockquote', 'br', 'button', 'caption', 'center',
+                'cite', 'code', 'col', 'colgroup', 'dd', 'del', 'dfn', 'dir',
+                'div', 'dl', 'dt', 'em', 'fieldset', 'font', 'form', 'h1', 'h2',
+                'h3', 'h4', 'h5', 'h6', 'hr', 'i', 'img', 'input', 'ins', 'kbd',
+                'label', 'legend', 'li', 'map', 'menu', 'ol', 'optgroup',
+                'option', 'p', 'pre', 'q', 's', 'samp', 'select', 'small',
+                'span', 'strike', 'strong', 'sub', 'sup', 'table', 'tbody',
+                'td', 'textarea', 'tfoot', 'th', 'thead', 'tr', 'tt', 'u', 'ul',
+                'var'])
+            safe_attrs = frozenset(['abbr', 'accept', 'accept-charset',
+                'accesskey', 'action', 'align', 'alt', 'axis', 'border',
+                'cellpadding', 'cellspacing', 'char', 'charoff', 'charset',
+                'checked', 'cite', 'class', 'clear', 'cols', 'colspan', 'color',
+                'compact', 'coords', 'datetime', 'dir', 'disabled', 'enctype',
+                'for', 'frame', 'headers', 'height', 'href', 'hreflang',
+                'hspace', 'id', 'ismap', 'label', 'lang', 'longdesc',
+                'maxlength', 'media', 'method', 'multiple', 'name', 'nohref',
+                'noshade', 'nowrap', 'prompt', 'readonly', 'rel', 'rev', 'rows',
+                'rowspan', 'rules', 'scope', 'selected', 'shape', 'size',
+                'span', 'src', 'start', 'style', 'summary', 'tabindex',
+                'target', 'title', 'type', 'usemap', 'valign', 'value',
+                'vspace', 'width'])
+            uri_attrs = frozenset(['action', 'background', 'dynsrc', 'href',
+                                  'lowsrc', 'src'])
+            safe_schemes = frozenset(['file', 'ftp', 'http', 'https', 'mailto',
+                                      None])
+            empty_tags = frozenset(['br', 'hr', 'img', 'input'])
+            waiting_for = None
+
+            def handle_starttag(self, tag, attrs):
+                if self.waiting_for:
+                    return
+                if tag not in self.safe_tags:
+                    self.waiting_for = tag
+                    return
+                buf.write('<' + tag)
+
+                def _get_scheme(text):
+                    if ':' not in text:
+                        return None
+                    chars = [char for char in text.split(':', 1)[0]
+                             if char.isalnum()]
+                    return ''.join(chars).lower()
+
+                for attrname, attrval in attrs:
+                    if attrname not in self.safe_attrs:
+                        continue
+                    elif attrname in self.uri_attrs:
+                        # Don't allow URI schemes such as "javascript:"
+                        if _get_scheme(attrval) not in self.safe_schemes:
+                            continue
+                    elif attrname == 'style':
+                        # Remove dangerous CSS declarations from inline styles
+                        decls = []
+                        for decl in filter(None, attrval.split(';')):
+                            is_evil = False
+                            if 'expression' in decl:
+                                is_evil = True
+                            for m in re.finditer(r'url\s*\(([^)]+)', decl):
+                                if _get_scheme(m.group(1)) not in self.safe_schemes:
+                                    is_evil = True
+                                    break
+                            if not is_evil:
+                                decls.append(decl.strip())
+                        if not decls:
+                            continue
+                        attrval = '; '.join(decls)
+                    buf.write(' ' + attrname + '="' + escape(attrval) + '"')
+
+                if tag in self.empty_tags:
+                    buf.write(' />')
+                else:
+                    buf.write('>')
+
+            def handle_entityref(self, name):
+                if not self.waiting_for:
+                    if name not in ('amp', 'apos', 'lt', 'gt', 'quot'):
+                        try:
+                            codepoint = htmlentitydefs.name2codepoint[name]
+                            buf.write(unichr(codepoint).encode('utf-8'))
+                        except KeyError:
+                            buf.write('&amp;%s;' % name)
+                    else:
+                        buf.write('&%s;' % name)
+
+            def handle_data(self, data):
+                if not self.waiting_for:
+                    buf.write(escape(data, quotes=False))
+
+            def handle_endtag(self, tag):
+                if self.waiting_for:
+                    if self.waiting_for == tag:
+                        self.waiting_for = None
+                    return
+                if tag not in self.empty_tags:
+                    buf.write('</' + tag + '>')
+
+        # Translate any character or entity references to the corresponding
+        # UTF-8 characters
+        def _ref2utf8(match):
+            ref = match.group(1)
+            if ref.startswith('x'):
+                ref = int(ref[1:], 16)
+            else:
+                ref = int(ref, 10)
+            return unichr(int(ref)).encode('utf-8')
+        text = re.sub(r'&#((?:\d+)|(?:[xX][0-9a-fA-F]+));?', _ref2utf8, self)
+
+        sanitizer = HTMLSanitizer()
+        sanitizer.feed(text)
+        return Markup(buf.getvalue())
+
+
+escape = Markup.escape
+
+def unescape(text):
+    """Reverse-escapes &, <, > and \"."""
+    if not isinstance(text, Markup):
+        return text
+    return text.unescape()
+
+ENTITIES = re.compile(r"&(\w+);")
+def rss_title(text):
+    if isinstance(text, Markup):
+        def replace_entity(match):
+            return match.group(1) in ('amp', 'lt', 'gt', 'apos', 'quot') \
+                   and match.group(0) or ''
+        return Markup(re.sub(ENTITIES, replace_entity,
+                             text.striptags().replace('\n', ' ')))
+    return text
+
+
+
+def to_utf8(text, charset='iso-8859-15'):
+    """Convert a string to UTF-8, assuming the encoding is either UTF-8, ISO
+    Latin-1, or as specified by the optional `charset` parameter."""
+    try:
+        # Do nothing if it's already utf-8
+        u = unicode(text, 'utf-8')
+        return text
+    except UnicodeError:
+        try:
+            # Use the user supplied charset if possible
+            u = unicode(text, charset)
+        except UnicodeError:
+            # This should always work
+            u = unicode(text, 'iso-8859-15')
+        return u.encode('utf-8')
+
+def shorten_line(text, maxlen = 75):
+    if len(text or '') < maxlen:
+        return text
+    shortline = text[:maxlen]
+    cut = shortline.rfind(' ') + 1 or shortline.rfind('\n') + 1 or maxlen
+    shortline = text[:cut]+' ...'
+    return shortline
+
+DIGITS = re.compile(r'(\d+)')
+def embedded_numbers(s):
+    """Comparison function for natural order sorting based on
+    http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/214202."""
+    pieces = DIGITS.split(s)
+    pieces[1::2] = map(int, pieces[1::2])
+    return pieces
+
+def hex_entropy(bytes=32):
+    import md5
+    import random
+    return md5.md5(str(random.random() + time.time())).hexdigest()[:bytes]
+
+def pretty_size(size):
+    if size is None:
+        return ''
+
+    jump = 512
+    if size < jump:
+        return '%d bytes' % size
+
+    units = ['kB', 'MB', 'GB', 'TB']
+    i = 0
+    while size >= jump and i < len(units):
+        i += 1
+        size /= 1024.
+
+    return '%.1f %s' % (size, units[i - 1])
+
+def pretty_timedelta(time1, time2=None, resolution=None):
+    """Calculate time delta (inaccurately, only for decorative purposes ;-) for
+    prettyprinting. If time1 is None, the current time is used."""
+    if not time1: time1 = time.time()
+    if not time2: time2 = time.time()
+    if time1 > time2:
+        time2, time1 = time1, time2
+    units = ((3600 * 24 * 365, 'year',   'years'),
+             (3600 * 24 * 30,  'month',  'months'),
+             (3600 * 24 * 7,   'week',   'weeks'),
+             (3600 * 24,       'day',    'days'),
+             (3600,            'hour',   'hours'),
+             (60,              'minute', 'minutes'))
+    age_s = int(time2 - time1)
+    if resolution and age_s < resolution:
+        return ''
+    if age_s < 60:
+        return '%i second%s' % (age_s, age_s != 1 and 's' or '')
+    for u, unit, unit_plural in units:
+        r = float(age_s) / float(u)
+        if r >= 0.9:
+            r = int(round(r))
+            return '%d %s' % (r, r == 1 and unit or unit_plural)
+    return ''
+
+def create_unique_file(path):
+    """Create a new file. An index is added if the path exists"""
+    parts = os.path.splitext(path)
+    idx = 1
+    while 1:
+        try:
+            flags = os.O_CREAT + os.O_WRONLY + os.O_EXCL
+            if hasattr(os, 'O_BINARY'):
+                flags += os.O_BINARY
+            return path, os.fdopen(os.open(path, flags), 'w')
+        except OSError:
+            idx += 1
+            # A sanity check
+            if idx > 100:
+                raise Exception('Failed to create unique name: ' + path)
+            path = '%s.%d%s' % (parts[0], idx, parts[1])
+
+def get_reporter_id(req):
+    name = req.session.get('name', None)
+    email = req.session.get('email', None)
+    
+    if req.authname != 'anonymous':
+        return req.authname
+    elif name and email:
+        return '%s <%s>' % (name, email)
+    elif not name and email:
+        return email
+    else:
+        return req.authname
+
+# Date/time utilities
+
+def format_datetime(t=None, format='%x %X', gmt=False):
+    if t is None:
+        t = time.time()
+    if not isinstance(t, (list, tuple, time.struct_time)):
+        if gmt:
+            t = time.gmtime(int(t))
+        else:
+            t = time.localtime(int(t))
+
+    text = time.strftime(format, t)
+    return to_utf8(text)
+
+def format_date(t=None, format='%x', gmt=False):
+    return format_datetime(t, format, gmt)
+
+def format_time(t=None, format='%X', gmt=False):
+    return format_datetime(t, format, gmt)
+
+def get_date_format_hint():
+    t = time.localtime(0)
+    t = (1999, 10, 29, t[3], t[4], t[5], t[6], t[7], t[8])
+    tmpl = time.strftime('%x', t)
+    return tmpl.replace('1999', 'YYYY', 1).replace('99', 'YY', 1) \
+               .replace('10', 'MM', 1).replace('29', 'DD', 1)
+
+def get_datetime_format_hint():
+    t = time.localtime(0)
+    t = (1999, 10, 29, 23, 59, 58, t[6], t[7], t[8])
+    tmpl = time.strftime('%x %X', t)
+    return tmpl.replace('1999', 'YYYY', 1).replace('99', 'YY', 1) \
+               .replace('10', 'MM', 1).replace('29', 'DD', 1) \
+               .replace('23', 'hh', 1).replace('59', 'mm', 1) \
+               .replace('58', 'ss', 1)
+
+def http_date(t=None):
+    """Format t as a rfc822 timestamp"""
+    if t is None:
+        t = time.time()
+    if not isinstance(t, (list, tuple, time.struct_time)):
+        t = time.gmtime(int(t))
+    weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
+    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',
+              'Oct', 'Nov', 'Dec']
+    return '%s, %02d %s %04d %02d:%02d:%02d GMT' % (
+           weekdays[t.tm_wday], t.tm_mday, months[t.tm_mon - 1], t.tm_year,
+           t.tm_hour, t.tm_min, t.tm_sec)
+
+def parse_date(text):
+    seconds = None
+    text = text.strip()
+    for format in ['%x %X', '%x, %X', '%X %x', '%X, %x', '%x', '%c',
+                   '%b %d, %Y']:
+        try:
+            date = time.strptime(text, format)
+            seconds = time.mktime(date)
+            break
+        except ValueError:
+            continue
+    if seconds == None:
+        raise ValueError, '%s is not a known date format.' % text
+    return seconds
+
+
+class NaivePopen:
+    """This is a deadlock-safe version of popen that returns an object with
+    errorlevel, out (a string) and err (a string).
+    
+    (capturestderr may not work under Windows 9x.)
+
+    Example: print Popen3('grep spam','\n\nhere spam\n\n').out
+    """
+    def __init__(self, command, input=None, capturestderr=None):
+        outfile = tempfile.mktemp()
+        command = '( %s ) > %s' % (command, outfile)
+        if input:
+            infile = tempfile.mktemp()
+            tmp = open(infile, 'w')
+            tmp.write(input)
+            tmp.close()
+            command = command + ' <' + infile
+        if capturestderr:
+            errfile = tempfile.mktemp()
+            command = command + ' 2>' + errfile
+        try:
+            self.err = None
+            self.errorlevel = os.system(command) >> 8
+            outfd = file(outfile, 'r')
+            self.out = outfd.read()
+            outfd.close()
+            if capturestderr:
+                errfd = file(errfile,'r')
+                self.err = errfd.read()
+                errfd.close()
+        finally:
+            if os.path.isfile(outfile):
+                os.remove(outfile)
+            if input and os.path.isfile(infile):
+                os.remove(infile)
+            if capturestderr and os.path.isfile(errfile):
+                os.remove(errfile)
+
+
+def wrap(t, cols=75, initial_indent='', subsequent_indent='',
+         linesep=os.linesep):
+    try:
+        import textwrap
+        t = t.strip().replace('\r\n', '\n').replace('\r', '\n')
+        wrapper = textwrap.TextWrapper(cols, replace_whitespace = 0,
+                                       break_long_words = 0,
+                                       initial_indent = initial_indent,
+                                       subsequent_indent = subsequent_indent)
+        wrappedLines = []
+        for line in t.split('\n'):
+            wrappedLines += wrapper.wrap(line.rstrip()) or ['']
+        return linesep.join(wrappedLines)
+
+    except ImportError:
+        return t
+
+
+def safe__import__(module_name):
+    """
+    Safe imports: rollback after a failed import.
+    
+    Initially inspired from the RollbackImporter in PyUnit,
+    but it's now much simpler and works better for our needs.
+    
+    See http://pyunit.sourceforge.net/notes/reloading.html
+    """
+    already_imported = sys.modules.copy()
+    try:
+        return __import__(module_name, globals(), locals(), [])
+    except Exception, e:
+        for modname in sys.modules.copy():
+            if not already_imported.has_key(modname):
+                del(sys.modules[modname])
+        raise e
+
+
+class Deuglifier(object):
+    def __new__(cls):
+        self = object.__new__(cls)
+        if not hasattr(cls, '_compiled_rules'):
+            cls._compiled_rules = re.compile('(?:' + '|'.join(cls.rules()) + ')')
+        self._compiled_rules = cls._compiled_rules
+        return self
+    
+    def format(self, indata):
+        return re.sub(self._compiled_rules, self.replace, indata)
+
+    def replace(self, fullmatch):
+        for mtype, match in fullmatch.groupdict().items():
+            if match:
+                if mtype == 'font':
+                    return '<span>'
+                elif mtype == 'endfont':
+                    return '</span>'
+                return '<span class="code-%s">' % mtype
+
+# Original license for md5crypt:
+# Based on FreeBSD src/lib/libcrypt/crypt.c 1.2
+#
+# "THE BEER-WARE LICENSE" (Revision 42):
+# <phk@login.dknet.dk> wrote this file.  As long as you retain this notice you
+# can do whatever you want with this stuff. If we meet some day, and you think
+# this stuff is worth it, you can buy me a beer in return.   Poul-Henning Kamp
+
+def md5crypt(password, salt, magic='$1$'):
+    # /* The password first, since that is what is most unknown */
+    # /* Then our magic string */
+    # /* Then the raw salt */
+    m = md5.new()
+    m.update(password + magic + salt)
+
+    # /* Then just as many characters of the MD5(pw,salt,pw) */
+    mixin = md5.md5(password + salt + password).digest()
+    for i in range(0, len(password)):
+        m.update(mixin[i % 16])
+
+    # /* Then something really weird... */
+    # Also really broken, as far as I can tell.  -m
+    i = len(password)
+    while i:
+        if i & 1:
+            m.update('\x00')
+        else:
+            m.update(password[0])
+        i >>= 1
+
+    final = m.digest()
+
+    # /* and now, just to make sure things don't run too fast */
+    for i in range(1000):
+        m2 = md5.md5()
+        if i & 1:
+            m2.update(password)
+        else:
+            m2.update(final)
+
+        if i % 3:
+            m2.update(salt)
+
+        if i % 7:
+            m2.update(password)
+
+        if i & 1:
+            m2.update(final)
+        else:
+            m2.update(password)
+
+        final = m2.digest()
+
+    # This is the bit that uses to64() in the original code.
+
+    itoa64 = './0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
+
+    rearranged = ''
+    for a, b, c in ((0, 6, 12), (1, 7, 13), (2, 8, 14), (3, 9, 15), (4, 10, 5)):
+        v = ord(final[a]) << 16 | ord(final[b]) << 8 | ord(final[c])
+        for i in range(4):
+            rearranged += itoa64[v & 0x3f]; v >>= 6
+
+    v = ord(final[11])
+    for i in range(2):
+        rearranged += itoa64[v & 0x3f]; v >>= 6
+
+    return magic + salt + '$' + rearranged
diff -urN trac-trunk/build/lib/trac/versioncontrol/__init__.py aw-trac/build/lib/trac/versioncontrol/__init__.py
--- trac-trunk/build/lib/trac/versioncontrol/__init__.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/__init__.py	2005-08-22 15:00:25.000000000 -0700
@@ -0,0 +1 @@
+from trac.versioncontrol.api import *
diff -urN trac-trunk/build/lib/trac/versioncontrol/api.py aw-trac/build/lib/trac/versioncontrol/api.py
--- trac-trunk/build/lib/trac/versioncontrol/api.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/api.py	2006-02-09 00:46:19.000000000 -0800
@@ -0,0 +1,339 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+from heapq import heappop, heappush
+
+from trac.core import *
+from trac.perm import PermissionError
+
+
+class IRepositoryConnector(Interface):
+    """Extension point interface for components that provide support for a
+    specific version control system."""
+
+    def get_supported_types():
+        """Return the types of version control systems that are supported by
+        this connector, and their relative priorities.
+        
+        Highest number is highest priority.
+        """
+
+    def get_repository(repos_type, repos_dir, authname):
+        """Return the Repository object for the given repository type and
+        directory.
+        """
+
+
+class RepositoryManager(Component):
+    """Component that keeps track of the supported version control systems, and
+    provides easy access to the configured implementation."""
+
+    connectors = ExtensionPoint(IRepositoryConnector)
+
+    def __init__(self):
+        self._connector = None
+
+    def get_repository(self, repos_type, repos_dir, authname):
+        if not self._connector:
+            candidates = []
+            for connector in self.connectors:
+                for repos_type_, prio in connector.get_supported_types():
+                    if repos_type_ != repos_type:
+                        continue
+                    heappush(candidates, (-prio, connector))
+            if not candidates:
+                raise TracError, 'Unsupported version control system "%s"' \
+                                 % repos_type
+            self._connector = heappop(candidates)[1]
+        return self._connector.get_repository(repos_type, repos_dir, authname)
+
+
+class Repository(object):
+    """
+    Base class for a repository provided by a version control system.
+    """
+
+    def __init__(self, name, authz, log):
+        self.name = name
+        self.authz = authz or Authorizer()
+        self.log = log
+
+    def close(self):
+        """
+        Close the connection to the repository.
+        """
+        raise NotImplementedError
+
+    def get_changeset(self, rev):
+        """
+        Retrieve a Changeset object that describes the changes made in
+        revision 'rev'.
+        """
+        raise NotImplementedError
+
+    def get_changesets(self, start, stop):
+        """
+        Generate Changeset belonging to the given time period (start, stop).
+        """
+        rev = self.youngest_rev
+        while rev:
+            if self.authz.has_permission_for_changeset(rev):
+                chgset = self.get_changeset(rev)
+                if chgset.date < start:
+                    return
+                if chgset.date < stop:
+                    yield chgset
+            rev = self.previous_rev(rev)
+
+    def has_node(self, path, rev=None):
+        """
+        Tell if there's a node at the specified (path,rev) combination.
+
+        When `rev` is `None`, the latest revision is implied.
+        """
+        try:
+            self.get_node(path, rev)
+            return True
+        except TracError:
+            return False        
+    
+    def get_node(self, path, rev=None):
+        """
+        Retrieve a Node (directory or file) from the repository at the
+        given path. If the rev parameter is specified, the version of the
+        node at that revision is returned, otherwise the latest version
+        of the node is returned.
+        """
+        raise NotImplementedError
+
+    def get_oldest_rev(self):
+        """
+        Return the oldest revision stored in the repository.
+        """
+        raise NotImplementedError
+    oldest_rev = property(lambda x: x.get_oldest_rev())
+
+    def get_youngest_rev(self):
+        """
+        Return the youngest revision in the repository.
+        """
+        raise NotImplementedError
+    youngest_rev = property(lambda x: x.get_youngest_rev())
+
+    def previous_rev(self, rev):
+        """
+        Return the revision immediately preceding the specified revision.
+        """
+        raise NotImplementedError
+
+    def next_rev(self, rev, path=''):
+        """
+        Return the revision immediately following the specified revision.
+        """
+        raise NotImplementedError
+
+    def rev_older_than(self, rev1, rev2):
+        """
+        Return True if rev1 is older than rev2, i.e. if rev1 comes before rev2
+        in the revision sequence.
+        """
+        raise NotImplementedError
+
+    def get_youngest_rev_in_cache(self, db):
+        """
+        Return the youngest revision currently cached.
+        The way revisions are sequenced is version control specific.
+        By default, one assumes that the revisions are sequenced in time.
+        """
+        cursor = db.cursor()
+        cursor.execute("SELECT rev FROM revision ORDER BY time DESC LIMIT 1")
+        row = cursor.fetchone()
+        return row and row[0] or None
+
+    def get_path_history(self, path, rev=None, limit=None):
+        """
+        Retrieve all the revisions containing this path (no newer than 'rev').
+        The result format should be the same as the one of Node.get_history()
+        """
+        raise NotImplementedError
+
+    def normalize_path(self, path):
+        """
+        Return a canonical representation of path in the repos.
+        """
+        return NotImplementedError
+
+    def normalize_rev(self, rev):
+        """
+        Return a canonical representation of a revision in the repos.
+        'None' is a valid revision value and represents the youngest revision.
+        """
+        return NotImplementedError
+
+    def short_rev(self, rev):
+        """
+        Return a compact representation of a revision in the repos.
+        """
+        return self.normalize_rev(rev)
+        
+    def get_changes(self, old_path, old_rev, new_path, new_rev,
+                    ignore_ancestry=1):
+        """
+        Generator that yields change tuples (old_node, new_node, kind, change)
+        for each node change between the two arbitrary (path,rev) pairs.
+
+        The old_node is assumed to be None when the change is an ADD,
+        the new_node is assumed to be None when the change is a DELETE.
+        """
+        raise NotImplementedError
+
+
+class Node(object):
+    """
+    Represents a directory or file in the repository.
+    """
+
+    DIRECTORY = "dir"
+    FILE = "file"
+
+    def __init__(self, path, rev, kind):
+        assert kind in (Node.DIRECTORY, Node.FILE), "Unknown node kind %s" % kind
+        self.path = str(path)
+        self.rev = rev
+        self.kind = kind
+
+    def get_content(self):
+        """
+        Return a stream for reading the content of the node. This method
+        will return None for directories. The returned object should provide
+        a read([len]) function.
+        """
+        raise NotImplementedError
+
+    def get_entries(self):
+        """
+        Generator that yields the immediate child entries of a directory, in no
+        particular order. If the node is a file, this method returns None.
+        """
+        raise NotImplementedError
+
+    def get_history(self, limit=None):
+        """
+        Generator that yields (path, rev, chg) tuples, one for each revision in which
+        the node was changed. This generator will follow copies and moves of a
+        node (if the underlying version control system supports that), which
+        will be indicated by the first element of the tuple (i.e. the path)
+        changing.
+        Starts with an entry for the current revision.
+        """
+        raise NotImplementedError
+
+    def get_previous(self):
+        """
+        Return the (path, rev, chg) tuple corresponding to the previous
+        revision for that node.
+        """
+        skip = True
+        for p in self.get_history(2):
+            if skip:
+                skip = False
+            else:
+                return p
+
+    def get_properties(self):
+        """
+        Returns a dictionary containing the properties (meta-data) of the node.
+        The set of properties depends on the version control system.
+        """
+        raise NotImplementedError
+
+    def get_content_length(self):
+        raise NotImplementedError
+    content_length = property(lambda x: x.get_content_length())
+
+    def get_content_type(self):
+        raise NotImplementedError
+    content_type = property(lambda x: x.get_content_type())
+
+    def get_name(self):
+        return self.path.split('/')[-1]
+    name = property(lambda x: x.get_name())
+
+    def get_last_modified(self):
+        raise NotImplementedError
+    last_modified = property(lambda x: x.get_last_modified())
+
+    isdir = property(lambda x: x.kind == Node.DIRECTORY)
+    isfile = property(lambda x: x.kind == Node.FILE)
+
+
+class Changeset(object):
+    """
+    Represents a set of changes of a repository.
+    """
+
+    ADD = 'add'
+    COPY = 'copy'
+    DELETE = 'delete'
+    EDIT = 'edit'
+    MOVE = 'move'
+
+    def __init__(self, rev, message, author, date):
+        self.rev = rev
+        self.message = message
+        self.author = author
+        self.date = date
+
+    def get_changes(self):
+        """
+        Generator that produces a (path, kind, change, base_rev, base_path)
+        tuple for every change in the changeset, where change can be one of
+        Changeset.ADD, Changeset.COPY, Changeset.DELETE, Changeset.EDIT or
+        Changeset.MOVE, and kind is one of Node.FILE or Node.DIRECTORY.
+        """
+        raise NotImplementedError
+
+
+class PermissionDenied(PermissionError):
+    """
+    Exception raised by an authorizer if the user has insufficient permissions
+    to view a specific part of the repository.
+    """
+    def __str__(self):
+        return self.action
+
+
+class Authorizer(object):
+    """
+    Base class for authorizers that are responsible to granting or denying
+    access to view certain parts of a repository.
+    """
+
+    def assert_permission(self, path):
+        if not self.has_permission(path):
+            raise PermissionDenied, \
+                  'Insufficient permissions to access %s' % path
+
+    def assert_permission_for_changeset(self, rev):
+        if not self.has_permission_for_changeset(rev):
+            raise PermissionDenied, \
+                  'Insufficient permissions to access changeset %s' % rev
+
+    def has_permission(self, path):
+        return True
+
+    def has_permission_for_changeset(self, rev):
+        return True
diff -urN trac-trunk/build/lib/trac/versioncontrol/cache.py aw-trac/build/lib/trac/versioncontrol/cache.py
--- trac-trunk/build/lib/trac/versioncontrol/cache.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/cache.py	2006-02-10 01:37:26.000000000 -0800
@@ -0,0 +1,160 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+from trac.util import TracError
+from trac.versioncontrol import Changeset, Node, Repository, Authorizer
+
+
+_kindmap = {'D': Node.DIRECTORY, 'F': Node.FILE}
+_actionmap = {'A': Changeset.ADD, 'C': Changeset.COPY,
+              'D': Changeset.DELETE, 'E': Changeset.EDIT,
+              'M': Changeset.MOVE}
+
+
+class CachedRepository(Repository):
+
+    def __init__(self, db, repos, authz, log):
+        Repository.__init__(self, repos.name, authz, log)
+        self.db = db
+        self.repos = repos
+        self.synced = 0
+
+    def close(self):
+        self.repos.close()
+
+    def get_changeset(self, rev):
+        if not self.synced:
+            self.sync()
+            self.synced = 1
+        return CachedChangeset(self.repos.normalize_rev(rev), self.db,
+                               self.authz)
+
+    def sync(self):
+        self.log.debug("Checking whether sync with repository is needed")
+        cursor = self.db.cursor()
+
+        # -- repository used for populating the cache
+        cursor.execute("SELECT value FROM system WHERE name='repository_dir'")
+        row = cursor.fetchone()
+        if row:
+            previous_repository_dir = row[0]
+        else: # no 'repository_dir' stored yet, assume everything's OK
+            previous_repository_dir = self.name
+
+        if self.name != previous_repository_dir:
+            raise TracError, ("The 'repository_dir' has changed, "
+                              "a 'trac-admin resync' operation is needed.")
+
+        youngest_stored = self.repos.get_youngest_rev_in_cache(self.db)
+
+        if youngest_stored != str(self.repos.youngest_rev):
+            authz = self.repos.authz
+            self.repos.authz = Authorizer() # remove permission checking
+
+            kindmap = dict(zip(_kindmap.values(), _kindmap.keys()))
+            actionmap = dict(zip(_actionmap.values(), _actionmap.keys()))
+            self.log.info("Syncing with repository (%s to %s)"
+                          % (youngest_stored, self.repos.youngest_rev))
+            if youngest_stored:
+                current_rev = self.repos.next_rev(youngest_stored)
+            else:
+                try:
+                    current_rev = self.repos.oldest_rev
+                    current_rev = self.repos.normalize_rev(current_rev)
+                except TracError:
+                    current_rev = None
+            while current_rev is not None:
+                changeset = self.repos.get_changeset(current_rev)
+                cursor.execute("INSERT INTO revision (rev,time,author,message) "
+                               "VALUES (%s,%s,%s,%s)", (str(current_rev),
+                               changeset.date, changeset.author,
+                               changeset.message))
+                for path,kind,action,base_path,base_rev in changeset.get_changes():
+                    self.log.debug("Caching node change in [%s]: %s"
+                                   % (current_rev, (path, kind, action,
+                                      base_path, base_rev)))
+                    kind = kindmap[kind]
+                    action = actionmap[action]
+                    cursor.execute("INSERT INTO node_change (rev,path,"
+                                   "node_type,change_type,base_path,base_rev) "
+                                   "VALUES (%s,%s,%s,%s,%s,%s)",
+                                   (str(current_rev), path, kind, action,
+                                   base_path, base_rev))
+                current_rev = self.repos.next_rev(current_rev)
+            self.db.commit()
+            self.repos.authz = authz # restore permission checking
+
+    def get_node(self, path, rev=None):
+        return self.repos.get_node(path, rev)
+
+    def has_node(self, path, rev):
+        return self.repos.has_node(path, rev)
+
+    def get_oldest_rev(self):
+        return self.repos.oldest_rev
+
+    def get_youngest_rev(self):
+        return self.repos.youngest_rev
+
+    def previous_rev(self, rev):
+        return self.repos.previous_rev(rev)
+
+    def next_rev(self, rev, path=''):
+        return self.repos.next_rev(rev, path)
+
+    def rev_older_than(self, rev1, rev2):
+        return self.repos.rev_older_than(rev1, rev2)
+
+    def get_path_history(self, path, rev=None, limit=None):
+        return self.repos.get_path_history(path, rev, limit)
+
+    def normalize_path(self, path):
+        return self.repos.normalize_path(path)
+
+    def normalize_rev(self, rev):
+        return self.repos.normalize_rev(rev)
+
+    def get_changes(self, old_path, old_rev, new_path, new_rev, ignore_ancestry=1):
+        return self.repos.get_changes(old_path, old_rev, new_path, new_rev, ignore_ancestry)
+
+
+class CachedChangeset(Changeset):
+
+    def __init__(self, rev, db, authz):
+        self.db = db
+        self.authz = authz
+        cursor = self.db.cursor()
+        cursor.execute("SELECT time,author,message FROM revision "
+                       "WHERE rev=%s", (rev,))
+        row = cursor.fetchone()
+        if row:
+            date, author, message = row
+            Changeset.__init__(self, rev, message, author, int(date))
+        else:
+            raise TracError, "No changeset %s in the repository" % rev
+
+    def get_changes(self):
+        cursor = self.db.cursor()
+        cursor.execute("SELECT path,node_type,change_type,base_path,base_rev "
+                       "FROM node_change WHERE rev=%s "
+                       "ORDER BY path", (self.rev,))
+        for path, kind, change, base_path, base_rev in cursor:
+            if not self.authz.has_permission(path):
+                # FIXME: what about the base_path?
+                continue
+            kind = _kindmap[kind]
+            change = _actionmap[change]
+            yield path, kind, change, base_path, base_rev
diff -urN trac-trunk/build/lib/trac/versioncontrol/diff.py aw-trac/build/lib/trac/versioncontrol/diff.py
--- trac-trunk/build/lib/trac/versioncontrol/diff.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/diff.py	2006-01-19 05:39:35.000000000 -0800
@@ -0,0 +1,278 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2006 Edgewall Software
+# Copyright (C) 2004-2006 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+from trac.util import escape, Markup
+
+from difflib import SequenceMatcher
+import re
+
+__all__ = ['get_diff_options', 'hdf_diff', 'unified_diff']
+
+
+def _get_change_extent(str1, str2):
+    """
+    Determines the extent of differences between two strings. Returns a tuple
+    containing the offset at which the changes start, and the negative offset
+    at which the changes end. If the two strings have neither a common prefix
+    nor a common suffix, (0, 0) is returned.
+    """
+    start = 0
+    limit = min(len(str1), len(str2))
+    while start < limit and str1[start] == str2[start]:
+        start += 1
+    end = -1
+    limit = limit - start
+    while -end <= limit and str1[end] == str2[end]:
+        end -= 1
+    return (start, end + 1)
+
+def _get_opcodes(fromlines, tolines, ignore_blank_lines=False,
+                 ignore_case=False, ignore_space_changes=False):
+    """
+    Generator built on top of SequenceMatcher.get_opcodes().
+    
+    This function detects line changes that should be ignored and emits them
+    as tagged as 'equal', possibly joined with the preceding and/or following
+    'equal' block.
+    """
+
+    def is_ignorable(tag, fromlines, tolines):
+        if tag == 'delete' and ignore_blank_lines:
+            if ''.join(fromlines) == '':
+                return True
+        elif tag == 'insert' and ignore_blank_lines:
+            if ''.join(tolines) == '':
+                return True
+        elif tag == 'replace' and (ignore_case or ignore_space_changes):
+            if len(fromlines) != len(tolines):
+                return False
+            def f(str):
+                if ignore_case:
+                    str = str.lower()
+                if ignore_space_changes:
+                    str = ' '.join(str.split())
+                return str
+            for i in range(len(fromlines)):
+                if f(fromlines[i]) != f(tolines[i]):
+                    return False
+            return True
+
+    matcher = SequenceMatcher(None, fromlines, tolines)
+    previous = None
+    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
+        if tag == 'equal':
+            if previous:
+                previous = (tag, previous[1], i2, previous[3], j2)
+            else:
+                previous = (tag, i1, i2, j1, j2)
+        else:
+            if is_ignorable(tag, fromlines[i1:i2], tolines[j1:j2]):
+                if previous:
+                    previous = 'equal', previous[1], i2, previous[3], j2
+                else:
+                    previous = 'equal', i1, i2, j1, j2
+                continue
+            if previous:
+                yield previous
+            yield tag, i1, i2, j1, j2
+            previous = None
+
+    if previous:
+        yield previous
+
+def _group_opcodes(opcodes, n=3):
+    """
+    Python 2.2 doesn't have SequenceMatcher.get_grouped_opcodes(), so let's
+    provide equivalent here. The opcodes parameter can be any iterable or
+    sequence.
+
+    This function can also be used to generate full-context diffs by passing 
+    None for the parameter n.
+    """
+    # Full context produces all the opcodes
+    if n is None:
+        yield opcodes
+        return
+
+    # Otherwise we leave at most n lines with the tag 'equal' before and after
+    # every change
+    nn = n + n
+    group = []
+    for idx, (tag, i1, i2, j1, j2) in enumerate(opcodes):
+        if idx == 0 and tag == 'equal': # Fixup leading unchanged block
+            i1, j1 = max(i1, i2 - n), max(j1, j2 - n)
+        elif tag == 'equal' and i2 - i1 > nn:
+            group.append((tag, i1, min(i2, i1 + n), j1, min(j2, j1 + n)))
+            yield group
+            group = []
+            i1, j1 = max(i1, i2 - n), max(j1, j2 - n)
+        group.append((tag, i1, i2, j1 ,j2))
+
+    if group and not (len(group) == 1 and group[0][0] == 'equal'):
+        if group[-1][0] == 'equal': # Fixup trailing unchanged block
+            tag, i1, i2, j1, j2 = group[-1]
+            group[-1] = tag, i1, min(i2, i1 + n), j1, min(j2, j1 + n)
+        yield group
+
+def hdf_diff(fromlines, tolines, context=None, tabwidth=8,
+             ignore_blank_lines=0, ignore_case=0, ignore_space_changes=0):
+    """
+    Return an array that is adequate for adding the the HDF data set for HTML
+    rendering of the differences.
+    """
+
+    type_map = {'replace': 'mod', 'delete': 'rem', 'insert': 'add',
+                'equal': 'unmod'}
+
+    space_re = re.compile(' ( +)|^ ')
+    def htmlify(match):
+        div, mod = divmod(len(match.group(0)), 2)
+        return div * '&nbsp; ' + mod * '&nbsp;'
+
+    def markup_intraline_changes(opcodes):
+        for tag, i1, i2, j1, j2 in opcodes:
+            if tag == 'replace' and i2 - i1 == j2 - j1:
+                for i in range(i2 - i1):
+                    fromline, toline = fromlines[i1 + i], tolines[j1 + i]
+                    (start, end) = _get_change_extent(fromline, toline)
+
+                    if start == 0 and end < 0:
+                        # Change at start of line
+                        fromlines[i1 + i] = '\0' + fromline[:end] + '\1' + \
+                                            fromline[end:]
+                        tolines[j1 + i] = '\0' + toline[:end] + '\1' + \
+                                          toline[end:]
+                    elif start > 0 and end == 0:
+                        # Change at end of line
+                        fromlines[i1 + i] = fromline[:start] + '\0' + \
+                                            fromline[start:] + '\1'
+                        tolines[j1 + i] = toline[:start] + '\0' + \
+                                          toline[start:] + '\1'
+                    elif start > 0 and end < 0:
+                        # Change somewhere in the middle
+                        fromlines[i1 + i] = fromline[:start] + '\0' + \
+                                            fromline[start:end] + '\1' + \
+                                            fromline[end:]
+                        tolines[j1 + i] = toline[:start] + '\0' + \
+                                          toline[start:end] + '\1' + \
+                                          toline[end:]
+            yield tag, i1, i2, j1, j2
+
+    changes = []
+    opcodes = _get_opcodes(fromlines, tolines, ignore_blank_lines, ignore_case,
+                           ignore_space_changes)
+    for group in _group_opcodes(opcodes, context):
+        blocks = []
+        last_tag = None
+        for tag, i1, i2, j1, j2 in markup_intraline_changes(group):
+            if tag != last_tag:
+                blocks.append({'type': type_map[tag], 'base.offset': i1,
+                               'base.lines': [], 'changed.offset': j1,
+                               'changed.lines': []})
+            if tag == 'equal':
+                for line in fromlines[i1:i2]:
+                    line = line.expandtabs(tabwidth)
+                    line = space_re.sub(htmlify, escape(line, quotes=False))
+                    blocks[-1]['base.lines'].append(Markup(line))
+                for line in tolines[j1:j2]:
+                    line = line.expandtabs(tabwidth)
+                    line = space_re.sub(htmlify, escape(line, quotes=False))
+                    blocks[-1]['changed.lines'].append(Markup(line))
+            else:
+                if tag in ('replace', 'delete'):
+                    for line in fromlines[i1:i2]:
+                        line = line.expandtabs(tabwidth)
+                        line = escape(line, quotes=False).replace('\0', '<del>') \
+                                                         .replace('\1', '</del>')
+                        blocks[-1]['base.lines'].append(Markup(space_re.sub(htmlify,
+                                                                            line)))
+                if tag in ('replace', 'insert'):
+                    for line in tolines[j1:j2]:
+                        line = line.expandtabs(tabwidth)
+                        line = escape(line, quotes=False).replace('\0', '<ins>') \
+                                                         .replace('\1', '</ins>')
+                        blocks[-1]['changed.lines'].append(Markup(space_re.sub(htmlify,
+                                                                               line)))
+        changes.append(blocks)
+    return changes
+
+def unified_diff(fromlines, tolines, context=None, ignore_blank_lines=0,
+                 ignore_case=0, ignore_space_changes=0):
+    opcodes = _get_opcodes(fromlines, tolines, ignore_blank_lines, ignore_case,
+                           ignore_space_changes)
+    for group in _group_opcodes(opcodes, context):
+        i1, i2, j1, j2 = group[0][1], group[-1][2], group[0][3], group[-1][4]
+        if i1 == 0 and i2 == 0:
+            i1, i2 = -1, -1 # support for 'A'dd changes
+        yield '@@ -%d,%d +%d,%d @@' % (i1 + 1, i2 - i1, j1 + 1, j2 - j1)
+        for tag, i1, i2, j1, j2 in group:
+            if tag == 'equal':
+                for line in fromlines[i1:i2]:
+                    yield ' ' + line
+            else:
+                if tag in ('replace', 'delete'):
+                    for line in fromlines[i1:i2]:
+                        yield '-' + line
+                if tag in ('replace', 'insert'):
+                    for line in tolines[j1:j2]:
+                        yield '+' + line
+
+def get_diff_options(req):
+
+    def get_bool_option(name, default=0):
+        pref = int(req.session.get('diff_' + name, default))
+        arg = int(req.args.has_key(name))
+        if req.args.has_key('update') and arg != pref:
+            req.session['diff_' + name] = arg
+        else:
+            arg = pref
+        return arg
+
+    pref = req.session.get('diff_style', 'inline')
+    style = req.args.get('style', pref)
+    if req.args.has_key('update') and style != pref:
+        req.session['diff_style'] = style
+    req.hdf['diff.style'] = style
+
+    pref = int(req.session.get('diff_contextlines', 2))
+    try:
+        arg = int(req.args.get('contextlines', pref))
+    except ValueError:
+        arg = -1
+    if req.args.has_key('update') and arg != pref:
+        req.session['diff_contextlines'] = arg
+    options = ['-U%d' % arg]
+    if arg >= 0:
+        req.hdf['diff.options.contextlines'] = arg
+    else:
+        req.hdf['diff.options.contextlines'] = 'all'
+
+    arg = get_bool_option('ignoreblanklines')
+    if arg:
+        options.append('-B')
+    req.hdf['diff.options.ignoreblanklines'] = arg
+
+    arg = get_bool_option('ignorecase')
+    if arg:
+        options.append('-i')
+    req.hdf['diff.options.ignorecase'] = arg
+
+    arg = get_bool_option('ignorewhitespace')
+    if arg:
+        options.append('-b')
+    req.hdf['diff.options.ignorewhitespace'] = arg
+
+    return (style, options)
diff -urN trac-trunk/build/lib/trac/versioncontrol/svn_authz.py aw-trac/build/lib/trac/versioncontrol/svn_authz.py
--- trac-trunk/build/lib/trac/versioncontrol/svn_authz.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/svn_authz.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,145 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2005 Edgewall Software
+# Copyright (C) 2004 Francois Harvey <fharvey@securiweb.net>
+# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Francois Harvey <fharvey@securiweb.net>
+#         Matthew Good <trac@matt-good.net>
+
+from trac.versioncontrol import Authorizer
+
+def SubversionAuthorizer(env, authname):
+    authz_file = env.config.get('trac','authz_file')    
+    if not authz_file:
+        return Authorizer()
+
+    module_name = env.config.get('trac','authz_module_name','')
+    db = env.get_db_cnx()
+    return RealSubversionAuthorizer(db, authname, module_name, authz_file)
+
+def parent_iter(path):
+    path = path.strip('/')
+    if path:
+        path = '/' + path + '/'
+    else:
+        path = '/'
+
+    while 1:
+        yield path
+        if path == '/':
+            raise StopIteration()
+        path = path[:-1]
+        yield path
+        idx = path.rfind('/')
+        path = path[:idx + 1]
+
+
+class RealSubversionAuthorizer(Authorizer):
+
+    auth_name = ''
+    module_name = ''
+    conf_authz = None
+
+    def __init__(self, db, auth_name, module_name, cfg_file, cfg_fp=None):
+        self.db = db
+        self.auth_name = auth_name
+        self.module_name = module_name
+                                
+        from ConfigParser import ConfigParser
+        self.conf_authz = ConfigParser()
+        if cfg_fp:
+            self.conf_authz.readfp(cfg_fp, cfg_file)
+        elif cfg_file:
+            self.conf_authz.read(cfg_file)
+
+        self.groups = self._groups()
+
+    def has_permission(self, path):
+        if path is None:
+            return 1
+
+        for p in parent_iter(path):
+            if self.module_name:
+                for perm in self._get_section(self.module_name + ':' + p):
+                    if perm is not None:
+                        return perm
+            for perm in self._get_section(p):
+                if perm is not None:
+                    return perm
+
+        return 0
+
+    def has_permission_for_changeset(self, rev):
+        cursor = self.db.cursor()
+        cursor.execute("SELECT path FROM node_change WHERE rev=%s", (rev,))
+        for row in cursor:
+            if self.has_permission(row[0]):
+                return 1
+        return 0
+
+    # Internal API
+
+    def _groups(self):
+        if not self.conf_authz.has_section('groups'):
+            return []
+
+        grp_parents = {}
+        usr_grps = []
+
+        for group in self.conf_authz.options('groups'):
+            for member in self.conf_authz.get('groups', group).split(','):
+                member = member.strip()
+                if member == self.auth_name:
+                    usr_grps.append(group)
+                elif member.startswith('@'):
+                    grp_parents.setdefault(member[1:], []).append(group)
+
+        expanded = {}
+
+        def expand_group(group):
+            if group in expanded:
+                return
+            expanded[group] = True
+            for parent in grp_parents.get(group, []):
+                expand_group(parent)
+
+        for g in usr_grps:
+            expand_group(g)
+
+        # expand groups
+        return expanded.keys()
+
+    def _get_section(self, section):
+        if not self.conf_authz.has_section(section):
+            return
+
+        yield self._get_permission(section, self.auth_name)
+
+        group_perm = None
+        for g in self.groups:
+            p = self._get_permission(section, '@' + g)
+            if p is not None:
+                group_perm = p
+
+            if group_perm:
+                yield 1
+
+        yield group_perm
+
+        yield self._get_permission(section, '*')
+
+    def _get_permission(self, section, subject):
+        if self.conf_authz.has_option(section, subject):
+            return 'r' in self.conf_authz.get(section, subject)
+        return None
+
diff -urN trac-trunk/build/lib/trac/versioncontrol/svn_fs.py aw-trac/build/lib/trac/versioncontrol/svn_fs.py
--- trac-trunk/build/lib/trac/versioncontrol/svn_fs.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/svn_fs.py	2006-02-02 02:54:22.000000000 -0800
@@ -0,0 +1,677 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005-2006 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+#         Christian Boos <cboos@neuf.fr>
+
+import os.path
+import time
+import weakref
+import posixpath
+
+from trac.core import *
+from trac.versioncontrol import Changeset, Node, Repository, \
+                                IRepositoryConnector
+from trac.versioncontrol.cache import CachedRepository
+from trac.versioncontrol.svn_authz import SubversionAuthorizer
+
+try:
+    from svn import fs, repos, core, delta
+    has_subversion = True
+except ImportError:
+    has_subversion = False
+    class dummy_svn(object):
+        svn_node_dir = 1
+        svn_node_file = 2
+        def apr_pool_destroy(): pass
+        def apr_terminate(): pass
+        def apr_pool_clear(): pass
+        Editor = object
+    delta = core = dummy_svn()
+    
+
+_kindmap = {core.svn_node_dir: Node.DIRECTORY,
+            core.svn_node_file: Node.FILE}
+
+
+application_pool = None
+    
+def _get_history(path, authz, fs_ptr, pool, start, end, limit=None):
+    history = []
+    if hasattr(repos, 'svn_repos_history2'):
+        # For Subversion >= 1.1
+        def authz_cb(root, path, pool):
+            if limit and len(history) >= limit:
+                return 0
+            return authz.has_permission(path) and 1 or 0
+        def history2_cb(path, rev, pool):
+            history.append((path, rev))
+        repos.svn_repos_history2(fs_ptr, path, history2_cb, authz_cb,
+                                 start, end, 1, pool())
+    else:
+        # For Subversion 1.0.x
+        def history_cb(path, rev, pool):
+            if authz.has_permission(path):
+                history.append((path, rev))
+        repos.svn_repos_history(fs_ptr, path, history_cb, start, end, 1, pool())
+    for item in history:
+        yield item
+
+def _normalize_path(path):
+    """Remove leading "/", except for the root"""
+    return path and path.strip('/') or '/'
+
+def _path_within_scope(scope, fullpath):
+    """Remove the leading scope from repository paths"""
+    if fullpath:
+        if scope == '/':
+            return _normalize_path(fullpath)
+        elif fullpath.startswith(scope.rstrip('/')):
+            return fullpath[len(scope):] or '/'
+
+def _mark_weakpool_invalid(weakpool):
+    if weakpool():
+        weakpool()._mark_invalid()
+
+
+class Pool(object):
+    """A Pythonic memory pool object"""
+
+    # Protect svn.core methods from GC
+    apr_pool_destroy = staticmethod(core.apr_pool_destroy)
+    apr_terminate = staticmethod(core.apr_terminate)
+    apr_pool_clear = staticmethod(core.apr_pool_clear)
+    
+    def __init__(self, parent_pool=None):
+        """Create a new memory pool"""
+
+        global application_pool
+        self._parent_pool = parent_pool or application_pool
+
+        # Create pool
+        if self._parent_pool:
+            self._pool = core.svn_pool_create(self._parent_pool())
+        else:
+            # If we are an application-level pool,
+            # then initialize APR and set this pool
+            # to be the application-level pool
+            core.apr_initialize()
+            application_pool = self
+
+            self._pool = core.svn_pool_create(None)
+        self._mark_valid()
+
+    def __call__(self):
+        return self._pool
+
+    def valid(self):
+        """Check whether this memory pool and its parents
+        are still valid"""
+        return hasattr(self,"_is_valid")
+
+    def assert_valid(self):
+        """Assert that this memory_pool is still valid."""
+        assert self.valid();
+
+    def clear(self):
+        """Clear embedded memory pool. Invalidate all subpools."""
+        self.apr_pool_clear(self._pool)
+        self._mark_valid()
+
+    def destroy(self):
+        """Destroy embedded memory pool. If you do not destroy
+        the memory pool manually, Python will destroy it
+        automatically."""
+
+        global application_pool
+
+        self.assert_valid()
+
+        # Destroy pool
+        self.apr_pool_destroy(self._pool)
+
+        # Clear application pool and terminate APR if necessary
+        if not self._parent_pool:
+            application_pool = None
+            self.apr_terminate()
+
+        self._mark_invalid()
+
+    def __del__(self):
+        """Automatically destroy memory pools, if necessary"""
+        if self.valid():
+            self.destroy()
+
+    def _mark_valid(self):
+        """Mark pool as valid"""
+        if self._parent_pool:
+            # Refer to self using a weakreference so that we don't
+            # create a reference cycle
+            weakself = weakref.ref(self)
+
+            # Set up callbacks to mark pool as invalid when parents
+            # are destroyed
+            self._weakref = weakref.ref(self._parent_pool._is_valid,
+                                        lambda x: \
+                                        _mark_weakpool_invalid(weakself));
+
+        # mark pool as valid
+        self._is_valid = lambda: 1
+
+    def _mark_invalid(self):
+        """Mark pool as invalid"""
+        if self.valid():
+            # Mark invalid
+            del self._is_valid
+
+            # Free up memory
+            del self._parent_pool
+            if hasattr(self, "_weakref"):
+                del self._weakref
+
+
+# Initialize application-level pool
+if has_subversion:
+    Pool()
+
+
+class SubversionConnector(Component):
+
+    implements(IRepositoryConnector)
+
+    def get_supported_types(self):
+        global has_subversion
+        if has_subversion:
+            yield ("svnfs", 4)
+            yield ("svn", 2)
+
+    def get_repository(self, type, dir, authname):
+        """Return a `SubversionRepository`.
+
+        The repository is generally wrapped in a `CachedRepository`,
+        unless `direct-svn-fs` is the specified type.
+        """
+        authz = None
+        if authname:
+            authz = SubversionAuthorizer(self.env, authname)
+        repos = SubversionRepository(dir, authz, self.log)
+        return CachedRepository(self.env.get_db_cnx(), repos, authz, self.log)
+
+
+class SubversionRepository(Repository):
+    """
+    Repository implementation based on the svn.fs API.
+    """
+
+    def __init__(self, path, authz, log):
+        self.path = path
+        self.log = log
+        if core.SVN_VER_MAJOR < 1:
+            raise TracError, \
+                  "Subversion >= 1.0 required: Found %d.%d.%d" % \
+                  (core.SVN_VER_MAJOR, core.SVN_VER_MINOR, core.SVN_VER_MICRO)
+
+        self.pool = Pool()
+        
+        # Remove any trailing slash or else subversion might abort
+        path = os.path.normpath(path).replace('\\', '/')
+        self.path = repos.svn_repos_find_root_path(path, self.pool())
+        if self.path is None:
+            raise TracError, \
+                  "%s does not appear to be a Subversion repository." % path
+
+        self.repos = repos.svn_repos_open(self.path, self.pool())
+        self.fs_ptr = repos.svn_repos_fs(self.repos)
+        
+        uuid = fs.get_uuid(self.fs_ptr, self.pool())
+        name = 'svn:%s:%s' % (uuid, path)
+
+        Repository.__init__(self, name, authz, log)
+
+        if self.path != path:
+            self.scope = path[len(self.path):]
+            if not self.scope[-1] == '/':
+                self.scope += '/'
+        else:
+            self.scope = '/'
+        self.log.debug("Opening subversion file-system at %s with scope %s" \
+                       % (self.path, self.scope))
+        self.youngest = None
+        self.oldest = None
+
+    def __del__(self):
+        self.close()
+
+    def has_node(self, path, rev, pool=None):
+        if not pool:
+            pool = self.pool
+        rev_root = fs.revision_root(self.fs_ptr, rev, pool())
+        node_type = fs.check_path(rev_root, self.scope + path, pool())
+        return node_type in _kindmap
+
+    def normalize_path(self, path):
+        return _normalize_path(path)
+
+    def normalize_rev(self, rev):
+        try:
+            rev =  int(rev)
+        except (ValueError, TypeError):
+            rev = None
+        if rev is None:
+            rev = self.youngest_rev
+        elif rev > self.youngest_rev:
+            raise TracError, "Revision %s doesn't exist yet" % rev
+        return rev
+
+    def close(self):
+        self.log.debug("Closing subversion file-system at %s" % self.path)
+        self.repos = None
+        self.fs_ptr = None
+        self.pool = None
+
+    def get_changeset(self, rev):
+        return SubversionChangeset(int(rev), self.authz, self.scope,
+                                   self.fs_ptr, self.pool)
+
+    def get_node(self, path, rev=None):
+        path = path or ''
+        self.authz.assert_permission(posixpath.join(self.scope, path))
+        if path and path[-1] == '/':
+            path = path[:-1]
+
+        rev = self.normalize_rev(rev)
+
+        return SubversionNode(path, rev, self.authz, self.scope, self.fs_ptr,
+                              self.pool)
+
+    def _history(self, path, start, end, limit=None):
+        scoped_path = posixpath.join(self.scope[1:], path)
+        return _get_history(scoped_path, self.authz, self.fs_ptr, self.pool,
+                            start, end, limit)
+
+    def get_oldest_rev(self):
+        if self.oldest is None:
+            self.oldest = 1
+            if self.scope != '/':
+                self.oldest = self.next_rev(0, find_initial_rev=True)
+        return self.oldest
+
+    def get_youngest_rev(self):
+        if not self.youngest:
+            self.youngest = fs.youngest_rev(self.fs_ptr, self.pool())
+            if self.scope != '/':
+                for path, rev in self._history('', 0, self.youngest, limit=1):
+                    self.youngest = rev
+        return self.youngest
+
+    def previous_rev(self, rev, path=''):
+        rev = self.normalize_rev(rev)
+        if rev > 1: # don't use oldest here, as it's too expensive
+            try:
+                for _, prev in self._history(path, 0, rev-1, limit=1):
+                    return prev
+            except (SystemError, # "null arg to internal routine" in 1.2.x
+                    core.SubversionException): # in 1.3.x
+                pass
+        return None
+
+    def next_rev(self, rev, path='', find_initial_rev=False):
+        rev = self.normalize_rev(rev)
+        next = rev + 1
+        youngest = self.youngest_rev
+        while next <= youngest:
+            try:
+                for _, next in self._history(path, rev+1, next, limit=1):
+                    return next
+            except (SystemError, # "null arg to internal routine" in 1.2.x
+                    core.SubversionException): # in 1.3.x
+                if not find_initial_rev:
+                    return next # a 'delete' event is also interesting...
+            next += 1
+        return None
+
+    def rev_older_than(self, rev1, rev2):
+        return self.normalize_rev(rev1) < self.normalize_rev(rev2)
+
+    def get_youngest_rev_in_cache(self, db):
+        """Get the latest stored revision by sorting the revision strings
+        numerically
+        """
+        cursor = db.cursor()
+        cursor.execute("SELECT rev FROM revision "
+                       "ORDER BY -LENGTH(rev), rev DESC LIMIT 1")
+        row = cursor.fetchone()
+        return row and row[0] or None
+
+    def get_path_history(self, path, rev=None, limit=None):
+        path = self.normalize_path(path)
+        rev = self.normalize_rev(rev)
+        expect_deletion = False
+        subpool = Pool(self.pool)
+        while rev:
+            subpool.clear()
+            if self.has_node(path, rev, subpool):
+                if expect_deletion:
+                    # it was missing, now it's there again:
+                    #  rev+1 must be a delete
+                    yield path, rev+1, Changeset.DELETE
+                newer = None # 'newer' is the previously seen history tuple
+                older = None # 'older' is the currently examined history tuple
+                for p, r in _get_history(self.scope + path, self.authz,
+                                         self.fs_ptr, subpool, 0, rev, limit):
+                    older = (_path_within_scope(self.scope, p), r,
+                             Changeset.ADD)
+                    rev = self.previous_rev(r)
+                    if newer:
+                        if older[0] == path:
+                            # still on the path: 'newer' was an edit
+                            yield newer[0], newer[1], Changeset.EDIT
+                        else:
+                            # the path changed: 'newer' was a copy
+                            rev = self.previous_rev(newer[1])
+                            # restart before the copy op
+                            yield newer[0], newer[1], Changeset.COPY
+                            older = (older[0], older[1], 'unknown')
+                            break
+                    newer = older
+                if older:
+                    # either a real ADD or the source of a COPY
+                    yield older
+            else:
+                expect_deletion = True
+                rev = self.previous_rev(rev)
+
+    def get_changes(self, old_path, old_rev, new_path, new_rev,
+                   ignore_ancestry=0):
+        old_node = new_node = None
+        old_rev = self.normalize_rev(old_rev)
+        new_rev = self.normalize_rev(new_rev)
+        if self.has_node(old_path, old_rev):
+            old_node = self.get_node(old_path, old_rev)
+        else:
+            raise TracError, ('The Base for Diff is invalid: path %s'
+                              ' doesn\'t exist in revision %s' \
+                              % (old_path, old_rev))
+        if self.has_node(new_path, new_rev):
+            new_node = self.get_node(new_path, new_rev)
+        else:
+            raise TracError, ('The Target for Diff is invalid: path %s'
+                              ' doesn\'t exist in revision %s' \
+                              % (new_path, new_rev))
+        if new_node.kind != old_node.kind:
+            raise TracError, ('Diff mismatch: Base is a %s (%s in revision %s) '
+                              'and Target is a %s (%s in revision %s).' \
+                              % (old_node.kind, old_path, old_rev,
+                                 new_node.kind, new_path, new_rev))
+        subpool = Pool(self.pool)
+        if new_node.isdir:
+            editor = DiffChangeEditor()
+            e_ptr, e_baton = delta.make_editor(editor, subpool())
+            old_root = fs.revision_root(self.fs_ptr, old_rev, subpool())
+            new_root = fs.revision_root(self.fs_ptr, new_rev, subpool())
+            def authz_cb(root, path, pool): return 1
+            text_deltas = 0 # as this is anyway re-done in Diff.py...
+            entry_props = 0 # "... typically used only for working copy updates"
+            repos.svn_repos_dir_delta(old_root,
+                                      (self.scope + old_path).strip('/'), '',
+                                      new_root,
+                                      (self.scope + new_path).strip('/'),
+                                      e_ptr, e_baton, authz_cb,
+                                      text_deltas,
+                                      1, # directory
+                                      entry_props,
+                                      ignore_ancestry,
+                                      subpool())
+            for path, kind, change in editor.deltas:
+                old_node = new_node = None
+                if change != Changeset.ADD:
+                    old_node = self.get_node(posixpath.join(old_path, path),
+                                             old_rev)
+                if change != Changeset.DELETE:
+                    new_node = self.get_node(posixpath.join(new_path, path),
+                                             new_rev)
+                else:
+                    kind = _kindmap[fs.check_path(old_root,
+                                                  self.scope + old_node.path,
+                                                  subpool())]
+                yield  (old_node, new_node, kind, change)
+        else:
+            old_root = fs.revision_root(self.fs_ptr, old_rev, subpool())
+            new_root = fs.revision_root(self.fs_ptr, new_rev, subpool())
+            if fs.contents_changed(old_root, self.scope + old_path,
+                                   new_root, self.scope + new_path,
+                                   subpool()):
+                yield (old_node, new_node, Node.FILE, Changeset.EDIT)
+
+
+class SubversionNode(Node):
+
+    def __init__(self, path, rev, authz, scope, fs_ptr, pool=None):
+        self.authz = authz
+        self.scope = scope
+        if scope != '/':
+            self.scoped_path = scope + path
+        else:
+            self.scoped_path = path
+        self.fs_ptr = fs_ptr
+        self.pool = Pool(pool)
+        self._requested_rev = rev
+
+        self.root = fs.revision_root(fs_ptr, rev, self.pool())
+        node_type = fs.check_path(self.root, self.scoped_path, self.pool())
+        if not node_type in _kindmap:
+            raise TracError, "No node at %s in revision %s" % (path, rev)
+        self.created_rev = fs.node_created_rev(self.root, self.scoped_path,
+                                               self.pool())
+        self.created_path = fs.node_created_path(self.root, self.scoped_path,
+                                                 self.pool())
+        # Note: 'created_path' differs from 'path' if the last change was a copy,
+        #        and furthermore, 'path' might not exist at 'create_rev'.
+        #        The only guarantees are:
+        #          * this node exists at (path,rev)
+        #          * the node existed at (created_path,created_rev)
+        # TODO: check node id
+        self.rev = self.created_rev
+        
+        Node.__init__(self, path, self.rev, _kindmap[node_type])
+
+    def get_content(self):
+        if self.isdir:
+            return None
+        s = core.Stream(fs.file_contents(self.root, self.scoped_path,
+                                         self.pool()))
+        # Make sure the stream object references the pool to make sure the pool
+        # is not destroyed before the stream object.
+        s._pool = self.pool
+        return s
+
+    def get_entries(self):
+        if self.isfile:
+            return
+        pool = Pool(self.pool)
+        entries = fs.dir_entries(self.root, self.scoped_path, pool())
+        for item in entries.keys():
+            path = '/'.join((self.path, item))
+            if not self.authz.has_permission(path):
+                continue
+            yield SubversionNode(path, self._requested_rev, self.authz,
+                                 self.scope, self.fs_ptr, self.pool)
+
+    def get_history(self,limit=None):
+        newer = None # 'newer' is the previously seen history tuple
+        older = None # 'older' is the currently examined history tuple
+        pool = Pool(self.pool)
+        for path, rev in _get_history(self.scoped_path, self.authz, self.fs_ptr,
+                                      pool, 0, self._requested_rev, limit):
+            path = _path_within_scope(self.scope, path)
+            if rev > 0 and path:
+                older = (path, rev, Changeset.ADD)
+                if newer:
+                    change = newer[0] == older[0] and Changeset.EDIT or \
+                             Changeset.COPY
+                    newer = (newer[0], newer[1], change)
+                    yield newer
+                newer = older
+        if newer:
+            yield newer
+
+#    def get_previous(self):
+#        # FIXME: redo it with fs.node_history
+
+    def get_properties(self):
+        props = fs.node_proplist(self.root, self.scoped_path, self.pool())
+        for name,value in props.items():
+            props[name] = str(value) # Make sure the value is a proper string
+        return props
+
+    def get_content_length(self):
+        if self.isdir:
+            return None
+        return fs.file_length(self.root, self.scoped_path, self.pool())
+
+    def get_content_type(self):
+        if self.isdir:
+            return None
+        return self._get_prop(core.SVN_PROP_MIME_TYPE)
+
+    def get_last_modified(self):
+        date = fs.revision_prop(self.fs_ptr, self.created_rev,
+                                core.SVN_PROP_REVISION_DATE, self.pool())
+        return core.svn_time_from_cstring(date, self.pool()) / 1000000
+
+    def _get_prop(self, name):
+        return fs.node_prop(self.root, self.scoped_path, name, self.pool())
+
+
+class SubversionChangeset(Changeset):
+
+    def __init__(self, rev, authz, scope, fs_ptr, pool=None):
+        self.rev = rev
+        self.authz = authz
+        self.scope = scope
+        self.fs_ptr = fs_ptr
+        self.pool = Pool(pool)
+        message = self._get_prop(core.SVN_PROP_REVISION_LOG)
+        author = self._get_prop(core.SVN_PROP_REVISION_AUTHOR)
+        date = self._get_prop(core.SVN_PROP_REVISION_DATE)
+        date = core.svn_time_from_cstring(date, self.pool()) / 1000000
+        Changeset.__init__(self, rev, message, author, date)
+
+    def get_changes(self):
+        pool = Pool(self.pool)
+        tmp = Pool(pool)
+        root = fs.revision_root(self.fs_ptr, self.rev, pool())
+        editor = repos.RevisionChangeCollector(self.fs_ptr, self.rev, pool())
+        e_ptr, e_baton = delta.make_editor(editor, pool())
+        repos.svn_repos_replay(root, e_ptr, e_baton, pool())
+
+        idx = 0
+        copies, deletions = {}, {}
+        changes = []
+        revroots = {}
+        for path, change in editor.changes.items():
+            tmp.clear()
+            if not self.authz.has_permission(path):
+                # FIXME: what about base_path?
+                continue
+            if not (path+'/').startswith(self.scope[1:]):
+                continue
+            action = ''
+            if not change.path and change.base_path:
+                action = Changeset.DELETE
+                deletions[change.base_path] = idx
+            elif change.added:
+                if change.base_path and change.base_rev:
+                    action = Changeset.COPY
+                    copies[change.base_path] = idx
+                else:
+                    action = Changeset.ADD
+            else:
+                action = Changeset.EDIT
+                b_path, b_rev = change.base_path, change.base_rev
+                if revroots.has_key(b_rev):
+                    b_root = revroots[b_rev]
+                else:
+                    b_root = fs.revision_root(self.fs_ptr, b_rev, pool())
+                    revroots[b_rev] = b_root
+                change.base_path = fs.node_created_path(b_root, b_path, tmp())
+                change.base_rev = fs.node_created_rev(b_root, b_path, tmp())
+            kind = _kindmap[change.item_kind]
+            path = path[len(self.scope) - 1:]
+            base_path = _path_within_scope(self.scope, change.base_path)
+            changes.append([path, kind, action, base_path, change.base_rev])
+            idx += 1
+
+        moves = []
+        for k,v in copies.items():
+            if k in deletions:
+                changes[v][2] = Changeset.MOVE
+                moves.append(deletions[k])
+        offset = 0
+        moves.sort()
+        for i in moves:
+            del changes[i - offset]
+            offset += 1
+
+        changes.sort()
+        for change in changes:
+            yield tuple(change)
+
+    def _get_prop(self, name):
+        return fs.revision_prop(self.fs_ptr, self.rev, name, self.pool())
+
+
+#
+# Delta editor for diffs between arbitrary nodes
+#
+# Note 1: the 'copyfrom_path' and 'copyfrom_rev' information is not used
+#         because 'repos.svn_repos_dir_delta' *doesn't* provide it.
+#
+# Note 2: the 'dir_baton' is the path of the parent directory
+#
+
+class DiffChangeEditor(delta.Editor): 
+
+    def __init__(self):
+        self.deltas = []
+    
+    # -- svn.delta.Editor callbacks
+
+    def open_root(self, base_revision, dir_pool):
+        return ('/', Changeset.EDIT)
+
+    def add_directory(self, path, dir_baton, copyfrom_path, copyfrom_rev,
+                      dir_pool):
+        self.deltas.append((path, Node.DIRECTORY, Changeset.ADD))
+        return (path, Changeset.ADD)
+
+    def open_directory(self, path, dir_baton, base_revision, dir_pool):
+        return (path, dir_baton[1])
+
+    def change_dir_prop(self, dir_baton, name, value, pool):
+        path, change = dir_baton
+        if change != Changeset.ADD:
+            self.deltas.append((path, Node.DIRECTORY, change))
+
+    def delete_entry(self, path, revision, dir_baton, pool):
+        self.deltas.append((path, None, Changeset.DELETE))
+
+    def add_file(self, path, dir_baton, copyfrom_path, copyfrom_revision,
+                 dir_pool):
+        self.deltas.append((path, Node.FILE, Changeset.ADD))
+
+    def open_file(self, path, dir_baton, dummy_rev, file_pool):
+        self.deltas.append((path, Node.FILE, Changeset.EDIT))
+
diff -urN trac-trunk/build/lib/trac/versioncontrol/web_ui/__init__.py aw-trac/build/lib/trac/versioncontrol/web_ui/__init__.py
--- trac-trunk/build/lib/trac/versioncontrol/web_ui/__init__.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/web_ui/__init__.py	2006-01-19 05:39:35.000000000 -0800
@@ -0,0 +1,4 @@
+from trac.versioncontrol.web_ui.browser import *
+from trac.versioncontrol.web_ui.changeset import *
+from trac.versioncontrol.web_ui.log import *
+
diff -urN trac-trunk/build/lib/trac/versioncontrol/web_ui/browser.py aw-trac/build/lib/trac/versioncontrol/web_ui/browser.py
--- trac-trunk/build/lib/trac/versioncontrol/web_ui/browser.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/web_ui/browser.py	2006-03-06 05:18:14.000000000 -0800
@@ -0,0 +1,256 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+import re
+import urllib
+
+from trac import util
+from trac.util import sorted
+from trac.core import *
+from trac.mimeview import Mimeview, is_binary, get_mimetype
+from trac.perm import IPermissionRequestor
+from trac.web import IRequestHandler, RequestDone
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.wiki import wiki_to_html, wiki_to_oneliner, IWikiSyntaxProvider
+from trac.versioncontrol.web_ui.util import *
+
+
+IMG_RE = re.compile(r"\.(gif|jpg|jpeg|png)(\?.*)?$", re.IGNORECASE)
+
+CHUNK_SIZE = 4096
+
+
+class BrowserModule(Component):
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
+               IWikiSyntaxProvider)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'browser'
+
+    def get_navigation_items(self, req):
+        if not req.perm.has_permission('BROWSER_VIEW'):
+            return
+        yield ('mainnav', 'browser',
+               util.Markup('<a href="%s">Browse Source</a>',
+                           self.env.href.browser()))
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        return ['BROWSER_VIEW', 'FILE_VIEW']
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        import re
+        match = re.match(r'/(browser|file)(?:(/.*))?', req.path_info)
+        if match:
+            req.args['path'] = match.group(2) or '/'
+            if match.group(1) == 'file':
+                # FIXME: This should be a permanent redirect
+                req.redirect(self.env.href.browser(req.args.get('path'),
+                                                   rev=req.args.get('rev'),
+                                                   format=req.args.get('format')))
+            return True
+
+    def process_request(self, req):
+        path = req.args.get('path', '/')
+        rev = req.args.get('rev')
+
+        repos = self.env.get_repository(req.authname)
+        node = get_existing_node(self.env, repos, path, rev)
+        rev = repos.normalize_rev(rev)
+
+        hidden_properties = [p.strip() for p
+                             in self.config.get('browser', 'hide_properties').split(',')]
+
+        req.hdf['title'] = path
+        req.hdf['browser'] = {
+            'path': path,
+            'revision': rev,
+            'props': [{'name': name, 'value': value}
+                      for name, value in node.get_properties().items()
+                      if not name in hidden_properties],
+            'href': self.env.href.browser(path, rev=rev or
+                                          repos.youngest_rev),
+            'log_href': self.env.href.log(path, rev=rev or None),
+            'restr_changeset_href': self.env.href.changeset(node.rev, path),
+            'anydiff_href': self.env.href.anydiff(),
+        }
+
+        path_links = get_path_links(self.env.href, path, rev)
+        if len(path_links) > 1:
+            add_link(req, 'up', path_links[-2]['href'], 'Parent directory')
+        req.hdf['browser.path'] = path_links
+
+        if node.isdir:
+            req.hdf['browser.is_dir'] = True
+            self._render_directory(req, repos, node, rev)
+        else:
+            self._render_file(req, repos, node, rev)
+
+        add_stylesheet(req, 'common/css/browser.css')
+        return 'browser.cs', None
+
+    # Internal methods
+
+    def _render_directory(self, req, repos, node, rev=None):
+        req.perm.assert_permission('BROWSER_VIEW')
+
+        order = req.args.get('order', 'name').lower()
+        req.hdf['browser.order'] = order
+        desc = req.args.has_key('desc')
+        req.hdf['browser.desc'] = desc and 1 or 0
+
+        info = []
+        for entry in node.get_entries():
+            info.append({
+                'name': entry.name,
+                'fullpath': entry.path,
+                'is_dir': int(entry.isdir),
+                'content_length': entry.content_length,
+                'size': util.pretty_size(entry.content_length),
+                'rev': entry.rev,
+                'permission': 1, # FIXME
+                'log_href': self.env.href.log(entry.path, rev=rev),
+                'browser_href': self.env.href.browser(entry.path,
+                                                      rev=rev)
+            })
+        changes = get_changes(self.env, repos, [i['rev'] for i in info])
+
+        if order == 'date':
+            def file_order(a):
+                return changes[a['rev']]['date_seconds']
+        elif order == 'size':
+            def file_order(a):
+                return (a['content_length'],
+                        util.embedded_numbers(a['name'].lower()))
+        else:
+            def file_order(a):
+                return util.embedded_numbers(a['name'].lower())
+
+        dir_order = desc and 1 or -1
+
+        def browse_order(a):
+            return a['is_dir'] and dir_order or 0, file_order(a)
+        info = sorted(info, key=browse_order, reverse=desc)
+
+        req.hdf['browser.items'] = info
+        req.hdf['browser.changes'] = changes
+        if node.path != '':
+            zip_href = self.env.href.changeset(rev, node.path, old=rev,
+                                               old_path='/', # special case #238
+                                               format='zip')
+            add_link(req, 'alternate', zip_href, 'Zip Archive',
+                     'application/zip', 'zip')
+        
+        
+    def _render_file(self, req, repos, node, rev=None):
+        req.perm.assert_permission('FILE_VIEW')
+
+        changeset = repos.get_changeset(node.rev)  
+        req.hdf['file'] = {  
+            'rev': node.rev,  
+            'changeset_href': self.env.href.changeset(node.rev),
+            'date': util.format_datetime(changeset.date),
+            'age': util.pretty_timedelta(changeset.date),
+            'author': changeset.author or 'anonymous',
+            'message': wiki_to_html(changeset.message or '--', self.env, req,
+                                    escape_newlines=True)
+        }
+
+        mimeview = Mimeview(self.env)
+        
+        def get_mime_type(content=None):
+            mime_type = node.content_type
+            if not mime_type or mime_type == 'application/octet-stream':
+                mime_type = get_mimetype(node.name, content) or \
+                            mime_type or 'text/plain'
+            return mime_type
+
+        format = req.args.get('format')
+        if format in ['raw', 'txt']:
+            content = node.get_content()
+            chunk = content.read(CHUNK_SIZE)
+            mime_type = get_mime_type(chunk)
+
+            req.send_response(200)
+            req.send_header('Content-Type',
+                            format == 'txt' and 'text/plain' or mime_type)
+            req.send_header('Content-Length', node.content_length)
+            req.send_header('Last-Modified', util.http_date(node.last_modified))
+            req.end_headers()
+
+            while 1:
+                if not chunk:
+                    raise RequestDone
+                req.write(chunk)
+                chunk = content.read(CHUNK_SIZE)
+        else:
+            # Generate HTML preview
+            content = node.get_content().read(mimeview.max_preview_size())
+            mime_type = get_mime_type(content)
+            use_rev = rev and node.rev
+            
+            if not is_binary(content):
+                if mime_type != 'text/plain':
+                    plain_href = self.env.href.browser(node.path, rev=use_rev,
+                                                       format='txt')
+                    add_link(req, 'alternate', plain_href, 'Plain Text',
+                             'text/plain')
+                    
+            self.log.debug("Rendering preview of file %s with mime-type %s"
+                           % (node.name, mime_type))
+
+            req.hdf['file'] = mimeview.preview_to_hdf(req, content, mime_type,
+                                                      node.name, node.rev,
+                                                      annotations=['lineno'])
+
+            raw_href = self.env.href.browser(node.path, rev=use_rev,
+                                             format='raw')
+            add_link(req, 'alternate', raw_href, 'Original Format', mime_type)
+            req.hdf['file.raw_href'] = raw_href
+
+            add_stylesheet(req, 'common/css/code.css')
+
+    # IWikiSyntaxProvider methods
+    
+    def get_wiki_syntax(self):
+        return []
+
+    def get_link_resolvers(self):
+        return [('repos', self._format_link),
+                ('source', self._format_link),
+                ('browser', self._format_link)]
+
+    def _format_link(self, formatter, ns, path, label):
+        match = IMG_RE.search(path)
+        if formatter.flavor != 'oneliner' and match:
+            return '<img src="%s" alt="%s" />' % \
+                   (formatter.href.file(path, format='raw'), label)
+        path, rev, line = get_path_rev_line(path)
+        if line is not None:
+            anchor = '#L%d' % line
+        else:
+            anchor = ''
+        label = urllib.unquote(label)
+        return '<a class="source" href="%s%s">%s</a>' \
+               % (util.escape(formatter.href.browser(path, rev=rev)), anchor,
+                  label)
diff -urN trac-trunk/build/lib/trac/versioncontrol/web_ui/changeset.py aw-trac/build/lib/trac/versioncontrol/web_ui/changeset.py
--- trac-trunk/build/lib/trac/versioncontrol/web_ui/changeset.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/web_ui/changeset.py	2006-03-08 07:36:24.000000000 -0800
@@ -0,0 +1,739 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+#         Christian Boos <cboos@neuf.fr>
+
+import time
+import re
+import posixpath
+from urllib import urlencode
+
+from trac import util
+from trac.core import *
+from trac.mimeview import Mimeview, is_binary
+from trac.perm import IPermissionRequestor
+from trac.Search import ISearchSource, search_to_sql, shorten_result
+from trac.Timeline import ITimelineEventProvider
+from trac.versioncontrol import Changeset, Node
+from trac.versioncontrol.diff import get_diff_options, hdf_diff, unified_diff
+from trac.versioncontrol.svn_authz import SubversionAuthorizer
+from trac.web import IRequestHandler
+from trac.web.chrome import INavigationContributor, add_link, add_stylesheet
+from trac.wiki import wiki_to_html, wiki_to_oneliner, IWikiSyntaxProvider, \
+                      Formatter
+
+
+class DiffArgs(dict):
+    def __getattr__(self,str):
+        return self[str]
+
+
+class ChangesetModule(Component):
+    """Provide flexible functionality for showing sets of differences.
+
+    If the differences shown are coming from a specific changeset,
+    then that changeset informations can be shown too.
+
+    In addition, it is possible to show only a subset of the changeset:
+    Only the changes affecting a given path will be shown.
+    This is called the ''restricted'' changeset.
+
+    But the differences can also be computed in a more general way,
+    between two arbitrary paths and/or between two arbitrary revisions.
+    In that case, there's no changeset information displayed.
+    """
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
+               ITimelineEventProvider, IWikiSyntaxProvider, ISearchSource)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'browser'
+
+    def get_navigation_items(self, req):
+        return []
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        return ['CHANGESET_VIEW']
+
+    # IRequestHandler methods
+
+    _request_re = re.compile(r"/changeset(?:/([^/]+))?(/.*)?$")
+    
+    def match_request(self, req):
+        match = re.match(self._request_re, req.path_info)
+        if match:
+            new, new_path = match.groups()
+            if new:
+                req.args['new'] = new
+            if new_path:
+                req.args['new_path'] = new_path
+            return True
+
+    def process_request(self, req):
+        """
+        The appropriate mode of operation is inferred from the request
+        parameters:
+         * If `new_path` and `old_path` are equal (or `old_path` is omitted)
+           and `new` and `old` are equal (or `old` is omitted),
+           then we're about to view a revision Changeset: `chgset` is True.
+           Furthermore, if the path is not the root, the changeset is 
+           ''restricted'' to that path (only the changes affecting that path,
+           its children or its ancestor directories will be shown).
+         * In any other case, the set of changes corresponds to arbitrary
+           differences between path@rev pairs. If `new_path` and `old_path`
+           are equal, the ''restricted'' flag will also be set, meaning in this
+           case that the differences between two revisions are restricted to
+           those occurring on that path.
+         
+        In any case, either path@rev pairs must exist.
+        """
+        req.perm.assert_permission('CHANGESET_VIEW')
+        
+        # -- retrieve arguments
+        new_path = req.args.get('new_path')
+        new = req.args.get('new')
+        old_path = req.args.get('old_path')
+        old = req.args.get('old')
+
+        if old and '@' in old:
+            old_path, old = util.unescape(old).split('@')
+        if new and '@' in new:
+            new_path, new = util.unescape(new).split('@')
+
+        # -- normalize and check for special case
+        repos = self.env.get_repository(req.authname)
+        new_path = repos.normalize_path(new_path)
+        new = repos.normalize_rev(new)
+        old_path = repos.normalize_path(old_path or new_path)
+        old = repos.normalize_rev(old or new)
+
+        authzperm = SubversionAuthorizer(self.env, req.authname)
+        authzperm.assert_permission_for_changeset(new)
+
+        if old_path == new_path and old == new: # revert to Changeset
+            old_path = old = None
+
+        diff_options = get_diff_options(req)
+
+        # -- setup the `chgset` and `restricted` flags, see docstring above.
+        chgset = not old and not old_path
+        if chgset:
+            restricted = new_path not in ('', '/') # (subset or not)
+        else:
+            restricted = old_path == new_path # (same path or not)
+
+        # -- redirect if changing the diff options
+        if req.args.has_key('update'):
+            if chgset:
+                if restricted:
+                    req.redirect(self.env.href.changeset(new, new_path))
+                else:
+                    req.redirect(self.env.href.changeset(new))
+            else:
+                req.redirect(self.env.href.changeset(new, new_path, old=old,
+                                                     old_path=old_path))
+
+        # -- preparing the diff arguments
+        if chgset:
+            prev = repos.get_node(new_path, new).get_previous()
+            if prev:
+                prev_path, prev_rev = prev[:2]
+            else:
+                prev_path, prev_rev = new_path, repos.previous_rev(new)
+            diff_args = DiffArgs(old_path=prev_path, old_rev=prev_rev,
+                                 new_path=new_path, new_rev=new)
+        else:
+            if not new:
+                new = repos.youngest_rev
+            elif not old:
+                old = repos.youngest_rev
+            if not old_path:
+                old_path = new_path
+            diff_args = DiffArgs(old_path=old_path, old_rev=old,
+                                 new_path=new_path, new_rev=new)
+        if chgset:
+            chgset = repos.get_changeset(new)
+            req.check_modified(chgset.date, [
+                diff_options[0],
+                ''.join(diff_options[1]),
+                repos.name,
+                repos.rev_older_than(new, repos.youngest_rev),
+                chgset.message,
+                util.pretty_timedelta(chgset.date, None, 3600)])
+        else:
+            pass # FIXME: what date should we choose for a diff?
+
+        req.hdf['changeset'] = diff_args
+
+        format = req.args.get('format')
+
+        if format in ['diff', 'zip']:
+            # choosing an appropriate filename
+            rpath = new_path.replace('/','_')
+            if chgset:
+                if restricted:
+                    filename = 'changeset_%s_r%s' % (rpath, new)
+                else:
+                    filename = 'changeset_r%s' % new
+            else:
+                if restricted:
+                    filename = 'diff-%s-from-r%s-to-r%s' \
+                                  % (rpath, old, new)
+                elif old_path == '/': # special case for download (#238)
+                    filename = '%s-r%s' % (rpath, old)
+                else:
+                    filename = 'diff-from-%s-r%s-to-%s-r%s' \
+                               % (old_path.replace('/','_'), old, rpath, new)
+            if format == 'diff':
+                self._render_diff(req, filename, repos, diff_args,
+                                  diff_options)
+                return
+            elif format == 'zip':
+                self._render_zip(req, filename, repos, diff_args)
+                return
+
+        # -- HTML format
+        self._render_html(req, repos, chgset, restricted,
+                          diff_args, diff_options)
+        if chgset:
+            diff_params = 'new=%s' % new
+        else:
+            diff_params = urlencode({'new_path': new_path,
+                                     'new': new,
+                                     'old_path': old_path,
+                                     'old': old})
+        add_link(req, 'alternate', '?format=diff&'+diff_params, 'Unified Diff',
+                 'text/plain', 'diff')
+        add_link(req, 'alternate', '?format=zip&'+diff_params, 'Zip Archive',
+                 'application/zip', 'zip')
+        add_stylesheet(req, 'common/css/changeset.css')
+        add_stylesheet(req, 'common/css/diff.css')
+        add_stylesheet(req, 'common/css/code.css')
+        return 'changeset.cs', None
+
+    # Internal methods
+
+    def _render_html(self, req, repos, chgset, restricted, diff, diff_options):
+        """HTML version"""
+        req.hdf['changeset'] = {
+            'chgset': chgset and True,
+            'restricted': restricted,
+            'href': { 'new_rev': self.env.href.changeset(diff.new_rev),
+                      'old_rev': self.env.href.changeset(diff.old_rev),
+                      'new_path': self.env.href.browser(diff.new_path,
+                                                        rev=diff.new_rev),
+                      'old_path': self.env.href.browser(diff.old_path,
+                                                        rev=diff.old_rev),
+                      }
+            }
+        
+        if chgset: # Changeset Mode (possibly restricted on a path)
+            path, rev = diff.new_path, diff.new_rev
+
+            # -- getting the change summary from the Changeset.get_changes 
+            def get_changes():
+                old_node = new_node = None
+                for npath, kind, change, opath, orev in chgset.get_changes():
+                    if (restricted and 
+                        not (npath == path or                # same path
+                             npath.startswith(path + '/') or # npath is below
+                             path.startswith(npath + '/'))): # npath is above
+                        continue
+                    if change != Changeset.ADD:
+                        old_node = repos.get_node(opath, orev)
+                    if change != Changeset.DELETE:
+                        new_node = repos.get_node(npath, rev)
+                    yield old_node, new_node, kind, change
+                    
+            def _changeset_title(rev):
+                if restricted:
+                    return 'Changeset %s for %s' % (rev, path)
+                else:
+                    return 'Changeset %s' % rev
+
+            title = _changeset_title(rev)
+            req.hdf['changeset'] = {
+                'revision': chgset.rev,
+                'time': util.format_datetime(chgset.date),
+                'age': util.pretty_timedelta(chgset.date, None, 3600),
+                'author': chgset.author or 'anonymous',
+                'message': wiki_to_html(chgset.message or '--', self.env, req,
+                                        escape_newlines=True)
+                }
+            oldest_rev = repos.oldest_rev
+            if chgset.rev != oldest_rev:
+                if restricted:
+                    prev = repos.get_node(path, rev).get_previous()
+                    if prev:
+                        prev_path, prev_rev = prev[:2]
+                        if prev_rev:
+                            prev_href = self.env.href.changeset(prev_rev,
+                                                                prev_path)
+                    else:
+                        prev_path = prev_rev = None
+                else:
+                    add_link(req, 'first', self.env.href.changeset(oldest_rev),
+                             'Changeset %s' % oldest_rev)
+                    prev_path = diff.old_path
+                    prev_rev = repos.previous_rev(chgset.rev)
+                    if prev_rev:
+                        prev_href = self.env.href.changeset(prev_rev)
+                if prev_rev:
+                    add_link(req, 'prev', prev_href, _changeset_title(prev_rev))
+            youngest_rev = repos.youngest_rev
+            if str(chgset.rev) != str(youngest_rev):
+                if restricted:
+                    next_rev = repos.next_rev(chgset.rev, path)
+                    if next_rev:
+                        next_href = self.env.href.changeset(next_rev, path)
+                else:
+                    add_link(req, 'last', self.env.href.changeset(youngest_rev),
+                             'Changeset %s' % youngest_rev)
+                    next_rev = repos.next_rev(chgset.rev)
+                    if next_rev:
+                        next_href = self.env.href.changeset(next_rev)
+                if next_rev:
+                    add_link(req, 'next', next_href, _changeset_title(next_rev))
+
+        else: # Diff Mode
+            # -- getting the change summary from the Repository.get_changes 
+            def get_changes():
+                for d in repos.get_changes(**diff):
+                    yield d
+                    
+            reverse_href = self.env.href.changeset(diff.old_rev, diff.old_path,
+                                                   old=diff.new_rev,
+                                                   old_path=diff.new_path)
+            req.hdf['changeset.reverse_href'] = reverse_href
+            req.hdf['changeset.href.log'] = self.env.href.log(
+                diff.new_path, rev=diff.new_rev, stop_rev=diff.old_rev)
+            title = self.title_for_diff(diff)
+        req.hdf['title'] = title
+
+        def _change_info(old_node, new_node, change):
+            info = {'change': change}
+            if old_node:
+                info['path.old'] = old_node.path
+                info['rev.old'] = old_node.rev
+                old_href = self.env.href.browser(old_node.created_path,
+                                                 rev=old_node.created_rev)
+                # Reminder: old_node.path may not exist at old_node.rev
+                #           as long as old_node.rev==old_node.created_rev
+                #           ... and diff.old_rev may have nothing to do
+                #           with _that_ node specific history...
+                info['browser_href.old'] = old_href
+            if new_node:
+                info['path.new'] = new_node.path
+                info['rev.new'] = new_node.rev # created rev.
+                new_href = self.env.href.browser(new_node.created_path,
+                                                 rev=new_node.created_rev)
+                # (same remark as above)
+                info['browser_href.new'] = new_href
+            return info
+
+        hidden_properties = [p.strip() for p
+                             in self.config.get('browser', 'hide_properties').split(',')]
+
+        def _prop_changes(old_node, new_node):
+            old_props = old_node.get_properties()
+            new_props = new_node.get_properties()
+            changed_props = {}
+            if old_props != new_props:
+                for k,v in old_props.items():
+                    if not k in new_props:
+                        changed_props[k] = {'old': v}
+                    elif v != new_props[k]:
+                        changed_props[k] = {'old': v, 'new': new_props[k]}
+                for k,v in new_props.items():
+                    if not k in old_props:
+                        changed_props[k] = {'new': v}
+                for k in hidden_properties:
+                    if k in changed_props:
+                        del changed_props[k]
+            changed_properties = []
+            for name, props in changed_props.iteritems():
+                props.update(name=name)
+                changed_properties.append(props)
+            return changed_properties
+
+        def _estimate_changes(old_node, new_node):
+            old_size = old_node.get_content_length()
+            new_size = new_node.get_content_length()
+            return old_size + new_size
+
+        mimeview = Mimeview(self.env)
+
+        def _content_changes(old_node, new_node):
+            """
+            Returns the list of differences.
+            The list is empty when no differences between comparable files
+            are detected, but the return value is None for non-comparable files.
+            """
+            data = old_node.get_content().read()
+            if is_binary(data):
+                return None
+            old_content = mimeview.to_utf8(data, old_node.content_type)
+
+            data = new_node.get_content().read()
+            if is_binary(data):
+                return None
+            new_content = mimeview.to_utf8(data, new_node.content_type)
+
+            if old_content != new_content:
+                context = 3
+                options = diff_options[1]
+                for option in options:
+                    if option.startswith('-U'):
+                        context = int(option[2:])
+                        break
+                if context < 0:
+                    context = None
+                tabwidth = int(self.config.get('diff', 'tab_width',
+                                               self.config.get('mimeviewer',
+                                                               'tab_width')))
+                return hdf_diff(old_content.splitlines(),
+                                new_content.splitlines(),
+                                context, tabwidth,
+                                ignore_blank_lines='-B' in options,
+                                ignore_case='-i' in options,
+                                ignore_space_changes='-b' in options)
+            else:
+                return []
+
+        max_diff_bytes = int(self.config.get('changeset', 'max_diff_bytes'))
+        max_diff_files = int(self.config.get('changeset', 'max_diff_files'))
+        diff_bytes = diff_files = 0
+        if max_diff_bytes or max_diff_files:
+            for old_node, new_node, kind, change in get_changes():
+                if change == Changeset.EDIT and kind == Node.FILE:
+                    diff_files += 1
+                    diff_bytes += _estimate_changes(old_node, new_node)
+        show_diffs = (not max_diff_files or diff_files <= max_diff_files) and \
+                     (not max_diff_bytes or diff_bytes <= max_diff_bytes or \
+                      diff_files == 1)                      
+                
+        idx = 0
+        for old_node, new_node, kind, change in get_changes():
+            if change != Changeset.EDIT:
+                show_entry = True
+            else:
+                show_entry = False
+                assert old_node and new_node
+                props = _prop_changes(old_node, new_node)
+                if props:
+                    req.hdf['changeset.changes.%d.props' % idx] = props
+                    show_entry = True
+                if kind == Node.FILE and show_diffs:
+                    diffs = _content_changes(old_node, new_node)
+                    if diffs != []:
+                        if diffs:
+                            req.hdf['changeset.changes.%d.diff' % idx] = diffs
+                        # elif None (means: manually compare to (previous))
+                        show_entry = True
+            if show_entry or not show_diffs:
+                info = _change_info(old_node, new_node, change)
+                if change == Changeset.EDIT and not show_diffs:
+                    if chgset:
+                        diff_href = self.env.href.changeset(new_node.rev,
+                                                            new_node.path)
+                    else:
+                        diff_href = self.env.href.changeset(
+                            new_node.created_rev, new_node.created_path,
+                            old=old_node.created_rev,
+                            old_path=old_node.created_path)
+                    info['diff_href'] = diff_href                        
+                req.hdf['changeset.changes.%d' % idx] = info
+            idx += 1 # the sequence should be immutable
+
+    def _render_diff(self, req, filename, repos, diff, diff_options):
+        """Raw Unified Diff version"""
+        req.send_response(200)
+        req.send_header('Content-Type', 'text/plain;charset=utf-8')
+        req.send_header('Content-Disposition', 'inline;'
+                        'filename=%s.diff' % filename)
+        req.end_headers()
+
+        mimeview = Mimeview(self.env)
+        for old_node, new_node, kind, change in repos.get_changes(**diff):
+            # TODO: Property changes
+
+            # Content changes
+            if kind == Node.DIRECTORY:
+                continue
+
+            new_content = old_content = ''
+            new_node_info = old_node_info = ('','')
+
+            if old_node:
+                data = old_node.get_content().read()
+                if is_binary(data):
+                    continue
+                old_content = mimeview.to_utf8(data, old_node.content_type)
+                old_node_info = (old_node.path, old_node.rev)
+
+            if new_node:
+                data = new_node.get_content().read()
+                if is_binary(data):
+                    continue
+                new_content = mimeview.to_utf8(data, new_node.content_type) 
+                new_node_info = (new_node.path, new_node.rev)
+                new_path = new_node.path
+            else:
+                old_node_path = repos.normalize_path(old_node.path)
+                diff_old_path = repos.normalize_path(diff.old_path)
+                new_path = posixpath.join(diff.new_path,
+                                          old_node_path[len(diff_old_path)+1:])
+
+            if old_content != new_content:
+                context = 3
+                options = diff_options[1]
+                for option in options:
+                    if option.startswith('-U'):
+                        context = int(option[2:])
+                        break
+                if not old_node_info[0]:
+                    old_node_info = new_node_info # support for 'A'dd changes
+                req.write('Index: ' + new_path + util.CRLF)
+                req.write('=' * 67 + util.CRLF)
+                req.write('--- %s (revision %s)' % old_node_info +
+                          util.CRLF)
+                req.write('+++ %s (revision %s)' % new_node_info +
+                          util.CRLF)
+                for line in unified_diff(old_content.splitlines(),
+                                         new_content.splitlines(), context,
+                                         ignore_blank_lines='-B' in options,
+                                         ignore_case='-i' in options,
+                                         ignore_space_changes='-b' in options):
+                    req.write(line + util.CRLF)
+
+    def _render_zip(self, req, filename, repos, diff):
+        """ZIP archive with all the added and/or modified files."""
+        new_rev = diff.new_rev
+        req.send_response(200)
+        req.send_header('Content-Type', 'application/zip')
+        req.send_header('Content-Disposition', 'attachment;'
+                        'filename=%s.zip' % filename)
+
+        try:
+            from cStringIO import StringIO
+        except ImportError:
+            from StringIO import StringIO
+        from zipfile import ZipFile, ZipInfo, ZIP_DEFLATED
+
+        buf = StringIO()
+        zipfile = ZipFile(buf, 'w', ZIP_DEFLATED)
+        for old_node, new_node, kind, change in repos.get_changes(**diff):
+            if kind == Node.FILE and change != Changeset.DELETE:
+                assert new_node
+                zipinfo = ZipInfo()
+                zipinfo.filename = new_node.path
+                zipinfo.date_time = time.gmtime(new_node.last_modified)[:6]
+                zipinfo.compress_type = ZIP_DEFLATED
+                zipfile.writestr(zipinfo, new_node.get_content().read())
+        zipfile.close()
+
+        buf.seek(0, 2) # be sure to be at the end
+        req.send_header("Content-Length", buf.tell())
+        req.end_headers()
+        
+        req.write(buf.getvalue())
+
+    def title_for_diff(self, diff):
+        if diff.new_path == diff.old_path: # ''diff between 2 revisions'' mode
+            return 'Diff r%s:%s for %s' \
+                   % (diff.old_rev or 'latest', diff.new_rev or 'latest',
+                      diff.new_path or '/')
+        else:                              # ''arbitrary diff'' mode
+            return 'Diff from %s@%s to %s@%s' \
+                   % (diff.old_path or '/', diff.old_rev or 'latest',
+                      diff.new_path or '/', diff.new_rev or 'latest')
+
+    # ITimelineEventProvider methods
+
+    def get_timeline_filters(self, req):
+        if req.perm.has_permission('CHANGESET_VIEW'):
+            yield ('changeset', 'Repository checkins')
+
+    def get_timeline_events(self, req, start, stop, filters):
+        if 'changeset' in filters:
+            format = req.args.get('format')
+            show_files = int(self.config.get('timeline',
+                                             'changeset_show_files'))
+            db = self.env.get_db_cnx()
+            repos = self.env.get_repository(req.authname)
+            for chgset in repos.get_changesets(start, stop):
+                message = chgset.message or '--'
+                shortlog = wiki_to_oneliner(message, self.env, db, shorten=True)
+                if format == 'rss':
+                    title = util.Markup('Changeset [%s]: %s',
+                                        chgset.rev, shortlog)
+                    href = self.env.abs_href.changeset(chgset.rev)
+                    message = wiki_to_html(message, self.env, req, db,
+                                           absurls=True)
+                else:
+                    title = util.Markup('Changeset <em>[%s]</em> by %s',
+                                        chgset.rev, chgset.author)
+                    href = self.env.href.changeset(chgset.rev)
+                    message = wiki_to_oneliner(message, self.env, db,
+                                               shorten=True)
+                if show_files:
+                    files = []
+                    for chg in chgset.get_changes():
+                        if show_files > 0 and len(files) >= show_files:
+                            files.append('&hellip; <br />')
+                            break
+                        files.append(util.Markup('<span class="%s">%s</span>'
+                                                 '<br />',
+                                                 chg[2], chg[0] or '/'))
+                    message = util.Markup('<span class="changes">%s</span> %s',
+                                          util.Markup(''.join(files)), message)
+                yield 'changeset', href, title, chgset.date, chgset.author,\
+                      message
+
+    # IWikiSyntaxProvider methods
+
+    def get_wiki_syntax(self):
+        yield (
+            # [...] form: start with optional intertrac: [T... or [trac ... 
+            r"!?\[(?P<it_changeset>%s\s*)?" % Formatter.INTERTRAC_SCHEME +
+            #  digits + optional path for the restricted changeset
+            r"\d+(?:/[^\]]*)?\]|"   
+            # r... form: allow r1 but not r1:2 (handled by the log syntax)
+            r"(?:\b|!)r\d+\b(?!:\d)",
+            lambda x, y, z:
+            self._format_changeset_link(x, 'changeset',
+                                        y[0] == 'r' and y[1:] or y[1:-1],
+                                        y, z))
+
+    def get_link_resolvers(self):
+        yield ('changeset', self._format_changeset_link)
+        yield ('diff', self._format_diff_link)
+
+    def _format_changeset_link(self, formatter, ns, chgset, label,
+                               fullmatch=None):
+        intertrac = formatter.shorthand_intertrac_helper(ns, chgset, label,
+                                                         fullmatch)
+        if intertrac:
+            return intertrac
+        sep = chgset.find('/')
+        if sep > 0:
+            rev, path = chgset[:sep], chgset[sep:]
+        else:
+            rev, path = chgset, None
+        cursor = formatter.db.cursor()
+        cursor.execute('SELECT message FROM revision WHERE rev=%s', (rev,))
+        row = cursor.fetchone()
+        if row:
+            return '<a class="changeset" title="%s" href="%s">%s</a>' \
+                   % (util.escape(util.shorten_line(row[0])),
+                      formatter.href.changeset(rev, path), label)
+        else:
+            return '<a class="missing changeset" href="%s"' \
+                   ' rel="nofollow">%s</a>' \
+                   % (formatter.href.changeset(rev, path), label)
+
+    def _format_diff_link(self, formatter, ns, params, label):
+        def pathrev(path):
+            if '@' in path:
+                return path.split('@', 1)
+            else:
+                return (path, None)
+        if '//' in params:
+            p1, p2 = params.split('//', 1)
+            old, new = pathrev(p1), pathrev(p2)
+            diff = DiffArgs(old_path=old[0], old_rev=old[1],
+                            new_path=new[0], new_rev=new[1])
+        else: 
+            old_path, old_rev = pathrev(params)
+            new_rev = None
+            if old_rev and ':' in old_rev:
+                old_rev, new_rev = old_rev.split(':', 1)
+            diff = DiffArgs(old_path=old_path, old_rev=old_rev,
+                            new_path=old_path, new_rev=new_rev)
+        title = self.title_for_diff(diff)
+        href = formatter.href.changeset(new_path=diff.new_path or None,
+                                        new=diff.new_rev, 
+                                        old_path=diff.old_path or None,
+                                        old=diff.old_rev)
+        return '<a class="changeset" title="%s" href="%s">%s</a>' \
+               % (title, href, label)
+    
+    # ISearchSource methods
+
+    def get_search_filters(self, req):
+        if req.perm.has_permission('CHANGESET_VIEW'):
+            yield ('changeset', 'Changesets')
+
+    def get_search_results(self, req, terms, filters):
+        if not 'changeset' in filters:
+            return
+        authzperm = SubversionAuthorizer(self.env, req.authname)
+        db = self.env.get_db_cnx()
+        sql, args = search_to_sql(db, ['message', 'author'], terms)
+        cursor = db.cursor()
+        cursor.execute("SELECT rev,time,author,message "
+                       "FROM revision WHERE " + sql, args)
+        for rev, date, author, log in cursor:
+            if not authzperm.has_permission_for_changeset(rev):
+                continue
+            yield (self.env.href.changeset(rev),
+                   '[%s]: %s' % (rev, util.shorten_line(log)),
+                   date, author, shorten_result(log, terms))
+
+
+class AnyDiffModule(Component):
+
+    implements(IRequestHandler)
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        return re.match(r'/anydiff$', req.path_info)
+
+    def process_request(self, req):
+        # -- retrieve arguments
+        new_path = req.args.get('new_path')
+        new_rev = req.args.get('new_rev')
+        old_path = req.args.get('old_path')
+        old_rev = req.args.get('old_rev')
+
+        # -- normalize 
+        repos = self.env.get_repository(req.authname)
+        new_path = repos.normalize_path(new_path)
+        new_rev = repos.normalize_rev(new_rev)
+        old_path = repos.normalize_path(old_path)
+        old_rev = repos.normalize_rev(old_rev)
+
+        authzperm = SubversionAuthorizer(self.env, req.authname)
+        authzperm.assert_permission_for_changeset(new_rev)
+        authzperm.assert_permission_for_changeset(old_rev)
+        
+        # -- prepare rendering
+        req.hdf['anydiff'] = {
+            'new_path': new_path,
+            'new_rev': new_rev,
+            'old_path': old_path,
+            'old_rev': old_rev,
+            'changeset_href': self.env.href.changeset(),
+            }
+
+        return 'anydiff.cs', None
diff -urN trac-trunk/build/lib/trac/versioncontrol/web_ui/log.py aw-trac/build/lib/trac/versioncontrol/web_ui/log.py
--- trac-trunk/build/lib/trac/versioncontrol/web_ui/log.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/web_ui/log.py	2006-03-08 03:01:51.000000000 -0800
@@ -0,0 +1,228 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christian Boos <cboos@neuf.fr>
+
+import re
+import urllib
+
+from trac import util
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.web import IRequestHandler
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.wiki import IWikiSyntaxProvider
+from trac.versioncontrol import Changeset
+from trac.versioncontrol.web_ui.util import *
+
+LOG_LIMIT = 100
+
+class LogModule(Component):
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
+               IWikiSyntaxProvider)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'browser'
+
+    def get_navigation_items(self, req):
+        return []
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        return ['LOG_VIEW']
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        import re
+        match = re.match(r'/log(?:(/.*)|$)', req.path_info)
+        if match:
+            req.args['path'] = match.group(1) or '/'
+            return 1
+
+    def process_request(self, req):
+        req.perm.assert_permission('LOG_VIEW')
+
+        mode = req.args.get('mode', 'stop_on_copy')
+        path = req.args.get('path', '/')
+        rev = req.args.get('rev')
+        stop_rev = req.args.get('stop_rev')
+        format = req.args.get('format')
+        verbose = req.args.get('verbose')
+        limit = LOG_LIMIT
+
+        repos = self.env.get_repository(req.authname)
+        normpath = repos.normalize_path(path)
+        rev = str(repos.normalize_rev(rev))
+        if stop_rev:
+            stop_rev = str(repos.normalize_rev(stop_rev))
+            if repos.rev_older_than(rev, stop_rev):
+                rev, stop_rev = stop_rev, rev
+            
+        req.hdf['title'] = path + ' (log)'
+        req.hdf['log'] = {
+            'mode': mode,
+            'path': path,
+            'rev': rev,
+            'verbose': verbose,
+            'stop_rev': stop_rev,
+            'browser_href': self.env.href.browser(path),
+            'changeset_href': self.env.href.changeset(),
+            'log_href': self.env.href.log(path, rev=rev)
+        }
+
+        path_links = get_path_links(self.env.href, path, rev)
+        req.hdf['log.path'] = path_links
+        if path_links:
+            add_link(req, 'up', path_links[-1]['href'], 'Parent directory')
+
+        # The `history()` method depends on the mode:
+        #  * for ''stop on copy'' and ''follow copies'', it's `Node.history()` 
+        #  * for ''show only add, delete'' it's`Repository.get_path_history()` 
+        if mode == 'path_history':
+            def history(limit):
+                for h in repos.get_path_history(path, rev, limit):
+                    yield h
+        else:
+            history = get_existing_node(self.env, repos, path, rev).get_history
+
+        # -- retrieve history, asking for limit+1 results
+        info = []
+        previous_path = repos.normalize_path(path)
+        for old_path, old_rev, old_chg in history(limit+1):
+            if stop_rev and repos.rev_older_than(old_rev, stop_rev):
+                break
+            old_path = repos.normalize_path(old_path)
+            item = {
+                'rev': str(old_rev),
+                'path': str(old_path),
+                'log_href': self.env.href.log(old_path, rev=old_rev),
+                'browser_href': self.env.href.browser(old_path, rev=old_rev),
+                'changeset_href': self.env.href.changeset(old_rev),
+                'restricted_href': self.env.href.changeset(old_rev,
+                                                           new_path=old_path),
+                'change': old_chg
+            }
+            if not (mode == 'path_history' and old_chg == Changeset.EDIT):
+                info.append(item)
+            if old_path and old_path != previous_path \
+               and not (mode == 'path_history' and old_path == normpath):
+                item['copyfrom_path'] = old_path
+                if mode == 'stop_on_copy':
+                    break
+            if len(info) > limit: # we want limit+1 entries
+                break
+            previous_path = old_path
+        if info == []:
+            # FIXME: we should send a 404 error here
+            raise TracError("The file or directory '%s' doesn't exist "
+                            "at revision %s or at any previous revision."
+                            % (path, rev), 'Nonexistent path')
+
+        def make_log_href(path, **args):
+            link_rev = rev
+            if rev == str(repos.youngest_rev):
+                link_rev = None
+            params = {'rev': link_rev, 'mode': mode, 'limit': limit}
+            params.update(args)
+            if verbose:
+                params['verbose'] = verbose
+            return self.env.href.log(path, **params)
+
+        if len(info) == limit+1: # limit+1 reached, there _might_ be some more
+            next_rev = info[-1]['rev']
+            next_path = info[-1]['path']
+            add_link(req, 'next', make_log_href(next_path, rev=next_rev),
+                     'Revision Log (restarting at %s, rev. %s)'
+                     % (next_path, next_rev))
+            # now, only show 'limit' results
+            del info[-1]
+        
+        req.hdf['log.items'] = info
+
+        revs = [i['rev'] for i in info]
+        changes = get_changes(self.env, repos, revs, verbose, req, format)
+        if format == 'rss':
+            # Get the email addresses of all known users
+            email_map = {}
+            for username,name,email in self.env.get_known_users():
+                if email:
+                    email_map[username] = email
+            for cs in changes.values():
+                # For RSS, author must be an email address
+                author = cs['author']
+                author_email = ''
+                if '@' in author:
+                    author_email = author
+                elif email_map.has_key(author):
+                    author_email = email_map[author]
+                cs['author'] = author_email
+                cs['date'] = util.http_date(cs['date_seconds'])
+        elif format == 'changelog':
+            for rev in revs:
+                changeset = repos.get_changeset(rev)
+                cs = changes[rev]
+                cs['message'] = '\n'.join(['\t' + m for m in
+                                           changeset.message.split('\n')])
+                files = []
+                actions = []
+                for path, kind, chg, bpath, brev in changeset.get_changes():
+                    files.append(chg == Changeset.DELETE and bpath or path)
+                    actions.append(chg)
+                cs['files'] = files
+                cs['actions'] = actions
+        req.hdf['log.changes'] = changes
+
+        if req.args.get('format') == 'changelog':
+            return 'log_changelog.cs', 'text/plain'
+        elif req.args.get('format') == 'rss':
+            return 'log_rss.cs', 'application/rss+xml'
+
+        add_stylesheet(req, 'common/css/browser.css')
+        add_stylesheet(req, 'common/css/diff.css')
+
+        rss_href = make_log_href(path, format='rss', stop_rev=stop_rev)
+        add_link(req, 'alternate', rss_href, 'RSS Feed', 'application/rss+xml',
+                 'rss')
+        changelog_href = make_log_href(path, format='changelog',
+                                       stop_rev=stop_rev)
+        add_link(req, 'alternate', changelog_href, 'ChangeLog', 'text/plain')
+
+        return 'log.cs', None
+
+    # IWikiSyntaxProvider methods
+    
+    def get_wiki_syntax(self):
+        yield (r"!?\[\d+:\d+\]|(?:\b|!)r\d+:\d+\b",
+               lambda x, y, z: self._format_link(x, 'log',
+                                                 '#'+(y[0] == 'r' and y[1:]
+                                                      or y[1:-1]), y))
+
+    def get_link_resolvers(self):
+        yield ('log', self._format_link)
+
+    def _format_link(self, formatter, ns, path, label):
+        path, rev, line = get_path_rev_line(path)
+        stop_rev = None
+        if rev and ':' in rev:
+            stop_rev, rev = rev.split(':', 1)
+        label = urllib.unquote(label)
+        return '<a class="source" href="%s">%s</a>' \
+               % (formatter.href.log(path, rev=rev, stop_rev=stop_rev), label)
diff -urN trac-trunk/build/lib/trac/versioncontrol/web_ui/util.py aw-trac/build/lib/trac/versioncontrol/web_ui/util.py
--- trac-trunk/build/lib/trac/versioncontrol/web_ui/util.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/versioncontrol/web_ui/util.py	2006-03-08 02:58:43.000000000 -0800
@@ -0,0 +1,91 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christian Boos <cboos@neuf.fr>
+
+import re
+import urllib
+
+from trac.util import escape, format_datetime, pretty_timedelta, shorten_line, \
+                      TracError, Markup, rss_title
+from trac.wiki import wiki_to_html, wiki_to_oneliner
+
+__all__ = ['get_changes', 'get_path_links', 'get_path_rev_line',
+           'get_existing_node']
+
+def get_changes(env, repos, revs, full=None, req=None, format=None):
+    db = env.get_db_cnx()
+    changes = {}
+    for rev in revs:
+        changeset = repos.get_changeset(rev)
+        message = changeset.message or '--'
+        shortlog = wiki_to_oneliner(message, env, db, shorten=True)
+        if full:
+            message = wiki_to_html(message, env, req, db,
+                                   absurls=(format == 'rss'),
+                                   escape_newlines=True)
+        else:
+            message = shortlog
+        if format == 'rss':
+            shortlog = rss_title(shortlog)
+            message = str(message)
+        changes[rev] = {
+            'date_seconds': changeset.date,
+            'date': format_datetime(changeset.date),
+            'age': pretty_timedelta(changeset.date),
+            'author': changeset.author or 'anonymous',
+            'message': message,
+            'shortlog': shortlog,
+        }
+    return changes
+
+def get_path_links(href, path, rev):
+    links = []
+    parts = path.split('/')
+    if not parts[-1]:
+        parts.pop()
+    path = '/'
+    for part in parts:
+        path = path + part + '/'
+        links.append({
+            'name': part or 'root',
+            'href': href.browser(path, rev=rev)
+        })
+    return links
+
+rev_re = re.compile(r"([^@#]*)[@#]([^#]+)(?:#L(\d+))?")
+
+def get_path_rev_line(path):
+    rev = None
+    line = None
+    match = rev_re.search(path)
+    if match:
+        path = match.group(1)
+        rev = match.group(2)
+        if match.group(3):
+            line = int(match.group(3))
+    path = urllib.unquote(path)
+    return path, rev, line
+
+def get_existing_node(env, repos, path, rev):
+    try: 
+        return repos.get_node(path, rev) 
+    except TracError, e: 
+        raise TracError(Markup('%s<br><p>You can <a href="%s">search</a> ' 
+                               'in the repository history to see if that path '
+                               'existed but was later removed.</p>', e.message,
+                               env.href.log(path, rev=rev,
+                                            mode='path_history')))
diff -urN trac-trunk/build/lib/trac/web/__init__.py aw-trac/build/lib/trac/web/__init__.py
--- trac-trunk/build/lib/trac/web/__init__.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/__init__.py	2005-08-17 07:47:18.000000000 -0700
@@ -0,0 +1 @@
+from trac.web.api import *
\ No newline at end of file
diff -urN trac-trunk/build/lib/trac/web/_fcgi.py aw-trac/build/lib/trac/web/_fcgi.py
--- trac-trunk/build/lib/trac/web/_fcgi.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/_fcgi.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,1306 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (c) 2002, 2003, 2005 Allan Saddi <allan@saddi.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Allan Saddi <allan@saddi.com>
+
+"""
+fcgi - a FastCGI/WSGI gateway.
+
+For more information about FastCGI, see <http://www.fastcgi.com/>.
+
+For more information about the Web Server Gateway Interface, see
+<http://www.python.org/peps/pep-0333.html>.
+
+Example usage:
+
+  #!/usr/bin/env python
+  from myapplication import app # Assume app is your WSGI application object
+  from fcgi import WSGIServer
+  WSGIServer(app).run()
+
+See the documentation for WSGIServer/Server for more information.
+
+On most platforms, fcgi will fallback to regular CGI behavior if run in a
+non-FastCGI context. If you want to force CGI behavior, set the environment
+variable FCGI_FORCE_CGI to "Y" or "y".
+"""
+
+__author__ = 'Allan Saddi <allan@saddi.com>'
+__version__ = '$Revision: 1797 $'
+
+import sys
+import os
+import signal
+import struct
+import cStringIO as StringIO
+import select
+import socket
+import errno
+import traceback
+
+try:
+    import thread
+    import threading
+    thread_available = True
+except ImportError:
+    import dummy_thread as thread
+    import dummy_threading as threading
+    thread_available = False
+
+__all__ = ['WSGIServer']
+
+# Constants from the spec.
+FCGI_LISTENSOCK_FILENO = 0
+
+FCGI_HEADER_LEN = 8
+
+FCGI_VERSION_1 = 1
+
+FCGI_BEGIN_REQUEST = 1
+FCGI_ABORT_REQUEST = 2
+FCGI_END_REQUEST = 3
+FCGI_PARAMS = 4
+FCGI_STDIN = 5
+FCGI_STDOUT = 6
+FCGI_STDERR = 7
+FCGI_DATA = 8
+FCGI_GET_VALUES = 9
+FCGI_GET_VALUES_RESULT = 10
+FCGI_UNKNOWN_TYPE = 11
+FCGI_MAXTYPE = FCGI_UNKNOWN_TYPE
+
+FCGI_NULL_REQUEST_ID = 0
+
+FCGI_KEEP_CONN = 1
+
+FCGI_RESPONDER = 1
+FCGI_AUTHORIZER = 2
+FCGI_FILTER = 3
+
+FCGI_REQUEST_COMPLETE = 0
+FCGI_CANT_MPX_CONN = 1
+FCGI_OVERLOADED = 2
+FCGI_UNKNOWN_ROLE = 3
+
+FCGI_MAX_CONNS = 'FCGI_MAX_CONNS'
+FCGI_MAX_REQS = 'FCGI_MAX_REQS'
+FCGI_MPXS_CONNS = 'FCGI_MPXS_CONNS'
+
+FCGI_Header = '!BBHHBx'
+FCGI_BeginRequestBody = '!HB5x'
+FCGI_EndRequestBody = '!LB3x'
+FCGI_UnknownTypeBody = '!B7x'
+
+FCGI_EndRequestBody_LEN = struct.calcsize(FCGI_EndRequestBody)
+FCGI_UnknownTypeBody_LEN = struct.calcsize(FCGI_UnknownTypeBody)
+
+if __debug__:
+    import time
+
+    # Set non-zero to write debug output to a file.
+    DEBUG = 0
+    DEBUGLOG = '/tmp/fcgi.log'
+
+    def _debug(level, msg):
+        if DEBUG < level:
+            return
+
+        try:
+            f = open(DEBUGLOG, 'a')
+            f.write('%sfcgi: %s\n' % (time.ctime()[4:-4], msg))
+            f.close()
+        except:
+            pass
+
+class InputStream(object):
+    """
+    File-like object representing FastCGI input streams (FCGI_STDIN and
+    FCGI_DATA). Supports the minimum methods required by WSGI spec.
+    """
+    def __init__(self, conn):
+        self._conn = conn
+
+        # See Server.
+        self._shrinkThreshold = conn.server.inputStreamShrinkThreshold
+
+        self._buf = ''
+        self._bufList = []
+        self._pos = 0 # Current read position.
+        self._avail = 0 # Number of bytes currently available.
+
+        self._eof = False # True when server has sent EOF notification.
+
+    def _shrinkBuffer(self):
+        """Gets rid of already read data (since we can't rewind)."""
+        if self._pos >= self._shrinkThreshold:
+            self._buf = self._buf[self._pos:]
+            self._avail -= self._pos
+            self._pos = 0
+
+            assert self._avail >= 0
+
+    def _waitForData(self):
+        """Waits for more data to become available."""
+        self._conn.process_input()
+
+    def read(self, n=-1):
+        if self._pos == self._avail and self._eof:
+            return ''
+        while True:
+            if n < 0 or (self._avail - self._pos) < n:
+                # Not enough data available.
+                if self._eof:
+                    # And there's no more coming.
+                    newPos = self._avail
+                    break
+                else:
+                    # Wait for more data.
+                    self._waitForData()
+                    continue
+            else:
+                newPos = self._pos + n
+                break
+        # Merge buffer list, if necessary.
+        if self._bufList:
+            self._buf += ''.join(self._bufList)
+            self._bufList = []
+        r = self._buf[self._pos:newPos]
+        self._pos = newPos
+        self._shrinkBuffer()
+        return r
+
+    def readline(self, length=None):
+        if self._pos == self._avail and self._eof:
+            return ''
+        while True:
+            # Unfortunately, we need to merge the buffer list early.
+            if self._bufList:
+                self._buf += ''.join(self._bufList)
+                self._bufList = []
+            # Find newline.
+            i = self._buf.find('\n', self._pos)
+            if i < 0:
+                # Not found?
+                if self._eof:
+                    # No more data coming.
+                    newPos = self._avail
+                    break
+                else:
+                    # Wait for more to come.
+                    self._waitForData()
+                    continue
+            else:
+                newPos = i + 1
+                break
+        if length is not None:
+            if self._pos + length < newPos:
+                newPos = self._pos + length
+        r = self._buf[self._pos:newPos]
+        self._pos = newPos
+        self._shrinkBuffer()
+        return r
+
+    def readlines(self, sizehint=0):
+        total = 0
+        lines = []
+        line = self.readline()
+        while line:
+            lines.append(line)
+            total += len(line)
+            if 0 < sizehint <= total:
+                break
+            line = self.readline()
+        return lines
+
+    def __iter__(self):
+        return self
+
+    def next(self):
+        r = self.readline()
+        if not r:
+            raise StopIteration
+        return r
+
+    def add_data(self, data):
+        if not data:
+            self._eof = True
+        else:
+            self._bufList.append(data)
+            self._avail += len(data)
+
+class MultiplexedInputStream(InputStream):
+    """
+    A version of InputStream meant to be used with MultiplexedConnections.
+    Assumes the MultiplexedConnection (the producer) and the Request
+    (the consumer) are running in different threads.
+    """
+    def __init__(self, conn):
+        super(MultiplexedInputStream, self).__init__(conn)
+
+        # Arbitrates access to this InputStream (it's used simultaneously
+        # by a Request and its owning Connection object).
+        lock = threading.RLock()
+
+        # Notifies Request thread that there is new data available.
+        self._lock = threading.Condition(lock)
+
+    def _waitForData(self):
+        # Wait for notification from add_data().
+        self._lock.wait()
+
+    def read(self, n=-1):
+        self._lock.acquire()
+        try:
+            return super(MultiplexedInputStream, self).read(n)
+        finally:
+            self._lock.release()
+
+    def readline(self, length=None):
+        self._lock.acquire()
+        try:
+            return super(MultiplexedInputStream, self).readline(length)
+        finally:
+            self._lock.release()
+
+    def add_data(self, data):
+        self._lock.acquire()
+        try:
+            super(MultiplexedInputStream, self).add_data(data)
+            self._lock.notify()
+        finally:
+            self._lock.release()
+
+class OutputStream(object):
+    """
+    FastCGI output stream (FCGI_STDOUT/FCGI_STDERR). By default, calls to
+    write() or writelines() immediately result in Records being sent back
+    to the server. Buffering should be done in a higher level!
+    """
+    def __init__(self, conn, req, type, buffered=False):
+        self._conn = conn
+        self._req = req
+        self._type = type
+        self._buffered = buffered
+        self._bufList = [] # Used if buffered is True
+        self.dataWritten = False
+        self.closed = False
+
+    def _write(self, data):
+        length = len(data)
+        while length:
+            toWrite = min(length, self._req.server.maxwrite - FCGI_HEADER_LEN)
+
+            rec = Record(self._type, self._req.requestId)
+            rec.contentLength = toWrite
+            rec.contentData = data[:toWrite]
+            self._conn.writeRecord(rec)
+
+            data = data[toWrite:]
+            length -= toWrite
+
+    def write(self, data):
+        assert not self.closed
+
+        if not data:
+            return
+
+        self.dataWritten = True
+
+        if self._buffered:
+            self._bufList.append(data)
+        else:
+            self._write(data)
+
+    def writelines(self, lines):
+        assert not self.closed
+
+        for line in lines:
+            self.write(line)
+
+    def flush(self):
+        # Only need to flush if this OutputStream is actually buffered.
+        if self._buffered:
+            data = ''.join(self._bufList)
+            self._bufList = []
+            self._write(data)
+
+    # Though available, the following should NOT be called by WSGI apps.
+    def close(self):
+        """Sends end-of-stream notification, if necessary."""
+        if not self.closed and self.dataWritten:
+            self.flush()
+            rec = Record(self._type, self._req.requestId)
+            self._conn.writeRecord(rec)
+            self.closed = True
+
+class TeeOutputStream(object):
+    """
+    Simple wrapper around two or more output file-like objects that copies
+    written data to all streams.
+    """
+    def __init__(self, streamList):
+        self._streamList = streamList
+
+    def write(self, data):
+        for f in self._streamList:
+            f.write(data)
+
+    def writelines(self, lines):
+        for line in lines:
+            self.write(line)
+
+    def flush(self):
+        for f in self._streamList:
+            f.flush()
+
+class StdoutWrapper(object):
+    """
+    Wrapper for sys.stdout so we know if data has actually been written.
+    """
+    def __init__(self, stdout):
+        self._file = stdout
+        self.dataWritten = False
+
+    def write(self, data):
+        if data:
+            self.dataWritten = True
+        self._file.write(data)
+
+    def writelines(self, lines):
+        for line in lines:
+            self.write(line)
+
+    def __getattr__(self, name):
+        return getattr(self._file, name)
+
+def decode_pair(s, pos=0):
+    """
+    Decodes a name/value pair.
+
+    The number of bytes decoded as well as the name/value pair
+    are returned.
+    """
+    nameLength = ord(s[pos])
+    if nameLength & 128:
+        nameLength = struct.unpack('!L', s[pos:pos+4])[0] & 0x7fffffff
+        pos += 4
+    else:
+        pos += 1
+
+    valueLength = ord(s[pos])
+    if valueLength & 128:
+        valueLength = struct.unpack('!L', s[pos:pos+4])[0] & 0x7fffffff
+        pos += 4
+    else:
+        pos += 1
+
+    name = s[pos:pos+nameLength]
+    pos += nameLength
+    value = s[pos:pos+valueLength]
+    pos += valueLength
+
+    return (pos, (name, value))
+
+def encode_pair(name, value):
+    """
+    Encodes a name/value pair.
+
+    The encoded string is returned.
+    """
+    nameLength = len(name)
+    if nameLength < 128:
+        s = chr(nameLength)
+    else:
+        s = struct.pack('!L', nameLength | 0x80000000L)
+
+    valueLength = len(value)
+    if valueLength < 128:
+        s += chr(valueLength)
+    else:
+        s += struct.pack('!L', valueLength | 0x80000000L)
+
+    return s + name + value
+    
+class Record(object):
+    """
+    A FastCGI Record.
+
+    Used for encoding/decoding records.
+    """
+    def __init__(self, type=FCGI_UNKNOWN_TYPE, requestId=FCGI_NULL_REQUEST_ID):
+        self.version = FCGI_VERSION_1
+        self.type = type
+        self.requestId = requestId
+        self.contentLength = 0
+        self.paddingLength = 0
+        self.contentData = ''
+
+    def _recvall(sock, length):
+        """
+        Attempts to receive length bytes from a socket, blocking if necessary.
+        (Socket may be blocking or non-blocking.)
+        """
+        dataList = []
+        recvLen = 0
+        while length:
+            try:
+                data = sock.recv(length)
+            except socket.error, e:
+                if e[0] == errno.EAGAIN:
+                    select.select([sock], [], [])
+                    continue
+                else:
+                    raise
+            if not data: # EOF
+                break
+            dataList.append(data)
+            dataLen = len(data)
+            recvLen += dataLen
+            length -= dataLen
+        return ''.join(dataList), recvLen
+    _recvall = staticmethod(_recvall)
+
+    def read(self, sock):
+        """Read and decode a Record from a socket."""
+        try:
+            header, length = self._recvall(sock, FCGI_HEADER_LEN)
+        except:
+            raise EOFError
+
+        if length < FCGI_HEADER_LEN:
+            raise EOFError
+        
+        self.version, self.type, self.requestId, self.contentLength, \
+                      self.paddingLength = struct.unpack(FCGI_Header, header)
+
+        if __debug__: _debug(9, 'read: fd = %d, type = %d, requestId = %d, '
+                             'contentLength = %d' %
+                             (sock.fileno(), self.type, self.requestId,
+                              self.contentLength))
+        
+        if self.contentLength:
+            try:
+                self.contentData, length = self._recvall(sock,
+                                                         self.contentLength)
+            except:
+                raise EOFError
+
+            if length < self.contentLength:
+                raise EOFError
+
+        if self.paddingLength:
+            try:
+                self._recvall(sock, self.paddingLength)
+            except:
+                raise EOFError
+
+    def _sendall(sock, data):
+        """
+        Writes data to a socket and does not return until all the data is sent.
+        """
+        length = len(data)
+        while length:
+            try:
+                sent = sock.send(data)
+            except socket.error, e:
+                if e[0] == errno.EPIPE:
+                    return # Don't bother raising an exception. Just ignore.
+                elif e[0] == errno.EAGAIN:
+                    select.select([], [sock], [])
+                    continue
+                else:
+                    raise
+            data = data[sent:]
+            length -= sent
+    _sendall = staticmethod(_sendall)
+
+    def write(self, sock):
+        """Encode and write a Record to a socket."""
+        self.paddingLength = -self.contentLength & 7
+
+        if __debug__: _debug(9, 'write: fd = %d, type = %d, requestId = %d, '
+                             'contentLength = %d' %
+                             (sock.fileno(), self.type, self.requestId,
+                              self.contentLength))
+
+        header = struct.pack(FCGI_Header, self.version, self.type,
+                             self.requestId, self.contentLength,
+                             self.paddingLength)
+        self._sendall(sock, header)
+        if self.contentLength:
+            self._sendall(sock, self.contentData)
+        if self.paddingLength:
+            self._sendall(sock, '\x00'*self.paddingLength)
+            
+class Request(object):
+    """
+    Represents a single FastCGI request.
+
+    These objects are passed to your handler and is the main interface
+    between your handler and the fcgi module. The methods should not
+    be called by your handler. However, server, params, stdin, stdout,
+    stderr, and data are free for your handler's use.
+    """
+    def __init__(self, conn, inputStreamClass):
+        self._conn = conn
+
+        self.server = conn.server
+        self.params = {}
+        self.stdin = inputStreamClass(conn)
+        self.stdout = OutputStream(conn, self, FCGI_STDOUT)
+        self.stderr = OutputStream(conn, self, FCGI_STDERR, buffered=True)
+        self.data = inputStreamClass(conn)
+
+    def run(self):
+        """Runs the handler, flushes the streams, and ends the request."""
+        try:
+            protocolStatus, appStatus = self.server.handler(self)
+        except:
+            traceback.print_exc(file=self.stderr)
+            self.stderr.flush()
+            if not self.stdout.dataWritten:
+                self.server.error(self)
+
+            protocolStatus, appStatus = FCGI_REQUEST_COMPLETE, 0
+
+        if __debug__: _debug(1, 'protocolStatus = %d, appStatus = %d' %
+                             (protocolStatus, appStatus))
+
+        self._flush()
+        self._end(appStatus, protocolStatus)
+
+    def _end(self, appStatus=0L, protocolStatus=FCGI_REQUEST_COMPLETE):
+        self._conn.end_request(self, appStatus, protocolStatus)
+        
+    def _flush(self):
+        self.stdout.close()
+        self.stderr.close()
+
+class CGIRequest(Request):
+    """A normal CGI request disguised as a FastCGI request."""
+    def __init__(self, server):
+        # These are normally filled in by Connection.
+        self.requestId = 1
+        self.role = FCGI_RESPONDER
+        self.flags = 0
+        self.aborted = False
+        
+        self.server = server
+        self.params = dict(os.environ)
+        self.stdin = sys.stdin
+        self.stdout = StdoutWrapper(sys.stdout) # Oh, the humanity!
+        self.stderr = sys.stderr
+        self.data = StringIO.StringIO()
+        
+    def _end(self, appStatus=0L, protocolStatus=FCGI_REQUEST_COMPLETE):
+        sys.exit(appStatus)
+
+    def _flush(self):
+        # Not buffered, do nothing.
+        pass
+
+class Connection(object):
+    """
+    A Connection with the web server.
+
+    Each Connection is associated with a single socket (which is
+    connected to the web server) and is responsible for handling all
+    the FastCGI message processing for that socket.
+    """
+    _multiplexed = False
+    _inputStreamClass = InputStream
+
+    def __init__(self, sock, addr, server):
+        self._sock = sock
+        self._addr = addr
+        self.server = server
+
+        # Active Requests for this Connection, mapped by request ID.
+        self._requests = {}
+
+    def _cleanupSocket(self):
+        """Close the Connection's socket."""
+        try:
+            self._sock.shutdown(socket.SHUT_WR)
+        except:
+            return
+        try:
+            while True:
+                r, w, e = select.select([self._sock], [], [])
+                if not r or not self._sock.recv(1024):
+                    break
+        except:
+            pass
+        self._sock.close()
+        
+    def run(self):
+        """Begin processing data from the socket."""
+        self._keepGoing = True
+        while self._keepGoing:
+            try:
+                self.process_input()
+            except EOFError:
+                break
+            except (select.error, socket.error), e:
+                if e[0] == errno.EBADF: # Socket was closed by Request.
+                    break
+                raise
+
+        self._cleanupSocket()
+
+    def process_input(self):
+        """Attempt to read a single Record from the socket and process it."""
+        # Currently, any children Request threads notify this Connection
+        # that it is no longer needed by closing the Connection's socket.
+        # We need to put a timeout on select, otherwise we might get
+        # stuck in it indefinitely... (I don't like this solution.)
+        while self._keepGoing:
+            try:
+                r, w, e = select.select([self._sock], [], [], 1.0)
+            except ValueError:
+                # Sigh. ValueError gets thrown sometimes when passing select
+                # a closed socket.
+                raise EOFError
+            if r: break
+        if not self._keepGoing:
+            return
+        rec = Record()
+        rec.read(self._sock)
+
+        if rec.type == FCGI_GET_VALUES:
+            self._do_get_values(rec)
+        elif rec.type == FCGI_BEGIN_REQUEST:
+            self._do_begin_request(rec)
+        elif rec.type == FCGI_ABORT_REQUEST:
+            self._do_abort_request(rec)
+        elif rec.type == FCGI_PARAMS:
+            self._do_params(rec)
+        elif rec.type == FCGI_STDIN:
+            self._do_stdin(rec)
+        elif rec.type == FCGI_DATA:
+            self._do_data(rec)
+        elif rec.requestId == FCGI_NULL_REQUEST_ID:
+            self._do_unknown_type(rec)
+        else:
+            # Need to complain about this.
+            pass
+
+    def writeRecord(self, rec):
+        """
+        Write a Record to the socket.
+        """
+        rec.write(self._sock)
+
+    def end_request(self, req, appStatus=0L,
+                    protocolStatus=FCGI_REQUEST_COMPLETE, remove=True):
+        """
+        End a Request.
+
+        Called by Request objects. An FCGI_END_REQUEST Record is
+        sent to the web server. If the web server no longer requires
+        the connection, the socket is closed, thereby ending this
+        Connection (run() returns).
+        """
+        rec = Record(FCGI_END_REQUEST, req.requestId)
+        rec.contentData = struct.pack(FCGI_EndRequestBody, appStatus,
+                                      protocolStatus)
+        rec.contentLength = FCGI_EndRequestBody_LEN
+        self.writeRecord(rec)
+
+        if remove:
+            del self._requests[req.requestId]
+
+        if __debug__: _debug(2, 'end_request: flags = %d' % req.flags)
+
+        if not (req.flags & FCGI_KEEP_CONN) and not self._requests:
+            self._cleanupSocket()
+            self._keepGoing = False
+
+    def _do_get_values(self, inrec):
+        """Handle an FCGI_GET_VALUES request from the web server."""
+        outrec = Record(FCGI_GET_VALUES_RESULT)
+
+        pos = 0
+        while pos < inrec.contentLength:
+            pos, (name, value) = decode_pair(inrec.contentData, pos)
+            cap = self.server.capability.get(name)
+            if cap is not None:
+                outrec.contentData += encode_pair(name, str(cap))
+
+        outrec.contentLength = len(outrec.contentData)
+        self.writeRecord(rec)
+
+    def _do_begin_request(self, inrec):
+        """Handle an FCGI_BEGIN_REQUEST from the web server."""
+        role, flags = struct.unpack(FCGI_BeginRequestBody, inrec.contentData)
+
+        req = self.server.request_class(self, self._inputStreamClass)
+        req.requestId, req.role, req.flags = inrec.requestId, role, flags
+        req.aborted = False
+
+        if not self._multiplexed and self._requests:
+            # Can't multiplex requests.
+            self.end_request(req, 0L, FCGI_CANT_MPX_CONN, remove=False)
+        else:
+            self._requests[inrec.requestId] = req
+
+    def _do_abort_request(self, inrec):
+        """
+        Handle an FCGI_ABORT_REQUEST from the web server.
+
+        We just mark a flag in the associated Request.
+        """
+        req = self._requests.get(inrec.requestId)
+        if req is not None:
+            req.aborted = True
+
+    def _start_request(self, req):
+        """Run the request."""
+        # Not multiplexed, so run it inline.
+        req.run()
+
+    def _do_params(self, inrec):
+        """
+        Handle an FCGI_PARAMS Record.
+
+        If the last FCGI_PARAMS Record is received, start the request.
+        """
+        req = self._requests.get(inrec.requestId)
+        if req is not None:
+            if inrec.contentLength:
+                pos = 0
+                while pos < inrec.contentLength:
+                    pos, (name, value) = decode_pair(inrec.contentData, pos)
+                    req.params[name] = value
+            else:
+                self._start_request(req)
+
+    def _do_stdin(self, inrec):
+        """Handle the FCGI_STDIN stream."""
+        req = self._requests.get(inrec.requestId)
+        if req is not None:
+            req.stdin.add_data(inrec.contentData)
+
+    def _do_data(self, inrec):
+        """Handle the FCGI_DATA stream."""
+        req = self._requests.get(inrec.requestId)
+        if req is not None:
+            req.data.add_data(inrec.contentData)
+
+    def _do_unknown_type(self, inrec):
+        """Handle an unknown request type. Respond accordingly."""
+        outrec = Record(FCGI_UNKNOWN_TYPE)
+        outrec.contentData = struct.pack(FCGI_UnknownTypeBody, inrec.type)
+        outrec.contentLength = FCGI_UnknownTypeBody_LEN
+        self.writeRecord(rec)
+        
+class MultiplexedConnection(Connection):
+    """
+    A version of Connection capable of handling multiple requests
+    simultaneously.
+    """
+    _multiplexed = True
+    _inputStreamClass = MultiplexedInputStream
+
+    def __init__(self, sock, addr, server):
+        super(MultiplexedConnection, self).__init__(sock, addr, server)
+
+        # Used to arbitrate access to self._requests.
+        lock = threading.RLock()
+
+        # Notification is posted everytime a request completes, allowing us
+        # to quit cleanly.
+        self._lock = threading.Condition(lock)
+
+    def _cleanupSocket(self):
+        # Wait for any outstanding requests before closing the socket.
+        self._lock.acquire()
+        while self._requests:
+            self._lock.wait()
+        self._lock.release()
+
+        super(MultiplexedConnection, self)._cleanupSocket()
+        
+    def writeRecord(self, rec):
+        # Must use locking to prevent intermingling of Records from different
+        # threads.
+        self._lock.acquire()
+        try:
+            # Probably faster than calling super. ;)
+            rec.write(self._sock)
+        finally:
+            self._lock.release()
+
+    def end_request(self, req, appStatus=0L,
+                    protocolStatus=FCGI_REQUEST_COMPLETE, remove=True):
+        self._lock.acquire()
+        try:
+            super(MultiplexedConnection, self).end_request(req, appStatus,
+                                                           protocolStatus,
+                                                           remove)
+            self._lock.notify()
+        finally:
+            self._lock.release()
+
+    def _do_begin_request(self, inrec):
+        self._lock.acquire()
+        try:
+            super(MultiplexedConnection, self)._do_begin_request(inrec)
+        finally:
+            self._lock.release()
+
+    def _do_abort_request(self, inrec):
+        self._lock.acquire()
+        try:
+            super(MultiplexedConnection, self)._do_abort_request(inrec)
+        finally:
+            self._lock.release()
+
+    def _start_request(self, req):
+        thread.start_new_thread(req.run, ())
+
+    def _do_params(self, inrec):
+        self._lock.acquire()
+        try:
+            super(MultiplexedConnection, self)._do_params(inrec)
+        finally:
+            self._lock.release()
+
+    def _do_stdin(self, inrec):
+        self._lock.acquire()
+        try:
+            super(MultiplexedConnection, self)._do_stdin(inrec)
+        finally:
+            self._lock.release()
+
+    def _do_data(self, inrec):
+        self._lock.acquire()
+        try:
+            super(MultiplexedConnection, self)._do_data(inrec)
+        finally:
+            self._lock.release()
+        
+class Server(object):
+    """
+    The FastCGI server.
+
+    Waits for connections from the web server, processing each
+    request.
+
+    If run in a normal CGI context, it will instead instantiate a
+    CGIRequest and run the handler through there.
+    """
+    request_class = Request
+    cgirequest_class = CGIRequest
+
+    # Limits the size of the InputStream's string buffer to this size + the
+    # server's maximum Record size. Since the InputStream is not seekable,
+    # we throw away already-read data once this certain amount has been read.
+    inputStreamShrinkThreshold = 102400 - 8192
+
+    def __init__(self, handler=None, maxwrite=8192, bindAddress=None,
+                 multiplexed=False):
+        """
+        handler, if present, must reference a function or method that
+        takes one argument: a Request object. If handler is not
+        specified at creation time, Server *must* be subclassed.
+        (The handler method below is abstract.)
+
+        maxwrite is the maximum number of bytes (per Record) to write
+        to the server. I've noticed mod_fastcgi has a relatively small
+        receive buffer (8K or so).
+
+        bindAddress, if present, must either be a string or a 2-tuple. If
+        present, run() will open its own listening socket. You would use
+        this if you wanted to run your application as an 'external' FastCGI
+        app. (i.e. the webserver would no longer be responsible for starting
+        your app) If a string, it will be interpreted as a filename and a UNIX
+        socket will be opened. If a tuple, the first element, a string,
+        is the interface name/IP to bind to, and the second element (an int)
+        is the port number.
+
+        Set multiplexed to True if you want to handle multiple requests
+        per connection. Some FastCGI backends (namely mod_fastcgi) don't
+        multiplex requests at all, so by default this is off (which saves
+        on thread creation/locking overhead). If threads aren't available,
+        this keyword is ignored; it's not possible to multiplex requests
+        at all.
+        """
+        if handler is not None:
+            self.handler = handler
+        self.maxwrite = maxwrite
+        if thread_available:
+            try:
+                import resource
+                # Attempt to glean the maximum number of connections
+                # from the OS.
+                maxConns = resource.getrlimit(resource.RLIMIT_NOFILE)[0]
+            except ImportError:
+                maxConns = 100 # Just some made up number.
+            maxReqs = maxConns
+            if multiplexed:
+                self._connectionClass = MultiplexedConnection
+                maxReqs *= 5 # Another made up number.
+            else:
+                self._connectionClass = Connection
+            self.capability = {
+                FCGI_MAX_CONNS: maxConns,
+                FCGI_MAX_REQS: maxReqs,
+                FCGI_MPXS_CONNS: multiplexed and 1 or 0
+                }
+        else:
+            self._connectionClass = Connection
+            self.capability = {
+                # If threads aren't available, these are pretty much correct.
+                FCGI_MAX_CONNS: 1,
+                FCGI_MAX_REQS: 1,
+                FCGI_MPXS_CONNS: 0
+                }
+        self._bindAddress = bindAddress
+
+    def _setupSocket(self):
+        if self._bindAddress is None: # Run as a normal FastCGI?
+            isFCGI = True
+
+            sock = socket.fromfd(FCGI_LISTENSOCK_FILENO, socket.AF_INET,
+                                 socket.SOCK_STREAM)
+            try:
+                sock.getpeername()
+            except socket.error, e:
+                if e[0] == errno.ENOTSOCK:
+                    # Not a socket, assume CGI context.
+                    isFCGI = False
+                elif e[0] != errno.ENOTCONN:
+                    raise
+
+            # FastCGI/CGI discrimination is broken on Mac OS X.
+            # Set the environment variable FCGI_FORCE_CGI to "Y" or "y"
+            # if you want to run your app as a simple CGI. (You can do
+            # this with Apache's mod_env [not loaded by default in OS X
+            # client, ha ha] and the SetEnv directive.)
+            if not isFCGI or \
+               os.environ.get('FCGI_FORCE_CGI', 'N').upper().startswith('Y'):
+                req = self.cgirequest_class(self)
+                req.run()
+                sys.exit(0)
+        else:
+            # Run as a server
+            if type(self._bindAddress) is str:
+                # Unix socket
+                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
+                try:
+                    os.unlink(self._bindAddress)
+                except OSError:
+                    pass
+            else:
+                # INET socket
+                assert type(self._bindAddress) is tuple
+                assert len(self._bindAddress) == 2
+                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
+                sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
+
+            sock.bind(self._bindAddress)
+            sock.listen(socket.SOMAXCONN)
+
+        return sock
+
+    def _cleanupSocket(self, sock):
+        """Closes the main socket."""
+        sock.close()
+
+    def _installSignalHandlers(self):
+        self._oldSIGs = [(x,signal.getsignal(x)) for x in
+                         (signal.SIGHUP, signal.SIGINT, signal.SIGTERM)]
+        signal.signal(signal.SIGHUP, self._hupHandler)
+        signal.signal(signal.SIGINT, self._intHandler)
+        signal.signal(signal.SIGTERM, self._intHandler)
+
+    def _restoreSignalHandlers(self):
+        for signum,handler in self._oldSIGs:
+            signal.signal(signum, handler)
+        
+    def _hupHandler(self, signum, frame):
+        self._hupReceived = True
+        self._keepGoing = False
+
+    def _intHandler(self, signum, frame):
+        self._keepGoing = False
+
+    def run(self, timeout=1.0):
+        """
+        The main loop. Exits on SIGHUP, SIGINT, SIGTERM. Returns True if
+        SIGHUP was received, False otherwise.
+        """
+        web_server_addrs = os.environ.get('FCGI_WEB_SERVER_ADDRS')
+        if web_server_addrs is not None:
+            web_server_addrs = map(lambda x: x.strip(),
+                                   web_server_addrs.split(','))
+
+        sock = self._setupSocket()
+
+        self._keepGoing = True
+        self._hupReceived = False
+
+        # Install signal handlers.
+        self._installSignalHandlers()
+
+        while self._keepGoing:
+            try:
+                r, w, e = select.select([sock], [], [], timeout)
+            except select.error, e:
+                if e[0] == errno.EINTR:
+                    continue
+                raise
+
+            if r:
+                try:
+                    clientSock, addr = sock.accept()
+                except socket.error, e:
+                    if e[0] in (errno.EINTR, errno.EAGAIN):
+                        continue
+                    raise
+
+                if web_server_addrs and \
+                       (len(addr) != 2 or addr[0] not in web_server_addrs):
+                    clientSock.close()
+                    continue
+
+                # Instantiate a new Connection and begin processing FastCGI
+                # messages (either in a new thread or this thread).
+                conn = self._connectionClass(clientSock, addr, self)
+                thread.start_new_thread(conn.run, ())
+
+            self._mainloopPeriodic()
+
+        # Restore signal handlers.
+        self._restoreSignalHandlers()
+
+        self._cleanupSocket(sock)
+
+        return self._hupReceived
+
+    def _mainloopPeriodic(self):
+        """
+        Called with just about each iteration of the main loop. Meant to
+        be overridden.
+        """
+        pass
+
+    def _exit(self, reload=False):
+        """
+        Protected convenience method for subclasses to force an exit. Not
+        really thread-safe, which is why it isn't public.
+        """
+        if self._keepGoing:
+            self._keepGoing = False
+            self._hupReceived = reload
+
+    def handler(self, req):
+        """
+        Default handler, which just raises an exception. Unless a handler
+        is passed at initialization time, this must be implemented by
+        a subclass.
+        """
+        raise NotImplementedError, self.__class__.__name__ + '.handler'
+
+    def error(self, req):
+        """
+        Called by Request if an exception occurs within the handler. May and
+        should be overridden.
+        """
+        import cgitb
+        req.stdout.write('Content-Type: text/html\r\n\r\n' +
+                         cgitb.html(sys.exc_info()))
+
+class WSGIServer(Server):
+    """
+    FastCGI server that supports the Web Server Gateway Interface. See
+    <http://www.python.org/peps/pep-0333.html>.
+    """
+    def __init__(self, application, environ=None, multithreaded=True, **kw):
+        """
+        environ, if present, must be a dictionary-like object. Its
+        contents will be copied into application's environ. Useful
+        for passing application-specific variables.
+
+        Set multithreaded to False if your application is not MT-safe.
+        """
+        if kw.has_key('handler'):
+            del kw['handler'] # Doesn't make sense to let this through
+        super(WSGIServer, self).__init__(**kw)
+
+        if environ is None:
+            environ = {}
+
+        self.application = application
+        self.environ = environ
+        self.multithreaded = multithreaded
+
+        # Used to force single-threadedness
+        self._app_lock = thread.allocate_lock()
+
+    def handler(self, req):
+        """Special handler for WSGI."""
+        if req.role != FCGI_RESPONDER:
+            return FCGI_UNKNOWN_ROLE, 0
+
+        # Mostly taken from example CGI gateway.
+        environ = req.params
+        environ.update(self.environ)
+
+        environ['wsgi.version'] = (1,0)
+        environ['wsgi.input'] = req.stdin
+        if self._bindAddress is None:
+            stderr = req.stderr
+        else:
+            stderr = TeeOutputStream((sys.stderr, req.stderr))
+        environ['wsgi.errors'] = stderr
+        environ['wsgi.multithread'] = not isinstance(req, CGIRequest) and \
+                                      thread_available and self.multithreaded
+        # Rationale for the following: If started by the web server
+        # (self._bindAddress is None) in either FastCGI or CGI mode, the
+        # possibility of being spawned multiple times simultaneously is quite
+        # real. And, if started as an external server, multiple copies may be
+        # spawned for load-balancing/redundancy. (Though I don't think
+        # mod_fastcgi supports this?)
+        environ['wsgi.multiprocess'] = True
+        environ['wsgi.run_once'] = isinstance(req, CGIRequest)
+
+        if environ.get('HTTPS', 'off') in ('on', '1'):
+            environ['wsgi.url_scheme'] = 'https'
+        else:
+            environ['wsgi.url_scheme'] = 'http'
+
+        self._sanitizeEnv(environ)
+
+        headers_set = []
+        headers_sent = []
+        result = None
+
+        def write(data):
+            assert type(data) is str, 'write() argument must be string'
+            assert headers_set, 'write() before start_response()'
+
+            if not headers_sent:
+                status, responseHeaders = headers_sent[:] = headers_set
+                found = False
+                for header,value in responseHeaders:
+                    if header.lower() == 'content-length':
+                        found = True
+                        break
+                if not found and result is not None:
+                    try:
+                        if len(result) == 1:
+                            responseHeaders.append(('Content-Length',
+                                                    str(len(data))))
+                    except:
+                        pass
+                s = 'Status: %s\r\n' % status
+                for header in responseHeaders:
+                    s += '%s: %s\r\n' % header
+                s += '\r\n'
+                req.stdout.write(s)
+
+            req.stdout.write(data)
+            req.stdout.flush()
+
+        def start_response(status, response_headers, exc_info=None):
+            if exc_info:
+                try:
+                    if headers_sent:
+                        # Re-raise if too late
+                        raise exc_info[0], exc_info[1], exc_info[2]
+                finally:
+                    exc_info = None # avoid dangling circular ref
+            else:
+                assert not headers_set, 'Headers already set!'
+
+            assert type(status) is str, 'Status must be a string'
+            assert len(status) >= 4, 'Status must be at least 4 characters'
+            assert int(status[:3]), 'Status must begin with 3-digit code'
+            assert status[3] == ' ', 'Status must have a space after code'
+            assert type(response_headers) is list, 'Headers must be a list'
+            if __debug__:
+                for name,val in response_headers:
+                    assert type(name) is str, 'Header names must be strings'
+                    assert type(val) is str, 'Header values must be strings'
+
+            headers_set[:] = [status, response_headers]
+            return write
+
+        if not self.multithreaded:
+            self._app_lock.acquire()
+        try:
+            result = self.application(environ, start_response)
+            try:
+                for data in result:
+                    if data:
+                        write(data)
+                if not headers_sent:
+                    write('') # in case body was empty
+            finally:
+                if hasattr(result, 'close'):
+                    result.close()
+        finally:
+            if not self.multithreaded:
+                self._app_lock.release()
+
+        return FCGI_REQUEST_COMPLETE, 0
+
+    def _sanitizeEnv(self, environ):
+        """Ensure certain values are present, if required by WSGI."""
+        if not environ.has_key('SCRIPT_NAME'):
+            environ['SCRIPT_NAME'] = ''
+        if not environ.has_key('PATH_INFO'):
+            environ['PATH_INFO'] = ''
+
+        # If any of these are missing, it probably signifies a broken
+        # server...
+        for name,default in [('REQUEST_METHOD', 'GET'),
+                             ('SERVER_NAME', 'localhost'),
+                             ('SERVER_PORT', '80'),
+                             ('SERVER_PROTOCOL', 'HTTP/1.0')]:
+            if not environ.has_key(name):
+                environ['wsgi.errors'].write('%s: missing FastCGI param %s '
+                                             'required by WSGI!\n' %
+                                             (self.__class__.__name__, name))
+                environ[name] = default
+            
+if __name__ == '__main__':
+    def test_app(environ, start_response):
+        """Probably not the most efficient example."""
+        import cgi
+        start_response('200 OK', [('Content-Type', 'text/html')])
+        yield '<html><head><title>Hello World!</title></head>\n' \
+              '<body>\n' \
+              '<p>Hello World!</p>\n' \
+              '<table border="1">'
+        names = environ.keys()
+        names.sort()
+        for name in names:
+            yield '<tr><td>%s</td><td>%s</td></tr>\n' % (
+                name, cgi.escape(`environ[name]`))
+
+        form = cgi.FieldStorage(fp=environ['wsgi.input'], environ=environ,
+                                keep_blank_values=1)
+        if form.list:
+            yield '<tr><th colspan="2">Form data</th></tr>'
+
+        for field in form.list:
+            yield '<tr><td>%s</td><td>%s</td></tr>\n' % (
+                field.name, field.value)
+
+        yield '</table>\n' \
+              '</body></html>\n'
+
+    WSGIServer(test_app).run()
diff -urN trac-trunk/build/lib/trac/web/api.py aw-trac/build/lib/trac/web/api.py
--- trac-trunk/build/lib/trac/web/api.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/api.py	2006-03-08 01:26:20.000000000 -0800
@@ -0,0 +1,432 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+from BaseHTTPServer import BaseHTTPRequestHandler
+from Cookie import SimpleCookie as Cookie
+import cgi
+import mimetypes
+import os
+from StringIO import StringIO
+import sys
+import urlparse
+
+from trac.core import Interface
+from trac.util import http_date
+from trac.web.href import Href
+
+HTTP_STATUS = dict([(code, reason.title()) for code, (reason, description)
+                    in BaseHTTPRequestHandler.responses.items()])
+
+class HTTPException(Exception):
+    """Exception representing a HTTP status code."""
+
+    def __init__(self, code):
+        self.code = code
+        self.reason = HTTP_STATUS.get(self.code, 'Unknown')
+        self.__doc__ = 'Exception for HTTP %d %s' % (self.code, self.reason)
+
+    def __call__(self, message, *args):
+        self.message = message
+        if args:
+            self.message = self.message % args
+        Exception.__init__(self, '%s %s (%s)' % (self.code, self.reason,
+                                                 message))
+        return self
+
+    def __str__(self):
+        return '%s %s (%s)' % (self.code, self.reason, self.message)
+
+
+for code in [code for code in HTTP_STATUS if code >= 400]:
+    exc_name = HTTP_STATUS[code].replace(' ', '')
+    if exc_name.lower().startswith('http'):
+        exc_name = exc_name[4:]
+    setattr(sys.modules[__name__], 'HTTP' + exc_name, HTTPException(code))
+del code, exc_name
+
+
+class _RequestArgs(dict):
+    """Dictionary subclass that provides convenient access to request
+    parameters that may contain multiple values."""
+
+    def getfirst(self, name, default=None):
+        """Return the first value for the specified parameter, or `default` if
+        the parameter was not provided.
+        """
+        if name not in self:
+            return default
+        val = self[name]
+        if isinstance(val, list):
+            val = val[0]
+        return val
+
+    def getlist(self, name):
+        """Return a list of values for the specified parameter, even if only
+        one value was provided.
+        """
+        if name not in self:
+            return []
+        val = self[name]
+        if not isinstance(val, list):
+            val = [val]
+        return val
+
+
+class RequestDone(Exception):
+    """Marker exception that indicates whether request processing has completed
+    and a response was sent.
+    """
+
+
+class Request(object):
+    """Represents a HTTP request/response pair.
+    
+    This class provides a convenience API over WSGI.
+    """
+    args = None
+    hdf = None
+    authname = None
+    perm = None
+    session = None
+
+    def __init__(self, environ, start_response):
+        """Create the request wrapper.
+        
+        @param environ: The WSGI environment dict
+        @param start_response: The WSGI callback for starting the response
+        """
+        self.environ = environ
+        self._start_response = start_response
+        self._write = None
+        self._status = '200 OK'
+        self._response = None
+
+        self._inheaders = [(name[5:].replace('_', '-').lower(), value)
+                           for name, value in environ.items()
+                           if name.startswith('HTTP_')]
+        if 'CONTENT_LENGTH' in environ:
+            self._inheaders.append(('content-length',
+                                    environ['CONTENT_LENGTH']))
+        if 'CONTENT_TYPE' in environ:
+            self._inheaders.append(('content-type', environ['CONTENT_TYPE']))
+        self._outheaders = []
+
+        self.incookie = Cookie()
+        cookie = self.get_header('Cookie')
+        if cookie:
+            self.incookie.load(cookie)
+        self.outcookie = Cookie()
+
+        self.base_url = self.environ.get('trac.base_url')
+        if not self.base_url:
+            self.base_url = self._reconstruct_url()
+        self.href = Href(self.base_path)
+        self.abs_href = Href(self.base_url)
+
+        self.args = self._parse_args()
+
+    def _parse_args(self):
+        """Parse the supplied request parameters into a dictionary."""
+        args = _RequestArgs()
+
+        fp = self.environ['wsgi.input']
+        ctype = self.get_header('Content-Type')
+        if ctype:
+            # Avoid letting cgi.FieldStorage consume the input stream when the
+            # request does not contain form data
+            ctype, options = cgi.parse_header(ctype)
+            if ctype not in ('application/x-www-form-urlencoded',
+                             'multipart/form-data'):
+                fp = StringIO('')
+
+        fs = cgi.FieldStorage(fp, environ=self.environ, keep_blank_values=True)
+        if fs.list:
+            for name in fs.keys():
+                values = fs[name]
+                if not isinstance(values, list):
+                    values = [values]
+                for value in values:
+                    if not value.filename:
+                        value = value.value
+                    if name in args:
+                        if isinstance(args[name], list):
+                            args[name].append(value)
+                        else:
+                            args[name] = [args[name], value]
+                    else:
+                        args[name] = value
+
+        return args
+
+    def _reconstruct_url(self):
+        """Reconstruct the absolute base URL of the application."""
+        host = self.get_header('Host')
+        if self.get_header('X-Forwarded-Host'):
+            host = self.get_header('X-Forwarded-Host')
+        if not host:
+            # Missing host header, so reconstruct the host from the
+            # server name and port
+            default_port = {'http': 80, 'https': 443}
+            if self.server_port and self.server_port != default_port[self.scheme]:
+                host = '%s:%d' % (self.server_name, self.server_port)
+            else:
+                host = self.server_name
+        return urlparse.urlunparse((self.scheme, host, self.base_path, None,
+                                    None, None))
+
+    method = property(fget=lambda self: self.environ['REQUEST_METHOD'],
+                      doc='The HTTP method of the request')
+    path_info = property(fget=lambda self: self.environ.get('PATH_INFO', ''),
+                         doc='Path inside the application')
+    remote_addr = property(fget=lambda self: self.environ.get('REMOTE_ADDR'),
+                           doc='IP address of the remote user')
+    remote_user = property(fget=lambda self: self.environ.get('REMOTE_USER'),
+                           doc='Name of the remote user, `None` if the user'
+                               'has not logged in using HTTP authentication')
+    scheme = property(fget=lambda self: self.environ['wsgi.url_scheme'],
+                      doc='The scheme of the request URL')
+    base_path = property(fget=lambda self: self.environ.get('SCRIPT_NAME', ''),
+                         doc='The root path of the application')
+    server_name = property(fget=lambda self: self.environ['SERVER_NAME'],
+                           doc='Name of the server')
+    server_port = property(fget=lambda self: int(self.environ['SERVER_PORT']),
+                           doc='Port number the server is bound to')
+
+    def get_header(self, name):
+        """Return the value of the specified HTTP header, or `None` if there's
+        no such header in the request.
+        """
+        name = name.lower()
+        for key, value in self._inheaders:
+            if key == name:
+                return value
+        return None
+
+    def send_response(self, code=200):
+        """Set the status code of the response."""
+        self._status = '%s %s' % (code, HTTP_STATUS.get(code, 'Unknown'))
+
+    def send_header(self, name, value):
+        """Send the response header with the specified name and value."""
+        self._outheaders.append((name, str(value)))
+
+    def _send_cookie_headers(self):
+        for name in self.outcookie.keys():
+            path = self.outcookie[name].get('path')
+            if path:
+                path = path.replace(' ', '%20') \
+                           .replace(';', '%3B') \
+                           .replace(',', '%3C')
+            self.outcookie[name]['path'] = path
+
+        cookies = self.outcookie.output(header='')
+        for cookie in cookies.splitlines():
+            self._outheaders.append(('Set-Cookie', cookie.strip()))
+
+    def end_headers(self):
+        """Must be called after all headers have been sent and before the actual
+        content is written.
+        """
+        self._send_cookie_headers()
+        self._write = self._start_response(self._status, self._outheaders)
+
+    def check_modified(self, timesecs, extra=''):
+        """Check the request "If-None-Match" header against an entity tag
+        generated from the specified last modified time in seconds (`timesecs`),
+        optionally appending an `extra` string to indicate variants of the
+        requested resource. That `extra` parameter can also be a list,
+        in which case the MD5 sum of the list content will be used.
+
+        If the generated tag matches the "If-None-Match" header of the request,
+        this method sends a "304 Not Modified" response to the client.
+        Otherwise, it adds the entity tag as as "ETag" header to the response so
+        that consequetive requests can be cached.
+        """
+        if isinstance(extra, list):
+            import md5
+            m = md5.new()
+            for elt in extra:
+                m.update(str(elt))
+            extra = m.hexdigest()
+        etag = 'W"%s/%d/%s"' % (self.authname, timesecs, extra)
+        inm = self.get_header('If-None-Match')
+        if (not inm or inm != etag):
+            self.send_header('ETag', etag)
+        else:
+            self.send_response(304)
+            self.end_headers()
+            raise RequestDone
+
+    def redirect(self, url, permanent=False):
+        """Send a redirect to the client, forwarding to the specified URL. The
+        `url` may be relative or absolute, relative URLs will be translated
+        appropriately.
+        """
+        if self.session:
+            self.session.save() # has to be done before the redirect is sent
+
+        if permanent:
+            status = 301 # 'Moved Permanently'
+        elif self.method == 'POST':
+            status = 303 # 'See Other' -- safe to use in response to a POST
+        else:
+            status = 302 # 'Found' -- normal temporary redirect
+
+        self.send_response(status)
+        if not url.startswith('http://') and not url.startswith('https://'):
+            # Make sure the URL is absolute
+            url = urlparse.urlunparse((self.scheme,
+                                       urlparse.urlparse(self.base_url)[1],
+                                       url, None, None, None))
+        self.send_header('Location', url)
+        self.send_header('Content-Type', 'text/plain')
+        self.send_header('Pragma', 'no-cache')
+        self.send_header('Cache-control', 'no-cache')
+        self.send_header('Expires', 'Fri, 01 Jan 1999 00:00:00 GMT')
+        self.end_headers()
+
+        if self.method != 'HEAD':
+            self.write('Redirecting...')
+        raise RequestDone
+
+    def display(self, template, content_type='text/html', status=200):
+        """Render the response using the ClearSilver template given by the
+        `template` parameter, which can be either the name of the template file,
+        or an already parsed `neo_cs.CS` object.
+        """
+        assert self.hdf, 'HDF dataset not available'
+        if self.args.has_key('hdfdump'):
+            # FIXME: the administrator should probably be able to disable HDF
+            #        dumps
+            content_type = 'text/plain'
+            data = str(self.hdf)
+        else:
+            data = self.hdf.render(template)
+
+        self.send_response(status)
+        self.send_header('Cache-control', 'must-revalidate')
+        self.send_header('Expires', 'Fri, 01 Jan 1999 00:00:00 GMT')
+        self.send_header('Content-Type', content_type + ';charset=utf-8')
+        self.send_header('Content-Length', len(data))
+        self.end_headers()
+
+        if self.method != 'HEAD':
+            self.write(data)
+        raise RequestDone
+
+    def send_error(self, exc_info, template='error.cs',
+                   content_type='text/html', status=500):
+        if self.hdf:
+            if self.args.has_key('hdfdump'):
+                # FIXME: the administrator should probably be able to disable HDF
+                #        dumps
+                content_type = 'text/plain'
+                data = str(self.hdf)
+            else:
+                data = self.hdf.render(template)
+        else:
+            data = str(exc_info[1])
+
+        self.send_response(status)
+        self._outheaders = []
+        self.send_header('Cache-control', 'must-revalidate')
+        self.send_header('Expires', 'Fri, 01 Jan 1999 00:00:00 GMT')
+        self.send_header('Content-Type', content_type + ';charset=utf-8')
+        self.send_header('Content-Length', len(data))
+        self._send_cookie_headers()
+
+        self._write = self._start_response(self._status, self._outheaders,
+                                           exc_info)
+
+        if self.method != 'HEAD':
+            self.write(data)
+        raise RequestDone
+
+    def send_file(self, path, mimetype=None):
+        """Send a local file to the browser.
+        
+        This method includes the "Last-Modified", "Content-Type" and
+        "Content-Length" headers in the response, corresponding to the file
+        attributes. It also checks the last modification time of the local file
+        against the "If-Modified-Since" provided by the user agent, and sends a
+        "304 Not Modified" response if it matches.
+        """
+        if not os.path.isfile(path):
+            raise HTTPNotFound("File %s not found" % path)
+
+        stat = os.stat(path)
+        last_modified = http_date(stat.st_mtime)
+        if last_modified == self.get_header('If-Modified-Since'):
+            self.send_response(304)
+            self.end_headers()
+            raise RequestDone
+
+        if not mimetype:
+            mimetype = mimetypes.guess_type(path)[0]
+
+        self.send_response(200)
+        self.send_header('Content-Type', mimetype)
+        self.send_header('Content-Length', stat.st_size)
+        self.send_header('Last-Modified', last_modified)
+        self.end_headers()
+
+        if self.method != 'HEAD':
+            self._response = file(path, 'rb')
+            file_wrapper = self.environ.get('wsgi.file_wrapper')
+            if file_wrapper:
+                self._response = file_wrapper(self._response, 4096)
+        raise RequestDone
+
+    def read(self, size=None):
+        """Read the specified number of bytes from the request body."""
+        fileobj = self.environ['wsgi.input']
+        if size is None:
+            size = int(self.get_header('Content-Length', -1))
+        data = fileobj.read(size)
+        return data
+
+    def write(self, data):
+        """Write the given data to the response body."""
+        if not self._write:
+            self.end_headers()
+        self._write(data)
+
+
+class IAuthenticator(Interface):
+    """Extension point interface for components that can provide the name
+    of the remote user."""
+
+    def authenticate(req):
+        """Return the name of the remote user, or `None` if the identity of the
+        user is unknown."""
+
+
+class IRequestHandler(Interface):
+    """Extension point interface for request handlers."""
+
+    def match_request(req):
+        """Return whether the handler wants to process the given request."""
+
+    def process_request(req):
+        """Process the request. Should return a (template_name, content_type)
+        tuple, where `template` is the ClearSilver template to use (either
+        a `neo_cs.CS` object, or the file name of the template), and
+        `content_type` is the MIME type of the content. If `content_type` is
+        `None`, "text/html" is assumed.
+
+        Note that if template processing should not occur, this method can
+        simply send the response itself and not return anything.
+        """
diff -urN trac-trunk/build/lib/trac/web/auth.py aw-trac/build/lib/trac/web/auth.py
--- trac-trunk/build/lib/trac/web/auth.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/auth.py	2006-03-06 03:36:02.000000000 -0800
@@ -0,0 +1,174 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+import re
+import time
+
+from trac.core import *
+from trac.web.api import IAuthenticator, IRequestHandler
+from trac.web.chrome import INavigationContributor
+from trac.util import escape, hex_entropy, Markup
+
+
+class LoginModule(Component):
+    """Implements user authentication based on HTTP authentication provided by
+    the web-server, combined with cookies for communicating the login
+    information across the whole site.
+
+    This mechanism expects that the web-server is setup so that a request to the
+    path '/login' requires authentication (such as Basic or Digest). The login
+    name is then stored in the database and associated with a unique key that
+    gets passed back to the user agent using the 'trac_auth' cookie. This cookie
+    is used to identify the user in subsequent requests to non-protected
+    resources.
+    """
+
+    implements(IAuthenticator, INavigationContributor, IRequestHandler)
+
+    # IAuthenticator methods
+
+    def authenticate(self, req):
+        authname = None
+        if req.remote_user:
+            authname = req.remote_user
+        elif req.incookie.has_key('trac_auth'):
+            authname = self._get_name_for_cookie(req, req.incookie['trac_auth'])
+
+        if not authname:
+            return None
+
+        if self.config.getbool('trac', 'ignore_auth_case'):
+            authname = authname.lower()
+
+        return authname
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'login'
+
+    def get_navigation_items(self, req):
+        if req.authname and req.authname != 'anonymous':
+            yield ('metanav', 'login', 'logged in as %s' % req.authname)
+            yield ('metanav', 'logout',
+                   Markup('<a href="%s">Logout</a>' 
+                          % escape(self.env.href.logout())))
+        else:
+            yield ('metanav', 'login',
+                   Markup('<a href="%s">Login</a>' 
+                          % escape(self.env.href.login())))
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        return re.match('/(login|logout)/?', req.path_info)
+
+    def process_request(self, req):
+        if req.path_info.startswith('/login'):
+            self._do_login(req)
+        elif req.path_info.startswith('/logout'):
+            self._do_logout(req)
+        self._redirect_back(req)
+
+    # Internal methods
+
+    def _do_login(self, req):
+        """Log the remote user in.
+
+        This function expects to be called when the remote user name is
+        available. The user name is inserted into the `auth_cookie` table and a
+        cookie identifying the user on subsequent requests is sent back to the
+        client.
+
+        If the Authenticator was created with `ignore_case` set to true, then 
+        the authentication name passed from the web server in req.remote_user
+        will be converted to lower case before being used. This is to avoid
+        problems on installations authenticating against Windows which is not
+        case sensitive regarding user names and domain names
+        """
+        assert req.remote_user, 'Authentication information not available.'
+
+        remote_user = req.remote_user
+        if self.config.getbool('trac', 'ignore_auth_case'):
+            remote_user = remote_user.lower()
+
+        assert req.authname in ('anonymous', remote_user), \
+               'Already logged in as %s.' % req.authname
+
+        cookie = hex_entropy()
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("INSERT INTO auth_cookie (cookie,name,ipnr,time) "
+                       "VALUES (%s, %s, %s, %s)", (cookie, remote_user,
+                       req.remote_addr, int(time.time())))
+        db.commit()
+
+        req.authname = remote_user
+        req.outcookie['trac_auth'] = cookie
+        req.outcookie['trac_auth']['path'] = self.env.href()
+
+    def _do_logout(self, req):
+        """Log the user out.
+
+        Simply deletes the corresponding record from the auth_cookie table.
+        """
+        if req.authname == 'anonymous':
+            # Not logged in
+            return
+
+        # While deleting this cookie we also take the opportunity to delete
+        # cookies older than 10 days
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("DELETE FROM auth_cookie WHERE name=%s OR time < %s",
+                       (req.authname, int(time.time()) - 86400 * 10))
+        db.commit()
+        self._expire_cookie(req)
+
+    def _expire_cookie(self, req):
+        """Instruct the user agent to drop the auth cookie by setting the
+        "expires" property to a date in the past.
+        """
+        req.outcookie['trac_auth'] = ''
+        req.outcookie['trac_auth']['path'] = self.env.href()
+        req.outcookie['trac_auth']['expires'] = -10000
+
+    def _get_name_for_cookie(self, req, cookie):
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        if self.config.getbool('trac', 'check_auth_ip'):
+            cursor.execute("SELECT name FROM auth_cookie "
+                           "WHERE cookie=%s AND ipnr=%s",
+                           (cookie.value, req.remote_addr))
+        else:
+            cursor.execute("SELECT name FROM auth_cookie WHERE cookie=%s",
+                           (cookie.value,))
+        row = cursor.fetchone()
+        if not row:
+            # The cookie is invalid (or has been purged from the database), so
+            # tell the user agent to drop it as it is invalid
+            self._expire_cookie(req)
+            return None
+
+        return row[0]
+
+    def _redirect_back(self, req):
+        """Redirect the user back to the URL she came from."""
+        referer = req.get_header('Referer')
+        if referer and not referer.startswith(req.base_url):
+            # only redirect to referer if it is from the same site
+            referer = None
+        req.redirect(referer or self.env.abs_href())
diff -urN trac-trunk/build/lib/trac/web/cgi_frontend.py aw-trac/build/lib/trac/web/cgi_frontend.py
--- trac-trunk/build/lib/trac/web/cgi_frontend.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/cgi_frontend.py	2006-03-06 03:36:02.000000000 -0800
@@ -0,0 +1,68 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+#         Matthew Good <trac@matt-good.net>
+
+import os
+import sys
+
+from trac.web.main import dispatch_request
+from trac.web.wsgi import WSGIGateway
+
+
+class CGIGateway(WSGIGateway):
+
+    wsgi_multithread = False
+    wsgi_multiprocess = False
+    wsgi_run_once = True
+
+    def __init__(self):
+        WSGIGateway.__init__(self, dict(os.environ))
+
+    def _write(self, data):
+        assert self.headers_set, 'Response not started'
+
+        if not self.headers_sent:
+            status, headers = self.headers_sent = self.headers_set
+            sys.stdout.write('Status: %s\r\n' % status)
+            for header in headers:
+                sys.stdout.write('%s: %s\r\n' % header)
+            sys.stdout.write('\r\n')
+            sys.stdout.flush()
+
+        sys.stdout.write(data)
+        sys.stdout.flush()
+
+
+def run():
+    try: # Make FreeBSD use blocking I/O like other platforms
+        import fcntl
+        for stream in [sys.stdin, sys.stdout]:
+            fd = stream.fileno()
+            flags = fcntl.fcntl(fd, fcntl.F_GETFL)
+            fcntl.fcntl(fd, fcntl.F_SETFL, flags & ~os.O_NONBLOCK)
+    except ImportError:
+        pass
+
+    try: # Use binary I/O on Windows
+        import msvcrt
+        msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
+        msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
+    except ImportError:
+        pass
+
+    gateway = CGIGateway()
+    gateway.run(dispatch_request)
diff -urN trac-trunk/build/lib/trac/web/chrome.py aw-trac/build/lib/trac/web/chrome.py
--- trac-trunk/build/lib/trac/web/chrome.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/chrome.py	2006-03-06 03:36:02.000000000 -0800
@@ -0,0 +1,281 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+import os
+import re
+
+from trac import mimeview, util
+from trac.core import *
+from trac.env import IEnvironmentSetupParticipant
+from trac.web.api import IRequestHandler, HTTPNotFound
+from trac.web.href import Href
+from trac.wiki import IWikiSyntaxProvider
+
+def add_link(req, rel, href, title=None, mimetype=None, classname=None):
+    """Add a link to the HDF data set that will be inserted as <link> element in
+    the <head> of the generated HTML
+    """
+    link = {'href': href}
+    if title:
+        link['title'] = title
+    if mimetype:
+        link['type'] = mimetype
+    if classname:
+        link['class'] = classname
+    idx = 0
+    while req.hdf.get('chrome.links.%s.%d.href' % (rel, idx)):
+        idx += 1
+    req.hdf['chrome.links.%s.%d' % (rel, idx)] = link
+
+def add_stylesheet(req, filename, mimetype='text/css'):
+    """Add a link to a style sheet to the HDF data set so that it gets included
+    in the generated HTML page.
+    """
+    if filename.startswith('common/') and 'htdocs_location' in req.hdf:
+        href = Href(req.hdf['htdocs_location'])
+        filename = filename[7:]
+    else:
+        href = Href(req.base_path).chrome
+    add_link(req, 'stylesheet', href(filename), mimetype=mimetype)
+
+
+class INavigationContributor(Interface):
+    """Extension point interface for components that contribute items to the
+    navigation.
+    """
+
+    def get_active_navigation_item(req):
+        """This method is only called for the `IRequestHandler` processing the
+        request.
+        
+        It should return the name of the navigation item that should be
+        highlighted as active/current.
+        """
+
+    def get_navigation_items(req):
+        """Should return an iterable object over the list of navigation items to
+        add, each being a tuple in the form (category, name, text).
+        """
+
+
+class ITemplateProvider(Interface):
+    """Extension point interface for components that provide their own
+    ClearSilver templates and accompanying static resources.
+    """
+
+    def get_htdocs_dirs():
+        """Return a list of directories with static resources (such as style
+        sheets, images, etc.)
+
+        Each item in the list must be a `(prefix, abspath)` tuple. The
+        `prefix` part defines the path in the URL that requests to these
+        resources are prefixed with.
+        
+        The `abspath` is the absolute path to the directory containing the
+        resources on the local file system.
+        """
+
+    def get_templates_dirs():
+        """Return a list of directories containing the provided ClearSilver
+        templates.
+        """
+
+
+class Chrome(Component):
+    """Responsible for assembling the web site chrome, i.e. everything that
+    is not actual page content.
+    """
+    implements(IEnvironmentSetupParticipant, IRequestHandler, ITemplateProvider,
+               IWikiSyntaxProvider)
+
+    navigation_contributors = ExtensionPoint(INavigationContributor)
+    template_providers = ExtensionPoint(ITemplateProvider)
+
+    # IEnvironmentSetupParticipant methods
+
+    def environment_created(self):
+        """Create the templates directory and some templates for
+        customization.
+        """
+        def _create_file(filename, data=None):
+            fd = open(filename, 'w')
+            if data:
+                fd.write(data)
+            fd.close()
+
+        if self.env.path:
+            templates_dir = os.path.join(self.env.path, 'templates')
+            if not os.path.exists(templates_dir):
+                os.mkdir(templates_dir)
+            _create_file(os.path.join(templates_dir, 'README'),
+                        'This directory contains project-specific custom '
+                        'templates and style sheet.\n')
+            _create_file(os.path.join(templates_dir, 'site_header.cs'),
+                         """<?cs
+####################################################################
+# Site header - Contents are automatically inserted above Trac HTML
+?>
+""")
+            _create_file(os.path.join(templates_dir, 'site_footer.cs'),
+                         """<?cs
+#########################################################################
+# Site footer - Contents are automatically inserted after main Trac HTML
+?>
+""")
+            _create_file(os.path.join(templates_dir, 'site_css.cs'),
+                         """<?cs
+##################################################################
+# Site CSS - Place custom CSS, including overriding styles here.
+?>
+""")
+
+    def environment_needs_upgrade(self, db):
+        return False
+
+    def upgrade_environment(self, db):
+        pass
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        match = re.match(r'/chrome/(?P<prefix>[^/]+)/(?P<filename>[/\w\-\.]+)',
+                         req.path_info)
+        if match:
+            req.args['prefix'] = match.group('prefix')
+            req.args['filename'] = match.group('filename')
+            return True
+
+    def process_request(self, req):
+        prefix = req.args['prefix']
+        filename = req.args['filename']
+
+        dirs = []
+        for provider in self.template_providers:
+            for dir in [os.path.normpath(dir[1]) for dir
+                        in provider.get_htdocs_dirs() if dir[0] == prefix]:
+                dirs.append(dir)
+                path = os.path.normpath(os.path.join(dir, filename))
+                assert os.path.commonprefix([dir, path]) == dir
+                if os.path.isfile(path):
+                    req.send_file(path)
+
+        self.log.warning('File %s not found in any of %s', filename, dirs)
+        raise HTTPNotFound('File %s not found', filename)
+
+    # ITemplateProvider methods
+
+    def get_htdocs_dirs(self):
+        from trac.config import default_dir
+        return [('common', default_dir('htdocs')),
+                ('site', self.env.get_htdocs_dir())]
+
+    def get_templates_dirs(self):
+        return [self.env.get_templates_dir(),
+                self.config.get('trac', 'templates_dir')]
+
+    # IWikiSyntaxProvider methods
+    
+    def get_wiki_syntax(self):
+        return []
+    
+    def get_link_resolvers(self):
+        yield ('htdocs', self._format_link)
+
+    def _format_link(self, formatter, ns, file, label):
+        href = self.env.href.chrome('site', file)
+        return '<a href="%s">%s</a>' % (util.escape(href), label)
+
+    # Public API methods
+
+    def get_all_templates_dirs(self):
+        """Return a list of the names of all known templates directories."""
+        dirs = []
+        for provider in self.template_providers:
+            dirs += provider.get_templates_dirs()
+        return dirs
+
+    def populate_hdf(self, req, handler):
+        """Add chrome-related data to the HDF."""
+
+        # Provided for template customization
+        req.hdf['HTTP.PathInfo'] = req.path_info
+
+        href = Href(req.base_path)
+        req.hdf['chrome.href'] = href.chrome()
+        htdocs_location = self.config.get('trac', 'htdocs_location') or \
+                          href.chrome('common')
+        req.hdf['htdocs_location'] = htdocs_location.rstrip('/') + '/'
+
+        # HTML <head> links
+        add_link(req, 'start', self.env.href.wiki())
+        add_link(req, 'search', self.env.href.search())
+        add_link(req, 'help', self.env.href.wiki('TracGuide'))
+        add_stylesheet(req, 'common/css/trac.css')
+        icon = self.config.get('project', 'icon')
+        if icon:
+            if not icon.startswith('/') and icon.find('://') == -1:
+                if '/' in icon:
+                    icon = href.chrome(icon)
+                else:
+                    icon = href.chrome('common', icon)
+            mimetype = mimeview.get_mimetype(icon)
+            add_link(req, 'icon', icon, mimetype=mimetype)
+            add_link(req, 'shortcut icon', icon, mimetype=mimetype)
+
+        # Logo image
+        logo_link = self.config.get('header_logo', 'link')
+        logo_src = self.config.get('header_logo', 'src')
+        if logo_src:
+            logo_src_abs = logo_src.startswith('http://') or \
+                           logo_src.startswith('https://')
+            if not logo_src.startswith('/') and not logo_src_abs:
+                if '/' in logo_src:
+                    logo_src = href.chrome(logo_src)
+                else:
+                    logo_src = href.chrome('common', logo_src)
+            req.hdf['chrome.logo'] = {
+                'link': logo_link, 'src': logo_src, 'src_abs': logo_src_abs,
+                'alt': self.config.get('header_logo', 'alt'),
+                'width': self.config.get('header_logo', 'width', ''),
+                'height': self.config.get('header_logo', 'height', '')
+            }
+        else:
+            req.hdf['chrome.logo.link'] = logo_link
+
+        # Navigation links
+        navigation = {}
+        active = None
+        for contributor in self.navigation_contributors:
+            for category, name, text in contributor.get_navigation_items(req):
+                navigation.setdefault(category, {})[name] = text
+            if contributor is handler:
+                active = contributor.get_active_navigation_item(req)
+
+        for category, items in [(k, v.items()) for k, v in navigation.items()]:
+            order = [x.strip() for x
+                     in self.config.get('trac', category).split(',')]
+            def navcmp(x, y):
+                if x[0] not in order:
+                    return int(y[0] in order)
+                if y[0] not in order:
+                    return -int(x[0] in order)
+                return cmp(order.index(x[0]), order.index(y[0]))
+            items.sort(navcmp)
+
+            for name, text in items:
+                req.hdf['chrome.nav.%s.%s' % (category, name)] = text
+                if name == active:
+                    req.hdf['chrome.nav.%s.%s.active' % (category, name)] = 1
diff -urN trac-trunk/build/lib/trac/web/clearsilver.py aw-trac/build/lib/trac/web/clearsilver.py
--- trac-trunk/build/lib/trac/web/clearsilver.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/clearsilver.py	2005-12-28 05:38:30.000000000 -0800
@@ -0,0 +1,282 @@
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+from trac.core import TracError
+from trac import util
+
+
+class HDFWrapper:
+    """
+    Convenience layer on top of the low-level ClearSilver python bindings
+    for HDF manipulation. This class makes the HDF look and behave more
+    like a standard Python dict.
+
+    >>> hdf = HDFWrapper()
+    >>> hdf['trac.url'] = 'http://projects.edgewall.com/trac/'
+    >>> hdf['trac.version'] = '1.0'
+    >>> print hdf
+    trac {
+      url = http://projects.edgewall.com/trac/
+      version = 1.0
+    }
+
+    HDFWrapper can also assign Python lists and dicts to HDF nodes,
+    automatically expanding them into the corresponding HDF structure.
+
+    A dictionary is mapped to a HDF node with named children:
+
+    >>> hdf = HDFWrapper()
+    >>> hdf['item'] = {'name': 'An item', 'value': '0'}
+    >>> print hdf
+    item {
+      name = An item
+      value = 0
+    }
+
+    A sequence is mapped to a HDF node with children whose names are
+    the indexes of the elements:
+
+    >>> hdf = HDFWrapper()
+    >>> hdf['items'] = ['Item 1', 'Item 2']
+    >>> print hdf
+    items {
+      0 = Item 1
+      1 = Item 2
+    }
+
+    Simple values can also be easily retrieved using the same syntax.
+
+    >>> hdf = HDFWrapper()
+    >>> hdf['time'] = 42
+    >>> hdf['time']
+    '42'
+    >>> hdf['name'] = 'Foo'
+    >>> hdf['name']
+    'Foo'
+
+    An attempt to retrieve a value that hasn't been set will raise a KeyError,
+    just like a standard dictionary:
+
+    >>> hdf['undef']
+    Traceback (most recent call last):
+        ...
+    KeyError: 'undef'
+    
+    It may be preferable to return a default value if the given key does not exit.
+    It will return 'None' when the specified key is not present:
+
+    >>> hdf.get('time')
+    '42'
+    >>> hdf.get('undef')
+
+    A second argument may be passed to specify the default return value:
+
+    >>> hdf.get('time', 'Undefined Key')
+    '42'
+    >>> hdf.get('undef', 'Undefined Key')
+    'Undefined Key'
+
+    The 'in' and 'not in' operators can be used to test whether the HDF contains
+    a value with a given name.
+
+    >>> 'name' in hdf
+    True
+    >>> 'undef' in hdf
+    False
+
+    has_key() performs the same function:
+
+    >>> hdf.has_key('name')
+    True
+    >>> hdf.has_key('undef')
+    False
+    """
+
+    def __init__(self, loadpaths=[]):
+        """Create a new HDF dataset.
+        
+        The loadpaths parameter can be used to specify a sequence of paths under
+        which ClearSilver will search for template files:
+
+        >>> hdf = HDFWrapper(loadpaths=['/etc/templates',
+        ...                             '/home/john/templates'])
+        >>> print hdf
+        hdf {
+          loadpaths {
+            0 = /etc/templates
+            1 = /home/john/templates
+          }
+        }
+        """
+        try:
+            import neo_cgi
+            # The following line is needed so that ClearSilver can be loaded when
+            # we are being run in multiple interpreters under mod_python
+            neo_cgi.update()
+            import neo_util
+            self.hdf = neo_util.HDF()
+        except ImportError, e:
+            raise TracError, "ClearSilver not installed (%s)" % e
+        
+        self['hdf.loadpaths'] = loadpaths
+
+    def __getattr__(self, name):
+        # For backwards compatibility, expose the interface of the underlying HDF
+        # object
+        return getattr(self.hdf, name)
+
+    def __contains__(self, name):
+        return self.hdf.getObj(str(name)) != None
+    has_key = __contains__
+
+    def get(self, name, default=None):
+        value = self.hdf.getValue(str(name), '<<NONE>>')
+        if value == '<<NONE>>':
+            return default
+        return value
+
+    def __getitem__(self, name):
+        value = self.get(name, None)
+        if value == None:
+            raise KeyError, name
+        return value
+
+    def __setitem__(self, name, value):
+        """Add data to the HDF dataset.
+        
+        The `name` parameter is the path of the node in dotted syntax. The
+        `value` parameter can be a simple value such as a string or number, but
+        also data structures such as dicts and lists.
+
+        >>> hdf = HDFWrapper()
+
+        Adding a simple value results in that value being inserted into the HDF
+        after being converted to a string.
+
+        >>> hdf['test.num'] = 42
+        >>> hdf['test.num']
+        '42'
+        >>> hdf['test.str'] = 'foo'
+        >>> hdf['test.str']
+        'foo'
+
+        The boolean literals `True` and `False` are converted to there integer
+        representation before being added:
+
+        >>> hdf['test.true'] = True
+        >>> hdf['test.true']
+        '1'
+        >>> hdf['test.false'] = False
+        >>> hdf['test.false']
+        '0'
+
+        If value is `None`, nothing is added to the HDF:
+
+        >>> hdf['test.true'] = None
+        >>> hdf['test.none']
+        Traceback (most recent call last):
+            ...
+        KeyError: 'test.none'
+        """
+        self.set_value(name, value, True)
+        
+    def set_unescaped(self, name, value):
+        """
+        Add data to the HDF dataset.
+        
+        This method works the same way as `__setitem__` except that `value`
+        is not escaped if it is a string.
+        """
+        self.set_value(name, value, False)
+        
+    def set_value(self, name, value, escape=True):
+        """
+        Add data to the HDF dataset.
+        """
+        def add_value(prefix, value):
+            if value is None:
+                return
+            elif value in (True, False):
+                self.hdf.setValue(prefix, str(int(value)))
+            elif isinstance(value, util.Markup):
+                self.hdf.setValue(prefix, value)
+            elif isinstance(value, (str, unicode)):
+                if escape:
+                    self.hdf.setValue(prefix, util.escape(value))
+                else:
+                    self.hdf.setValue(prefix, value)
+            elif isinstance(value, dict):
+                for k in value.keys():
+                    add_value('%s.%s' % (prefix, k), value[k])
+            else:
+                if hasattr(value, '__iter__') or \
+                        isinstance(value, (list, tuple)):
+                    for idx, item in enumerate(value):
+                        add_value('%s.%d' % (prefix, idx), item)
+                else:
+                    self.hdf.setValue(prefix, str(value))
+        add_value(name, value)
+
+    def __str__(self):
+        from StringIO import StringIO
+        buf = StringIO()
+        def hdf_tree_walk(node, prefix=''):
+            while node:
+                name = node.name() or ''
+                buf.write('%s%s' % (prefix, name))
+                value = node.value()
+                if value or not node.child():
+                    if value.find('\n') == -1:
+                        buf.write(' = %s' % value)
+                    else:
+                        buf.write(' = << EOM\n%s\nEOM' % value)
+                if node.child():
+                    buf.write(' {\n')
+                    hdf_tree_walk(node.child(), prefix + '  ')
+                    buf.write('%s}\n' % prefix)
+                else:
+                    buf.write('\n')
+                node = node.next()
+        hdf_tree_walk(self.hdf.child())
+        return buf.getvalue().strip()
+
+    def parse(self, string):
+        """Parse the given string as template text, and returns a neo_cs.CS
+        object.
+        """
+        import neo_cs
+        cs = neo_cs.CS(self.hdf)
+        cs.parseStr(string)
+        return cs
+
+    def render(self, template):
+        """Render the HDF using the given template.
+
+        The template parameter can be either an already parse neo_cs.CS
+        object, or a string. In the latter case it is interpreted as name of the
+        template file.
+        """
+        if isinstance(template, (str, unicode)):
+            filename = template
+            import neo_cs
+            template = neo_cs.CS(self.hdf)
+            template.parseFile(filename)
+        return template.render()
+
+
+if __name__ == '__main__':
+    import doctest, sys
+    doctest.testmod(sys.modules[__name__])
diff -urN trac-trunk/build/lib/trac/web/fcgi_frontend.py aw-trac/build/lib/trac/web/fcgi_frontend.py
--- trac-trunk/build/lib/trac/web/fcgi_frontend.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/fcgi_frontend.py	2006-03-06 03:36:02.000000000 -0800
@@ -0,0 +1,22 @@
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Matthew Good <trac@matt-good.net>
+
+from trac.web.main import dispatch_request
+
+import _fcgi
+
+def run():
+    _fcgi.WSGIServer(dispatch_request).run()
diff -urN trac-trunk/build/lib/trac/web/href.py aw-trac/build/lib/trac/web/href.py
--- trac-trunk/build/lib/trac/web/href.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/href.py	2005-12-29 02:34:53.000000000 -0800
@@ -0,0 +1,163 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2004 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+from urllib import quote, urlencode
+
+
+class Href(object):
+    """
+    Implements a callable that constructs URLs with the given base. The
+    function can be called with any number of positional and keyword
+    arguments which than are used to assemble the URL.
+
+    Positional arguments are appended as individual segments to
+    the path of the URL:
+
+    >>> href = Href('/trac')
+    >>> href('ticket', 540)
+    '/trac/ticket/540'
+    >>> href('ticket', 540, 'attachment', 'bugfix.patch')
+    '/trac/ticket/540/attachment/bugfix.patch'
+    >>> href('ticket', '540/attachment/bugfix.patch')
+    '/trac/ticket/540/attachment/bugfix.patch'
+
+    If a positional parameter evaluates to None, it will be skipped:
+
+    >>> href('ticket', 540, 'attachment')
+    '/trac/ticket/540/attachment'
+
+    The first path segment can also be specified by calling an attribute
+    of the function, as follows:
+
+    >>> href.ticket(540)
+    '/trac/ticket/540'
+    >>> href.changeset(42, format='diff')
+    '/trac/changeset/42?format=diff'
+
+    Simply calling the Href object with no arguments will return the base URL:
+
+    >>> href()
+    '/trac'
+
+    Keyword arguments are added to the query string, unless the value is None:
+
+    >>> href = Href('/trac')
+    >>> href('timeline', format='rss')
+    '/trac/timeline?format=rss'
+    >>> href('timeline', format=None)
+    '/trac/timeline'
+    >>> href('search', q='foo bar')
+    '/trac/search?q=foo+bar'
+
+    Multiple values for one parameter are specified using a sequence (a list or
+    tuple) for the parameter:
+
+    >>> href('timeline', show=['ticket', 'wiki', 'changeset'])
+    '/trac/timeline?show=ticket&show=wiki&show=changeset'
+
+    Alternatively, query string parameters can be added by passing a dict or
+    list as last positional argument:
+
+    >>> href('timeline', {'from': '02/24/05', 'daysback': 30})
+    '/trac/timeline?daysback=30&from=02%2F24%2F05'
+
+    If the order of query string parameters should be preserved, you may also
+    pass a sequence of (name, value) tuples as last positional argument:
+
+    >>> href('query', (('group', 'component'), ('groupdesc', 1)))
+    '/trac/query?group=component&groupdesc=1'
+
+    >>> params = []
+    >>> params.append(('group', 'component'))
+    >>> params.append(('groupdesc', 1))
+    >>> href('query', params)
+    '/trac/query?group=component&groupdesc=1'
+
+    By specifying an absolute base, the function returned will also generate
+    absolute URLs:
+
+    >>> href = Href('http://projects.edgewall.com/trac')
+    >>> href('ticket', 540)
+    'http://projects.edgewall.com/trac/ticket/540'
+
+    >>> href = Href('https://projects.edgewall.com/trac')
+    >>> href('ticket', 540)
+    'https://projects.edgewall.com/trac/ticket/540'
+
+    Finally, the first path segment of the URL to generate can be specified in
+    the following way, mainly to improve readability:
+
+    >>> href = Href('/trac')
+    >>> href.ticket(540)
+    '/trac/ticket/540'
+    >>> href.browser('/trunk/README.txt', format='txt')
+    '/trac/browser/trunk/README.txt?format=txt'
+    """
+
+    def __init__(self, base):
+        self.base = base
+        self._derived = {}
+
+    def __call__(self, *args, **kw):
+        href = self.base
+        if href and href[-1] == '/':
+            href = href[:-1]
+        params = []
+
+        def add_param(name, value):
+            if type(value) in (list, tuple):
+                for i in [i for i in value if i != None]:
+                    params.append((name, i))
+            elif v != None:
+                params.append((name, value))
+
+        if args:
+            lastp = args[-1]
+            if lastp and type(lastp) is dict:
+                for k,v in lastp.items():
+                    add_param(k, v)
+                args = args[:-1]
+            elif lastp and type(lastp) in (list, tuple):
+                for k,v in lastp:
+                    add_param(k, v)
+                args = args[:-1]
+
+        # build the path
+        path = '/'.join([quote(str(arg).strip('/')) for arg in args
+                         if arg != None])
+        if path:
+            href += '/' + path
+
+        # assemble the query string
+        for k,v in kw.items():
+            add_param(k, v)
+
+        if params:
+            href += '?' + urlencode(params)
+
+        return href
+
+    def __getattr__(self, name):
+        if not self._derived.has_key(name):
+            self._derived[name] = lambda *args, **kw: self(name, *args, **kw)
+        return self._derived[name]
+
+
+if __name__ == '__main__':
+    import doctest, sys
+    doctest.testmod(sys.modules[__name__])
diff -urN trac-trunk/build/lib/trac/web/main.py aw-trac/build/lib/trac/web/main.py
--- trac-trunk/build/lib/trac/web/main.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/main.py	2006-03-07 14:08:56.000000000 -0800
@@ -0,0 +1,398 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+#         Matthew Good <trac@matt-good.net>
+
+import locale
+import os
+import sys
+import dircache
+
+from trac.core import *
+from trac.env import open_environment
+from trac.perm import PermissionCache, PermissionError
+from trac.util import format_datetime, http_date, Markup
+from trac.web.api import *
+from trac.web.chrome import Chrome
+from trac.web.clearsilver import HDFWrapper
+from trac.web.href import Href
+from trac.web.session import Session
+
+# Environment cache for multithreaded front-ends:
+try:
+    import threading
+except ImportError:
+    import dummy_threading as threading
+
+env_cache = {}
+env_cache_lock = threading.Lock()
+
+def _open_environment(env_path, run_once=False):
+    if run_once:
+        return open_environment(env_path)
+
+    global env_cache, env_cache_lock
+    env = None
+    env_cache_lock.acquire()
+    try:
+        if not env_path in env_cache:
+            env_cache[env_path] = open_environment(env_path)
+        env = env_cache[env_path]
+    finally:
+        env_cache_lock.release()
+
+    # Re-parse the configuration file if it changed since the last the time it
+    # was parsed
+    env.config.parse_if_needed()
+
+    return env
+
+def populate_hdf(hdf, env, req=None):
+    """Populate the HDF data set with various information, such as common URLs,
+    project information and request-related information.
+    """
+    from trac import __version__
+    hdf['trac'] = {
+        'version': __version__,
+        'time': format_datetime(),
+        'time.gmt': http_date()
+    }
+    hdf['trac.href'] = {
+        'wiki': env.href.wiki(),
+        'browser': env.href.browser('/'),
+        'timeline': env.href.timeline(),
+        'roadmap': env.href.roadmap(),
+        'milestone': env.href.milestone(None),
+        'report': env.href.report(),
+        'query': env.href.query(),
+        'newticket': env.href.newticket(),
+        'search': env.href.search(),
+        'about': env.href.about(),
+        'about_config': env.href.about('config'),
+        'login': env.href.login(),
+        'logout': env.href.logout(),
+        'settings': env.href.settings(),
+        'homepage': 'http://trac.edgewall.com/'
+    }
+
+    hdf['project'] = {
+        'name': env.config.get('project', 'name'),
+        'name_encoded': env.config.get('project', 'name'),
+        'descr': env.config.get('project', 'descr'),
+        'footer': Markup(env.config.get('project', 'footer')),
+        'url': env.config.get('project', 'url')
+    }
+
+    if req:
+        hdf['base_url'] = req.base_url
+        hdf['base_host'] = req.base_url[:req.base_url.rfind(req.base_path)]
+        hdf['cgi_location'] = req.base_path
+        hdf['trac.authname'] = req.authname
+
+        for action in req.perm.permissions():
+            req.hdf['trac.acl.' + action] = True
+
+        for arg in [k for k in req.args.keys() if k]:
+            if isinstance(req.args[arg], (list, tuple)):
+                hdf['args.%s' % arg] = [v for v in req.args[arg]]
+            elif isinstance(req.args[arg], basestring):
+                hdf['args.%s' % arg] = req.args[arg]
+            # others are file uploads
+
+
+class RequestDispatcher(Component):
+    """Component responsible for dispatching requests to registered handlers."""
+
+    authenticators = ExtensionPoint(IAuthenticator)
+    handlers = ExtensionPoint(IRequestHandler)
+    default_handler = SingletonExtensionPoint(IRequestHandler,
+                                              'trac', 'default_handler')
+
+    def authenticate(self, req):
+        for authenticator in self.authenticators:
+            authname = authenticator.authenticate(req)
+            if authname:
+                return authname
+        else:
+            return 'anonymous'
+
+    def dispatch(self, req):
+        """Find a registered handler that matches the request and let it process
+        it.
+        
+        In addition, this method initializes the HDF data set and adds the web
+        site chrome.
+        """
+        # For backwards compatibility, should be removed in the future
+        self.env.href = req.href
+        self.env.abs_href = req.abs_href
+
+        req.authname = self.authenticate(req)
+        req.perm = PermissionCache(self.env, req.authname)
+
+        chrome = Chrome(self.env)
+        req.hdf = HDFWrapper(loadpaths=chrome.get_all_templates_dirs())
+        populate_hdf(req.hdf, self.env, req)
+
+        req.session = Session(self.env, req)
+
+        # Select the component that should handle the request
+        chosen_handler = None
+        if not req.path_info or req.path_info == '/':
+            chosen_handler = self.default_handler
+        else:
+            for handler in self.handlers:
+                if handler.match_request(req):
+                    chosen_handler = handler
+                    break
+
+        chrome.populate_hdf(req, chosen_handler)
+
+        if not chosen_handler:
+            raise HTTPNotFound('No handler matched request to %s',
+                               req.path_info)
+
+        try:
+            try:
+                resp = chosen_handler.process_request(req)
+                if resp:
+                    template, content_type = resp
+                    if not content_type:
+                        content_type = 'text/html'
+
+                    req.display(template, content_type or 'text/html')
+            except PermissionError, e:
+                raise HTTPForbidden(str(e))
+            except TracError, e:
+                raise HTTPInternalError(str(e))
+        finally:
+            # Give the session a chance to persist changes
+            req.session.save()
+
+
+def dispatch_request(environ, start_response):
+    """Main entry point for the Trac web interface.
+    
+    @param environ: the WSGI environment dict
+    @param start_response: the WSGI callback for starting the response
+    """
+    if 'mod_python.options' in environ:
+        options = environ['mod_python.options']
+        environ.setdefault('trac.env_path', options.get('TracEnv'))
+        environ.setdefault('trac.env_parent_dir',
+                           options.get('TracEnvParentDir'))
+        environ.setdefault('trac.env_index_template',
+                           options.get('TracEnvIndexTemplate'))
+        environ.setdefault('trac.template_vars',
+                           options.get('TracTemplateVars'))
+        environ.setdefault('trac.locale', options.get('TracLocale'))
+
+        if 'TracUriRoot' in options:
+            # Special handling of SCRIPT_NAME/PATH_INFO for mod_python, which
+            # tends to get confused for whatever reason
+            root_uri = options['TracUriRoot'].rstrip('/')
+            request_uri = environ['REQUEST_URI'].split('?', 1)[0]
+            if not request_uri.startswith(root_uri):
+                raise ValueError('TracUriRoot set to %s but request URL '
+                                 'is %s' % (root_uri, request_uri))
+            environ['SCRIPT_NAME'] = root_uri
+            environ['PATH_INFO'] = request_uri[len(root_uri):]
+
+    else:
+        environ.setdefault('trac.env_path', os.getenv('TRAC_ENV'))
+        environ.setdefault('trac.env_parent_dir',
+                           os.getenv('TRAC_ENV_PARENT_DIR'))
+        environ.setdefault('trac.env_index_template',
+                           os.getenv('TRAC_ENV_INDEX_TEMPLATE'))
+        environ.setdefault('trac.template_vars',
+                           os.getenv('TRAC_TEMPLATE_VARS'))
+        environ.setdefault('trac.locale', '')
+
+    locale.setlocale(locale.LC_ALL, environ['trac.locale'])
+
+    # Allow specifying the python eggs cache directory using SetEnv
+    if 'mod_python.subprocess_env' in environ:
+        egg_cache = environ['mod_python.subprocess_env'].get('PYTHON_EGG_CACHE')
+        if egg_cache:
+            os.environ['PYTHON_EGG_CACHE'] = egg_cache
+
+    # Determine the environment
+    env_path = environ.get('trac.env_path')
+    if not env_path:
+        env_parent_dir = environ.get('trac.env_parent_dir')
+        env_paths = environ.get('trac.env_paths')
+        if env_parent_dir or env_paths:
+            # The first component of the path is the base name of the
+            # environment
+            path_info = environ.get('PATH_INFO', '').lstrip('/').split('/')
+            env_name = path_info.pop(0)
+
+            if not env_name:
+                # No specific environment requested, so render an environment
+                # index page
+                send_project_index(environ, start_response, env_parent_dir,
+                                   env_paths)
+                return []
+
+            # To make the matching patterns of request handlers work, we append
+            # the environment name to the `SCRIPT_NAME` variable, and keep only
+            # the remaining path in the `PATH_INFO` variable.
+            environ['SCRIPT_NAME'] = Href(environ['SCRIPT_NAME'])(env_name)
+            environ['PATH_INFO'] = '/'.join([''] + path_info)
+
+            if env_parent_dir:
+                env_path = os.path.join(env_parent_dir, env_name)
+            else:
+                env_path = get_environments(environ).get(env_name)
+
+            if not env_path or not os.path.isdir(env_path):
+                start_response('404 Not Found', [])
+                return ['Environment not found']
+
+    if not env_path:
+        raise EnvironmentError('The environment options "TRAC_ENV" or '
+                               '"TRAC_ENV_PARENT_DIR" or the mod_python '
+                               'options "TracEnv" or "TracEnvParentDir" are '
+                               'missing. Trac requires one of these options '
+                               'to locate the Trac environment(s).')
+    env = _open_environment(env_path, run_once=environ['wsgi.run_once'])
+
+    base_url = env.config.get('trac', 'base_url')
+    if base_url:
+        environ['trac.base_url'] = base_url
+
+    req = Request(environ, start_response)
+    try:
+        db = env.get_db_cnx()
+        try:
+            try:
+                dispatcher = RequestDispatcher(env)
+                dispatcher.dispatch(req)
+            except RequestDone:
+                pass
+            return req._response or []
+        finally:
+            db.close()
+
+    except HTTPException, e:
+        env.log.warn(e)
+        if req.hdf:
+            req.hdf['title'] = e.reason or 'Error'
+            req.hdf['error'] = {
+                'title': e.reason or 'Error',
+                'type': 'TracError',
+                'message': e.message
+            }
+        try:
+            req.send_error(sys.exc_info(), status=e.code)
+        except RequestDone:
+            return []
+
+    except Exception, e:
+        env.log.exception(e)
+
+        import traceback
+        from StringIO import StringIO
+        tb = StringIO()
+        traceback.print_exc(file=tb)
+
+        if req.hdf:
+            req.hdf['title'] = str(e) or 'Error'
+            req.hdf['error'] = {
+                'title': str(e) or 'Error',
+                'type': 'internal',
+                'traceback': tb.getvalue()
+            }
+        try:
+            req.send_error(sys.exc_info(), status=500)
+        except RequestDone:
+            return []
+
+def send_project_index(environ, start_response, parent_dir=None,
+                       env_paths=None):
+    from trac.config import default_dir
+    from trac.web.clearsilver import HDFWrapper
+
+    req = Request(environ, start_response)
+
+    loadpaths = [default_dir('templates')]
+    if req.environ.get('trac.env_index_template'):
+        tmpl_path, template = os.path.split(req.environ['trac.env_index_template'])
+        loadpaths.insert(0, tmpl_path)
+    else:
+        template = 'index.cs'
+    req.hdf = HDFWrapper(loadpaths=[default_dir('templates')])
+
+    tmpl_vars = {}
+    if req.environ.get('trac.template_vars'):
+        for pair in req.environ['trac.template_vars'].split(','):
+            key, val = pair.split('=')
+            req.hdf[key] = val
+
+    if parent_dir and not env_paths:
+        env_paths = dict([(filename, os.path.join(parent_dir, filename))
+                          for filename in os.listdir(parent_dir)])
+
+    try:
+        href = Href(req.base_path)
+        projects = []
+        for env_name, env_path in get_environments(environ).items():
+            try:
+                env = _open_environment(env_path,
+                                        run_once=environ['wsgi.run_once'])
+                proj = {
+                    'name': env.config.get('project', 'name'),
+                    'description': env.config.get('project', 'descr'),
+                    'href': href(env_name)
+                }
+            except Exception, e:
+                proj = {'name': env_name, 'description': str(e)}
+            projects.append(proj)
+        projects.sort(lambda x, y: cmp(x['name'].lower(), y['name'].lower()))
+
+        req.hdf['projects'] = projects
+        req.display(template)
+    except RequestDone:
+        pass
+
+def get_environments(environ, warn=False):
+    """Retrieve canonical environment name to path mapping.
+
+    The environments may not be all valid environments, but they are good
+    candidates.
+    """
+    env_paths = environ.get('trac.env_paths', [])
+    env_parent_dir = environ.get('trac.env_parent_dir')
+    if env_parent_dir:
+        env_parent_dir = os.path.normpath(env_parent_dir)
+        paths = dircache.listdir(env_parent_dir)[:]
+        dircache.annotate(env_parent_dir, paths)
+        env_paths += [os.path.join(env_parent_dir, project) \
+                      for project in paths if project[-1] == '/']
+    envs = {}
+    for env_path in env_paths:
+        env_path = os.path.normpath(env_path)
+        if not os.path.isdir(env_path):
+            continue
+        env_name = os.path.split(env_path)[1]
+        if env_name in envs:
+            if warn:
+                print >> sys.stderr, ('Warning: Ignoring project "%s" since '
+                                      'it conflicts with project "%s"'
+                                      % (env_path, envs[env_name]))
+        else:
+            envs[env_name] = env_path
+    return envs
diff -urN trac-trunk/build/lib/trac/web/modpython_frontend.py aw-trac/build/lib/trac/web/modpython_frontend.py
--- trac-trunk/build/lib/trac/web/modpython_frontend.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/modpython_frontend.py	2006-03-07 14:08:56.000000000 -0800
@@ -0,0 +1,87 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2005 Edgewall Software
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+#         Matthew Good <trac@matt-good.net>
+
+from mod_python import apache
+
+from trac.web.main import dispatch_request
+from trac.web.wsgi import WSGIGateway, _ErrorsWrapper
+
+
+class InputWrapper(object):
+
+    def __init__(self, req):
+        self.req = req
+
+    def close(self):
+        pass
+
+    def read(self, size=-1):
+        return self.req.read(size)
+
+    def readline(self):
+        return self.req.readline()
+
+    def readlines(self, hint=-1):
+        return self.req.readlines(hint)
+
+
+class ModPythonGateway(WSGIGateway):
+
+    wsgi_multithread = apache.mpm_query(apache.AP_MPMQ_IS_THREADED) > 0
+    wsgi_multiprocess = apache.mpm_query(apache.AP_MPMQ_IS_FORKED) > 0
+
+    def __init__(self, req, options):
+        environ = {}
+        environ.update(apache.build_cgi_env(req))
+        environ['mod_python.options'] = options
+        environ['mod_python.subprocess_env'] = req.subprocess_env
+        WSGIGateway.__init__(self, environ, InputWrapper(req),
+                             _ErrorsWrapper(lambda x: req.log_error(x)))
+        self.req = req
+
+    def _send_headers(self):
+        assert self.headers_set, 'Response not started'
+
+        if not self.headers_sent:
+            status, headers = self.headers_sent = self.headers_set
+            self.req.status = int(status[:3])
+            for name, value in headers:
+                if name.lower() == 'content-length':
+                    self.req.set_content_length(int(value))
+                elif name.lower() == 'content-type':
+                    self.req.content_type = value
+                else:
+                    self.req.headers_out.add(name, value)
+
+    def _sendfile(self, fileobj):
+        self._send_headers()
+        self.req.sendfile(fileobj.name)
+
+    def _write(self, data):
+        self._send_headers()
+        try:
+            self.req.write(data)
+        except IOError, e:
+            if 'client closed connection' not in e.strerror:
+                raise
+
+def handler(req):
+    options = req.get_options()
+    gateway = ModPythonGateway(req, options)
+    gateway.run(dispatch_request)
+    return apache.OK
diff -urN trac-trunk/build/lib/trac/web/session.py aw-trac/build/lib/trac/web/session.py
--- trac-trunk/build/lib/trac/web/session.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/session.py	2006-03-07 14:08:56.000000000 -0800
@@ -0,0 +1,190 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2004-2005 Edgewall Software
+# Copyright (C) 2004 Daniel Lundin <daniel@edgewall.com>
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Daniel Lundin <daniel@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import time
+
+from trac.core import TracError
+from trac.util import hex_entropy, Markup
+
+UPDATE_INTERVAL = 3600*24 # Update session last_visit time stamp after 1 day
+PURGE_AGE = 3600*24*90 # Purge session after 90 days idle
+COOKIE_KEY = 'trac_session'
+
+
+class Session(dict):
+    """Basic session handling and per-session storage."""
+
+    def __init__(self, env, req):
+        dict.__init__(self)
+        self.env = env
+        self.req = req
+        self.sid = None
+        self._old = {}
+        if req.authname == 'anonymous':
+            if not req.incookie.has_key(COOKIE_KEY):
+                self.sid = hex_entropy(24)
+                self.bake_cookie()
+            else:
+                sid = req.incookie[COOKIE_KEY].value
+                self.get_session(sid)
+        else:
+            if req.incookie.has_key(COOKIE_KEY):
+                sid = req.incookie[COOKIE_KEY].value
+                self.promote_session(sid)
+            self.get_session(req.authname, authenticated=True)
+
+    def bake_cookie(self, expires=PURGE_AGE):
+        assert self.sid, 'Session ID not set'
+        self.req.outcookie[COOKIE_KEY] = self.sid
+        self.req.outcookie[COOKIE_KEY]['path'] = self.req.base_path
+        self.req.outcookie[COOKIE_KEY]['expires'] = expires
+
+    def get_session(self, sid, authenticated=False):
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        self.sid = sid
+        cursor.execute("SELECT var_name,var_value FROM session "
+                       "WHERE sid=%s AND authenticated=%s",
+                       (sid, int(authenticated)))
+        for name, value in cursor:
+            self[name] = value
+        self._old.update(self)
+
+        # Refresh the session cookie if this is the first visit since over a day
+        if not authenticated and self.has_key('last_visit'):
+            if time.time() - int(self['last_visit']) > UPDATE_INTERVAL:
+                self.bake_cookie()
+
+    def change_sid(self, new_sid):
+        assert self.req.authname == 'anonymous', \
+               'Cannot change ID of authenticated session'
+        assert new_sid, 'Session ID cannot be empty'
+        if new_sid == self.sid:
+            return
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT sid FROM session WHERE sid=%s "
+                       "AND authenticated=0", (new_sid,))
+        if cursor.fetchone():
+            raise TracError(Markup('Session "%s" already exists.<br />'
+                                   'Please choose a different session ID.',
+                                   new_sid), 'Error renaming session')
+        self.env.log.debug('Changing session ID %s to %s' % (self.sid, new_sid))
+        cursor.execute("UPDATE session SET sid=%s WHERE sid=%s "
+                       "AND authenticated=0", (new_sid, self.sid))
+        db.commit()
+        self.sid = new_sid
+        self.bake_cookie()
+
+    def promote_session(self, sid):
+        """Promotes an anonymous session to an authenticated session, if there
+        is no preexisting session data for that user name.
+        """
+        assert self.req.authname != 'anonymous', \
+               'Cannot promote session of anonymous user'
+
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT COUNT(*) FROM session WHERE sid=%s "
+                       "AND authenticated=1", (self.req.authname,))
+        if cursor.fetchone()[0]:
+            # If there's already an authenticated session for the user, we
+            # simply delete the anonymous session
+            cursor.execute("DELETE FROM session WHERE sid=%s "
+                           "AND authenticated=0", (sid,))
+        else:
+            # Otherwise, update the session records so that the session ID is
+            # the user name, and the authenticated flag is set
+            self.env.log.debug('Promoting anonymous session %s to '
+                               'authenticated session for user %s', sid,
+                               self.req.authname)
+            cursor.execute("UPDATE session SET sid=%s,authenticated=1 "
+                           "WHERE sid=%s AND authenticated=0",
+                           (self.req.authname, sid))
+        db.commit()
+
+        self.sid = sid
+        self.bake_cookie(0) # expire the cookie
+
+    def save(self):
+        if not self._old and not self.items():
+            # The session doesn't have associated data, so there's no need to
+            # persist it
+            return
+
+        changed = False
+        now = int(time.time())
+
+        if self.req.authname == 'anonymous':
+            # Update the session last visit time if it is over an hour old,
+            # so that session doesn't get purged
+            last_visit = int(self.get('last_visit', 0))
+            if now - last_visit > UPDATE_INTERVAL:
+                self.env.log.info("Refreshing session %s" % self.sid)
+                self['last_visit'] = now
+
+            # If the only data in the session is the last_visit time, it makes
+            # no sense to keep the session around
+            if len(self.items()) == 1:
+                del self['last_visit']
+
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        authenticated = int(self.req.authname != 'anonymous')
+
+        # Find all new or modified session variables and persist their values to
+        # the database
+        for k,v in self.items():
+            if not self._old.has_key(k):
+                self.env.log.debug('Adding variable %s with value "%s" to '
+                                   'session %s' % (k, v,
+                                   self.sid or self.req.authname))
+                cursor.execute("INSERT INTO session VALUES(%s,%s,%s,%s)",
+                               (self.sid, authenticated, k, v))
+                changed = True
+            elif v != self._old[k]:
+                self.env.log.debug('Changing variable %s from "%s" to "%s" in '
+                                   'session %s' % (k, self._old[k], v,
+                                   self.sid))
+                cursor.execute("UPDATE session SET var_value=%s "
+                               "WHERE sid=%s AND authenticated=%s "
+                               "AND var_name=%s", (v, self.sid, authenticated,
+                               k))
+                changed = True
+
+        # Find all variables that have been deleted and also remove them from
+        # the database
+        for k in [k for k in self._old.keys() if not self.has_key(k)]:
+            self.env.log.debug('Deleting variable %s from session %s'
+                               % (k, self.sid or self.req.authname))
+            cursor.execute("DELETE FROM session WHERE sid=%s AND "
+                           "authenticated=%s AND var_name=%s",
+                           (self.sid, authenticated, k))
+            changed = True
+
+        if changed:
+            # Purge expired sessions. We do this only when the session was
+            # changed as to minimize the purging.
+            mintime = now - PURGE_AGE
+            self.env.log.debug('Purging old, expired, sessions.')
+            cursor.execute("DELETE FROM session WHERE authenticated=0 AND "
+                           "sid IN (SELECT sid FROM session WHERE "
+                           "var_name='last_visit' AND var_value < %s)",
+                           (mintime,))
+
+            db.commit()
diff -urN trac-trunk/build/lib/trac/web/standalone.py aw-trac/build/lib/trac/web/standalone.py
--- trac-trunk/build/lib/trac/web/standalone.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/standalone.py	2006-03-06 16:13:58.000000000 -0800
@@ -0,0 +1,309 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Matthew Good <trac@matt-good.net>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+try:
+    from base64 import b64decode
+except ImportError:
+    from base64 import decodestring as b64decode
+import md5
+import os
+import sys
+import urllib2
+from SocketServer import ThreadingMixIn
+
+from trac import util, __version__
+from trac.util import md5crypt
+from trac.web.main import dispatch_request
+from trac.web.wsgi import WSGIServer, WSGIRequestHandler
+
+
+class BasicAuth(object):
+
+    def __init__(self, htpasswd, realm):
+        self.hash = {}
+        self.realm = realm
+        try:
+            import crypt
+            self.crypt = crypt.crypt
+        except ImportError:
+            self.crypt = None
+        self.load(htpasswd)
+
+    def load(self, filename):
+        fd = open(filename, 'r')
+        for line in fd:
+            u, h = line.strip().split(':')
+            if '$' in h or self.crypt:
+                self.hash[u] = h
+            else:
+                print >>sys.stderr, 'Warning: cannot parse password for ' \
+                                    'user "%s" without the "crypt" module' % u
+
+        if self.hash == {}:
+            print >> sys.stderr, "Warning: found no users in file:", filename
+
+    def test(self, user, password):
+        the_hash = self.hash.get(user)
+        if the_hash is None:
+            return False
+
+        if not '$' in the_hash:
+            return self.crypt(password, the_hash[:2]) == the_hash
+
+        magic, salt = the_hash[1:].split('$')[:2]
+        magic = '$' + magic + '$'
+        return md5crypt(password, salt, magic) == the_hash
+
+    def send_auth_request(self, req):
+        req.send_response(401)
+        req.send_header('WWW-Authenticate', 'Basic realm="%s"' % self.realm)
+        req.end_headers()
+
+    def do_auth(self, req):
+        if not 'Authorization' in req.headers or \
+               not req.headers['Authorization'].startswith('Basic'):
+            self.send_auth_request(req)
+            return None
+
+        auth = req.headers['Authorization'][len('Basic')+1:]
+        auth = b64decode(auth).split(':')
+        if len(auth) != 2:
+            self.send_auth_request(req)
+            return None
+
+        user, password = auth
+        if not self.test(user, password):
+            self.send_auth_request(req)
+            return None
+
+        return user
+
+
+class DigestAuth(object):
+    """A simple HTTP DigestAuth implementation (rfc2617)"""
+
+    MAX_NONCES = 100
+
+    def __init__(self, htdigest, realm):
+        self.active_nonces = []
+        self.hash = {}
+        self.realm = realm
+        self.load_htdigest(htdigest, realm)
+
+    def load_htdigest(self, filename, realm):
+        """Load account information from apache style htdigest files, only
+        users from the specified realm are used
+        """
+        fd = open(filename, 'r')
+        for line in fd.readlines():
+            u, r, a1 = line.strip().split(':')
+            if r == realm:
+                self.hash[u] = a1
+        if self.hash == {}:
+            print >> sys.stderr, "Warning: found no users in realm:", realm
+        
+    def parse_auth_header(self, authorization):
+        values = {}
+        for value in urllib2.parse_http_list(authorization):
+            n, v = value.split('=', 1)
+            if v[0] == '"' and v[-1] == '"':
+                values[n] = v[1:-1]
+            else:
+                values[n] = v
+        return values
+
+    def send_auth_request(self, req, stale='false'):
+        """Send a digest challange to the browser. Record used nonces
+        to avoid replay attacks.
+        """
+        nonce = util.hex_entropy()
+        self.active_nonces.append(nonce)
+        if len(self.active_nonces) > DigestAuth.MAX_NONCES:
+            self.active_nonces = self.active_nonces[-DigestAuth.MAX_NONCES:]
+        req.send_response(401)
+        req.send_header('WWW-Authenticate',
+                        'Digest realm="%s", nonce="%s", qop="auth", stale="%s"'
+                        % (self.realm, nonce, stale))
+        req.end_headers()
+
+    def do_auth(self, req):
+        if not 'Authorization' in req.headers or \
+               not req.headers['Authorization'].startswith('Digest'):
+            self.send_auth_request(req)
+            return None
+        auth = self.parse_auth_header(req.headers['Authorization'][7:])
+        required_keys = ['username', 'realm', 'nonce', 'uri', 'response',
+                           'nc', 'cnonce']
+        # Invalid response?
+        for key in required_keys:
+            if not auth.has_key(key):
+                self.send_auth_request(req)
+                return None
+        # Unknown user?
+        if not self.hash.has_key(auth['username']):
+            self.send_auth_request(req)
+            return None
+
+        kd = lambda x: md5.md5(':'.join(x)).hexdigest()
+        a1 = self.hash[auth['username']]
+        a2 = kd([req.command, auth['uri']])
+        # Is the response correct?
+        correct = kd([a1, auth['nonce'], auth['nc'],
+                      auth['cnonce'], auth['qop'], a2])
+        if auth['response'] != correct:
+            self.send_auth_request(req)
+            return None
+        # Is the nonce active, if not ask the client to use a new one
+        if not auth['nonce'] in self.active_nonces:
+            self.send_auth_request(req, stale='true')
+            return None
+        self.active_nonces.remove(auth['nonce'])
+        return auth['username']
+
+
+class TracHTTPServer(ThreadingMixIn, WSGIServer):
+
+    def __init__(self, server_address, env_parent_dir, env_paths, auths):
+        WSGIServer.__init__(self, server_address, dispatch_request,
+                            request_handler=TracHTTPRequestHandler)
+        self.environ['trac.env_path'] = None
+        if env_parent_dir:
+            self.environ['trac.env_parent_dir'] = env_parent_dir
+        else:
+            self.environ['trac.env_paths'] = env_paths
+        self.auths = auths
+
+
+class TracHTTPRequestHandler(WSGIRequestHandler):
+
+    server_version = 'tracd/' + __version__
+
+    def handle_one_request(self):
+        environ = self.setup_environ()
+        path_info = environ.get('PATH_INFO', '')
+        path_parts = filter(None, path_info.split('/'))
+        if len(path_parts) > 1 and path_parts[1] == 'login':
+            env_name = path_parts[0]
+            if env_name:
+                auth = self.server.auths.get(env_name,
+                                             self.server.auths.get('*'))
+                if not auth:
+                    self.send_error(500, 'Authentication not enabled for %s. '
+                                         'Please use the tracd --auth option.'
+                                         % env_name)
+                    return
+                remote_user = auth.do_auth(self)
+                if not remote_user:
+                    return
+                environ['REMOTE_USER'] = remote_user
+
+        gateway = self.server.gateway(self, environ)
+        gateway.run(self.server.application)
+
+
+def daemonize(stdin='/dev/null', stdout='/dev/null', stderr='/dev/null'):
+    """Fork a daemon process (taken from the Python Cookbook)."""
+    # perform first fork
+    pid = os.fork()
+    if pid > 0:
+        sys.exit(0) # edit first parent
+
+    # decouple from parent environment
+    os.chdir('/')
+    os.umask(0)
+    os.setsid()
+
+    # perform second fork
+    pid = os.fork()
+    if pid > 0:
+        sys.exit(0) # edit first parent
+
+    # the projess is now daemonized, redirect standard file descriptors
+    for fileobj in sys.stdout, sys.stderr:
+        fileobj.flush()
+    stdin = file(stdin, 'r')
+    stdout = file(stdout, 'a+')
+    stderr = file(stderr, 'a+', 0)
+    os.dup2(stdin.fileno(), sys.stdin.fileno())
+    os.dup2(stdout.fileno(), sys.stdout.fileno())
+    os.dup2(stderr.fileno(), sys.stderr.fileno())
+
+def main():
+    from optparse import OptionParser
+    parser = OptionParser(usage='usage: %prog [options] [projenv] ...',
+                          version='%%prog %s' % __version__)
+
+    auths = {}
+    def _auth_callback(option, opt_str, value, parser, auths, cls):
+        info = value.split(',', 3)
+        if len(info) != 3:
+            usage()
+        env_name, filename, realm = info
+        if env_name in auths:
+            print >>sys.stderr, 'Ignoring duplicate authentication option for ' \
+                                'project: %s' % env_name
+        else:
+            auths[env_name] = cls(filename, realm)
+
+    parser.add_option('-a', '--auth', action='callback', type='string',
+                      metavar='DIGESTAUTH',
+                      callback=_auth_callback, callback_args=(auths, DigestAuth),
+                      help='[project],[htdigest_file],[realm]')
+    parser.add_option('--basic-auth', action='callback', type='string',
+                      metavar='BASICAUTH',
+                      callback=_auth_callback, callback_args=(auths, BasicAuth),
+                      help='[project],[htpasswd_file],[realm]')
+
+    parser.add_option('-p', '--port', action='store', type='int', dest='port',
+                      help='the port number to bind to')
+    parser.add_option('-b', '--hostname', action='store', dest='hostname',
+                      help='the host name or IP address to bind to')
+    parser.add_option('-e', '--env-parent-dir', action='store',
+                      dest='env_parent_dir', metavar='PARENTDIR',
+                      help='parent directory of the project environments')
+
+    if os.name == 'posix':
+        parser.add_option('-d', '--daemonize', action='store_true',
+                          dest='daemonize',
+                          help='run in the background as a daemon')
+
+    parser.set_defaults(port=80, hostname='', daemonize=False)
+    options, args = parser.parse_args()
+
+    if not args and not options.env_parent_dir:
+        parser.error('either the --env_parent_dir option or at least one '
+                     'environment must be specified')
+
+    server_address = (options.hostname, options.port)
+    httpd = TracHTTPServer(server_address, options.env_parent_dir, args, auths)
+
+    try:
+        if options.daemonize:
+            daemonize()
+
+        httpd.serve_forever()
+
+    except OSError:
+        sys.exit(1)
+    except KeyboardInterrupt:
+        pass
+
+if __name__ == '__main__':
+    main()
diff -urN trac-trunk/build/lib/trac/web/wsgi.py aw-trac/build/lib/trac/web/wsgi.py
--- trac-trunk/build/lib/trac/web/wsgi.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/web/wsgi.py	2006-03-06 03:36:02.000000000 -0800
@@ -0,0 +1,216 @@
+# -*- coding: iso8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+import sys
+from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler
+from SocketServer import ForkingMixIn, ThreadingMixIn
+import urllib
+
+
+class _ErrorsWrapper(object):
+
+    def __init__(self, logfunc):
+        self.logfunc = logfunc
+
+    def flush(self):
+        pass
+
+    def write(self, msg):
+        self.logfunc(msg)
+
+    def writelines(self, seq):
+        map(self.write, seq)
+
+
+class _FileWrapper(object):
+    """Wrapper for sending a file as response."""
+
+    def __init__(self, fileobj, blocksize=None):
+        self.fileobj = fileobj
+        self.blocksize = blocksize
+        self.read = self.fileobj.read
+        if hasattr(fileobj, 'close'):
+            self.close = fileobj.close
+
+    def __iter__(self):
+        return self
+
+    def next(self):
+        data = self.fileobj.read(self.blocksize)
+        if not data:
+            raise StopIteration
+        return data
+
+
+class WSGIGateway(object):
+    """Abstract base class for WSGI servers or gateways."""
+
+    wsgi_version = (1, 0)
+    wsgi_multithread = True
+    wsgi_multiprocess = True
+    wsgi_run_once = False
+    wsgi_file_wrapper = _FileWrapper
+
+    def __init__(self, environ, stdin=sys.stdin, stderr=sys.stderr):
+        """Initialize the gateway object."""
+        environ['wsgi.version'] = self.wsgi_version
+        environ['wsgi.url_scheme'] = 'http'
+        if environ.get('HTTPS', '').lower() in ('yes', 'on', '1'):
+            environ['wsgi.url_scheme'] = 'https'
+        environ['wsgi.input'] = stdin
+        environ['wsgi.errors'] = stderr
+        environ['wsgi.multithread'] = self.wsgi_multithread
+        environ['wsgi.multiprocess'] = self.wsgi_multiprocess
+        environ['wsgi.run_once'] = self.wsgi_run_once
+        if self.wsgi_file_wrapper is not None:
+            environ['wsgi.file_wrapper'] = self.wsgi_file_wrapper
+        self.environ = environ
+
+        self.headers_set = []
+        self.headers_sent = []
+
+    def run(self, application):
+        """Start the gateway with the given WSGI application."""
+        response = application(self.environ, self._start_response)
+        try:
+            if isinstance(response, self.wsgi_file_wrapper) \
+                    and hasattr(self, '_sendfile'):
+                self._sendfile(response.fileobj)
+            else:
+                for chunk in response:
+                    if chunk:
+                        self._write(chunk)
+                if not self.headers_sent:
+                    self._write('')
+        finally:
+            if hasattr(response, 'close'):
+                response.close()
+
+    def _start_response(self, status, headers, exc_info=None):
+        """Callback for starting a HTTP response."""
+        if exc_info:
+            try:
+                if self.headers_sent: # Re-raise original exception
+                    raise exc_info[0], exc_info[1], exc_info[2]
+            finally:
+                exc_info = None # avoid dangling circular ref
+        else:
+            assert not self.headers_set, 'Response already started'
+
+        self.headers_set = [status, headers]
+        return self._write
+
+    def _write(self, data):
+        """Callback for writing data to the response.
+        
+        Concrete subclasses must implement this method."""
+        raise NotImplementedError
+
+
+class WSGIRequestHandler(BaseHTTPRequestHandler):
+
+    def setup_environ(self):
+        self.raw_requestline = self.rfile.readline()
+        if not self.parse_request(): # An error code has been sent, just exit
+            self.close_connection = 1
+            return
+
+        environ = self.server.environ.copy()
+        environ['SERVER_PROTOCOL'] = self.request_version
+        environ['REQUEST_METHOD'] = self.command
+
+        if '?' in self.path:
+            path_info, query_string = self.path.split('?', 1)
+        else:
+            path_info, query_string = self.path, ''
+        environ['PATH_INFO'] = urllib.unquote(path_info)
+        environ['QUERY_STRING'] = query_string
+
+        host = self.address_string()
+        if host != self.client_address[0]:
+            environ['REMOTE_HOST'] = host
+        environ['REMOTE_ADDR'] = self.client_address[0]
+
+        if self.headers.typeheader is None:
+            environ['CONTENT_TYPE'] = self.headers.type
+        else:
+            environ['CONTENT_TYPE'] = self.headers.typeheader
+
+        length = self.headers.getheader('content-length')
+        if length:
+            environ['CONTENT_LENGTH'] = length
+
+        for name, value in [header.split(':', 1) for header
+                            in self.headers.headers]:
+            name = name.replace('-', '_').upper();
+            value = value.strip()
+            if name in environ:
+                # skip content length, type, etc.
+                continue
+            if 'HTTP_' + name in environ:
+                # comma-separate multiple headers
+                environ['HTTP_' + name] += ',' + value
+            else:
+                environ['HTTP_' + name] = value
+
+        return environ
+
+    def handle_one_request(self):
+        environ = self.setup_environ()
+        gateway = self.server.gateway(self, environ)
+        gateway.run(self.server.application)
+
+    def finish(self):
+        """We need to help the garbage collector a little."""
+        BaseHTTPRequestHandler.finish(self)
+        self.wfile = None
+        self.rfile = None
+
+
+class WSGIServerGateway(WSGIGateway):
+
+    def __init__(self, handler, environ):
+        WSGIGateway.__init__(self, environ, handler.rfile,
+                             _ErrorsWrapper(lambda x: handler.log_error('%s', x)))
+        self.handler = handler
+
+    def _write(self, data):
+        assert self.headers_set, 'Response not started'
+
+        if not self.headers_sent:
+            status, headers = self.headers_sent = self.headers_set
+            self.handler.send_response(int(status[:3]))
+            for name, value in headers:
+                self.handler.send_header(name, value)
+            self.handler.end_headers()
+        self.handler.wfile.write(data)
+
+
+class WSGIServer(HTTPServer):
+
+    def __init__(self, server_address, application, gateway=WSGIServerGateway,
+                 request_handler=WSGIRequestHandler):
+        HTTPServer.__init__(self, server_address, request_handler)
+
+        self.application = application
+
+        gateway.wsgi_multiprocess = isinstance(self, ThreadingMixIn)
+        gateway.wsgi_multiprocess = isinstance(self, ForkingMixIn)
+        self.gateway = gateway
+
+        self.environ = {'SERVER_NAME': self.server_name,
+                        'SERVER_PORT': str(self.server_port),
+                        'SCRIPT_NAME': ''}
diff -urN trac-trunk/build/lib/trac/wiki/__init__.py aw-trac/build/lib/trac/wiki/__init__.py
--- trac-trunk/build/lib/trac/wiki/__init__.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/wiki/__init__.py	2005-05-10 08:59:14.000000000 -0700
@@ -0,0 +1,3 @@
+from trac.wiki.api import *
+from trac.wiki.formatter import *
+from trac.wiki.model import *
diff -urN trac-trunk/build/lib/trac/wiki/api.py aw-trac/build/lib/trac/wiki/api.py
--- trac-trunk/build/lib/trac/wiki/api.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/wiki/api.py	2006-01-28 07:16:15.000000000 -0800
@@ -0,0 +1,226 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+try:
+    import threading
+except ImportError:
+    import dummy_threading as threading
+import time
+import urllib
+import re
+
+from trac.core import *
+from trac.util import to_utf8
+
+
+class IWikiChangeListener(Interface):
+    """Extension point interface for components that should get notified about
+    the creation, deletion and modification of wiki pages.
+    """
+
+    def wiki_page_added(page):
+        """Called whenever a new Wiki page is added."""
+
+    def wiki_page_changed(page, version, t, comment, author, ipnr):
+        """Called when a page has been modified."""
+
+    def wiki_page_deleted(page):
+        """Called when a page has been deleted."""
+
+
+class IWikiMacroProvider(Interface):
+    """Extension point interface for components that provide Wiki macros."""
+
+    def get_macros():
+        """Return an iterable that provides the names of the provided macros."""
+
+    def get_macro_description(name):
+        """Return a plain text description of the macro with the specified name.
+        """
+
+    def render_macro(req, name, content):
+        """Return the HTML output of the macro."""
+
+
+class IWikiSyntaxProvider(Interface):
+ 
+    def get_wiki_syntax():
+        """Return an iterable that provides additional wiki syntax.
+
+        Additional wiki syntax correspond to a pair of (regexp, cb),
+        the `regexp` for the additional syntax and the callback `cb`
+        which will be called if there's a match.
+        That function is of the form cb(formatter, ns, match).
+        """
+ 
+    def get_link_resolvers():
+        """Return an iterable over (namespace, formatter) tuples.
+
+        Each formatter should be a function of the form
+        fmt(formatter, ns, target, label), and should
+        return some HTML fragment.
+        The `label` is already HTML escaped, whereas the `target` is not.
+        """
+ 
+
+class WikiSystem(Component):
+    """Represents the wiki system."""
+
+    implements(IWikiChangeListener, IWikiSyntaxProvider)
+
+    change_listeners = ExtensionPoint(IWikiChangeListener)
+    macro_providers = ExtensionPoint(IWikiMacroProvider)
+    syntax_providers = ExtensionPoint(IWikiSyntaxProvider)
+
+    INDEX_UPDATE_INTERVAL = 5 # seconds
+
+    def __init__(self):
+        self._index = None
+        self._last_index_update = 0
+        self._index_lock = threading.RLock()
+        self._compiled_rules = None
+        self._link_resolvers = None
+        self._helper_patterns = None
+        self._external_handlers = None
+
+    def _update_index(self):
+        self._index_lock.acquire()
+        try:
+            now = time.time()
+            if now > self._last_index_update + WikiSystem.INDEX_UPDATE_INTERVAL:
+                self.log.debug('Updating wiki page index')
+                db = self.env.get_db_cnx()
+                cursor = db.cursor()
+                cursor.execute("SELECT DISTINCT name FROM wiki")
+                self._index = {}
+                for (name,) in cursor:
+                    self._index[name] = True
+                self._last_index_update = now
+        finally:
+            self._index_lock.release()
+
+    # Public API
+
+    def get_pages(self, prefix=None):
+        """Iterate over the names of existing Wiki pages.
+
+        If the `prefix` parameter is given, only names that start with that
+        prefix are included.
+        """
+        self._update_index()
+        for page in self._index.keys():
+            if not prefix or page.startswith(prefix):
+                yield page
+
+    def has_page(self, pagename):
+        """Whether a page with the specified name exists."""
+        self._update_index()
+        return self._index.has_key(pagename)
+
+    def _get_rules(self):
+        self._prepare_rules()
+        return self._compiled_rules
+    rules = property(_get_rules)
+
+    def _get_helper_patterns(self):
+        self._prepare_rules()
+        return self._helper_patterns
+    helper_patterns = property(_get_helper_patterns)
+
+    def _get_external_handlers(self):
+        self._prepare_rules()
+        return self._external_handlers
+    external_handlers = property(_get_external_handlers)
+    
+    def _prepare_rules(self):
+        from trac.wiki.formatter import Formatter
+        if not self._compiled_rules:
+            helpers = []
+            handlers = {}
+            syntax = Formatter._pre_rules[:]
+            i = 0
+            for resolver in self.syntax_providers:
+                for regexp, handler in resolver.get_wiki_syntax():
+                    handlers['i'+str(i)] = handler
+                    syntax.append('(?P<i%d>%s)' % (i, regexp))
+                    i += 1
+            syntax += Formatter._post_rules[:]
+            helper_re = re.compile(r'\?P<([a-z\d_]+)>')
+            for rule in syntax:
+                helpers += helper_re.findall(rule)[1:]
+            rules = re.compile('(?:' + '|'.join(syntax) + ')')
+            self._external_handlers = handlers
+            self._helper_patterns = helpers
+            self._compiled_rules = rules
+
+    def _get_link_resolvers(self):
+        if not self._link_resolvers:
+            resolvers = {}
+            for resolver in self.syntax_providers:
+                for namespace, handler in resolver.get_link_resolvers():
+                    resolvers[namespace] = handler
+            self._link_resolvers = resolvers
+        return self._link_resolvers
+    link_resolvers = property(_get_link_resolvers)
+
+    # IWikiChangeListener methods
+
+    def wiki_page_added(self, page):
+        if not self.has_page(page.name):
+            self.log.debug('Adding page %s to index' % page.name)
+            self._index[page.name] = True
+
+    def wiki_page_changed(self, page, version, t, comment, author, ipnr):
+        pass
+
+    def wiki_page_deleted(self, page):
+        if self.has_page(page.name):
+            self.log.debug('Removing page %s from index' % page.name)
+            del self._index[page.name]
+
+    # IWikiSyntaxProvider methods
+    
+    def get_wiki_syntax(self):
+        ignore_missing = self.config.getbool('wiki', 'ignore_missing_pages')
+        yield (r"!?(?<!/)\b[A-Z][a-z]+(?:[A-Z][a-z]*[a-z/])+"
+                "(?:#[A-Za-z0-9]+)?(?=:?\Z|:?\s|[.,;!?\)}\]])",
+               lambda x, y, z: self._format_link(x, 'wiki', y, y,
+                                                 ignore_missing))
+
+    def get_link_resolvers(self):
+        yield ('wiki', self._format_fancy_link)
+
+    def _format_fancy_link(self, f, n, p, l):
+        return self._format_link(f, n, p, l, False)
+
+    def _format_link(self, formatter, ns, page, label, ignore_missing):
+        anchor = ''
+        if page.find('#') != -1:
+            anchor = page[page.find('#'):]
+            page = page[:page.find('#')]
+        page = urllib.unquote(page)
+        label = urllib.unquote(label)
+
+        if not self.has_page(page):
+            if ignore_missing:
+                return label
+            return '<a class="missing wiki" href="%s" rel="nofollow">%s?</a>' \
+                   % (formatter.href.wiki(page) + anchor, label)
+        else:
+            return '<a class="wiki" href="%s">%s</a>' \
+                   % (formatter.href.wiki(page) + anchor, label)
diff -urN trac-trunk/build/lib/trac/wiki/formatter.py aw-trac/build/lib/trac/wiki/formatter.py
--- trac-trunk/build/lib/trac/wiki/formatter.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/wiki/formatter.py	2006-02-10 02:09:59.000000000 -0800
@@ -0,0 +1,899 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# Copyright (C) 2005-2006 Christian Boos <cboos@neuf.fr>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import re
+import os
+import urllib
+
+try:
+    from cStringIO import StringIO
+except ImportError:
+    from StringIO import StringIO
+
+from trac import util
+from trac.core import *
+from trac.mimeview import *
+from trac.wiki.api import WikiSystem, IWikiChangeListener, IWikiMacroProvider
+
+__all__ = ['wiki_to_html', 'wiki_to_oneliner', 'wiki_to_outline', 'Formatter' ]
+
+
+def system_message(msg, text):
+    return """<div class="system-message">
+ <strong>%s</strong>
+ <pre>%s</pre>
+</div>
+""" % (util.escape(msg), util.escape(text))
+
+
+class WikiProcessor(object):
+
+    def __init__(self, env, name):
+        self.env = env
+        self.name = name
+        self.error = None
+
+        builtin_processors = {'html': self._html_processor,
+                              'default': self._default_processor,
+                              'comment': self._comment_processor}
+        self.processor = builtin_processors.get(name)
+        if not self.processor:
+            # Find a matching wiki macro
+            from trac.wiki import WikiSystem
+            wiki = WikiSystem(self.env)
+            for macro_provider in wiki.macro_providers:
+                if self.name in list(macro_provider.get_macros()):
+                    self.processor = self._macro_processor
+                    break
+        if not self.processor:
+            # Find a matching mimeview renderer
+            from trac.mimeview.api import MIME_MAP
+            if MIME_MAP.has_key(self.name):
+                self.name = MIME_MAP[self.name]
+                self.processor = self._mimeview_processor
+            elif self.name in MIME_MAP.values():
+                self.processor = self._mimeview_processor
+            else:
+                self.processor = self._default_processor
+                self.error = 'No macro named [[%s]] found' % name
+
+    def _comment_processor(self, req, text):
+        return ''
+
+    def _default_processor(self, req, text):
+        return '<pre class="wiki">' + util.escape(text) + '</pre>\n'
+
+    def _html_processor(self, req, text):
+        from HTMLParser import HTMLParseError
+        try:
+            return util.Markup(text).sanitize()
+        except HTMLParseError, e:
+            self.env.log.warn(e)
+            return system_message('HTML parsing error: %s' % util.escape(e.msg),
+                                  text.splitlines()[e.lineno - 1].strip())
+
+    def _macro_processor(self, req, text):
+        from trac.wiki import WikiSystem
+        wiki = WikiSystem(self.env)
+        for macro_provider in wiki.macro_providers:
+            if self.name in list(macro_provider.get_macros()):
+                self.env.log.debug('Executing Wiki macro %s by provider %s'
+                                   % (self.name, macro_provider))
+                return macro_provider.render_macro(req, self.name, text)
+
+    def _mimeview_processor(self, req, text):
+        return Mimeview(self.env).render(req, self.name, text)
+
+    def process(self, req, text, inline=False):
+        if self.error:
+            return system_message(util.Markup('Error: Failed to load processor '
+                                              '<code>%s</code>', self.name),
+                                  self.error)
+        text = self.processor(req, text)
+        if inline:
+            code_block_start = re.compile('^<div class="code-block">')
+            code_block_end = re.compile('</div>$')
+            text, nr = code_block_start.subn('<span class="code-block">', text, 1 )
+            if nr:
+                text, nr = code_block_end.subn('</span>', text, 1 )
+            return text
+        else:
+            return text
+
+
+class Formatter(object):
+    flavor = 'default'
+
+    # Some constants used for clarifying the Wiki regexps:
+
+    BOLDITALIC_TOKEN = "'''''"
+    BOLD_TOKEN = "'''"
+    ITALIC_TOKEN = "''"
+    UNDERLINE_TOKEN = "__"
+    STRIKE_TOKEN = "~~"
+    SUBSCRIPT_TOKEN = ",,"
+    SUPERSCRIPT_TOKEN = r"\^"
+    INLINE_TOKEN = "`"
+
+    LINK_SCHEME = r"[\w.+-]+" # as per RFC 2396
+    INTERTRAC_SCHEME = r"[a-zA-Z.+-]+?" # no digits (support for shorthand links)
+
+    QUOTED_STRING = r"'[^']+'|\"[^\"]+\""
+
+    SHREF_TARGET_FIRST = r"[\w/?!#@]"
+    SHREF_TARGET_MIDDLE = r"(?:\|(?=[^|\s])|[^|<>\s])"
+    SHREF_TARGET_LAST = r"[a-zA-Z0-9/=]" # we don't want "_"
+
+    LHREF_RELATIVE_TARGET = r"[/.][^\s[\]]*"
+
+
+    # Rules provided by IWikiSyntaxProviders will be inserted,
+    # between _pre_rules and _post_rules
+
+    _pre_rules = [
+        # Font styles
+        r"(?P<bolditalic>%s)" % BOLDITALIC_TOKEN,
+        r"(?P<bold>%s)" % BOLD_TOKEN,
+        r"(?P<italic>%s)" % ITALIC_TOKEN,
+        r"(?P<underline>!?%s)" % UNDERLINE_TOKEN,
+        r"(?P<strike>!?%s)" % STRIKE_TOKEN,
+        r"(?P<subscript>!?%s)" % SUBSCRIPT_TOKEN,
+        r"(?P<superscript>!?%s)" % SUPERSCRIPT_TOKEN,
+        r"(?P<inlinecode>!?\{\{\{(?P<inline>.*?)\}\}\})",
+        r"(?P<inlinecode2>!?%s(?P<inline2>.*?)%s)" \
+        % (INLINE_TOKEN, INLINE_TOKEN)]
+
+    _post_rules = [
+        r"(?P<htmlescape>[&<>])",
+        # shref corresponds to short TracLinks, i.e. sns:stgt
+        r"(?P<shref>!?((?P<sns>%s):(?P<stgt>%s|%s(?:%s*%s)?)))" \
+        % (LINK_SCHEME, QUOTED_STRING,
+           SHREF_TARGET_FIRST, SHREF_TARGET_MIDDLE, SHREF_TARGET_LAST),
+        # lhref corresponds to long TracLinks, i.e. [lns:ltgt label?]
+        r"(?P<lhref>!?\[(?:(?P<lns>%s):(?P<ltgt>%s|[^\]\s]*)|(?P<rel>%s))"
+        r"(?:\s+(?P<label>%s|[^\]]+))?\])" \
+        % (LINK_SCHEME, QUOTED_STRING, LHREF_RELATIVE_TARGET, QUOTED_STRING),
+        # macro call
+        (r"(?P<macro>!?\[\[(?P<macroname>[\w/+-]+)"
+         r"(\]\]|\((?P<macroargs>.*?)\)\]\]))"),
+        # heading, list, definition, indent, table...
+        r"(?P<heading>^\s*(?P<hdepth>=+)\s.*\s(?P=hdepth)\s*$)",
+        r"(?P<list>^(?P<ldepth>\s+)(?:\*|\d+\.) )",
+        r"(?P<definition>^\s+(.+)::)\s*",
+        r"(?P<indent>^(?P<idepth>\s+)(?=\S))",
+        r"(?P<last_table_cell>\|\|\s*$)",
+        r"(?P<table_cell>\|\|)"]
+
+    _processor_re = re.compile('#\!([\w+-][\w+-/]*)')
+    _anchor_re = re.compile('[^\w\d\.-:]+', re.UNICODE)
+    
+    img_re = re.compile(r"\.(gif|jpg|jpeg|png)(\?.*)?$", re.IGNORECASE)
+
+    def __init__(self, env, req=None, absurls=0, db=None):
+        self.env = env
+        self.req = req
+        self._db = db
+        self._absurls = absurls
+        self._anchors = []
+        self._open_tags = []
+        self.href = absurls and env.abs_href or env.href
+        self._local = env.config.get('project', 'url') or env.abs_href.base
+
+    def _get_db(self):
+        if not self._db:
+            self._db = self.env.get_db_cnx()
+        return self._db
+    db = property(fget=_get_db)
+
+    def _get_rules(self):
+        return WikiSystem(self.env).rules
+    rules = property(_get_rules)
+
+    def _get_link_resolvers(self):
+        return WikiSystem(self.env).link_resolvers
+    link_resolvers = property(_get_link_resolvers)
+
+    def replace(self, fullmatch):
+        wiki = WikiSystem(self.env)        
+        for itype, match in fullmatch.groupdict().items():
+            if match and not itype in wiki.helper_patterns:
+                # Check for preceding escape character '!'
+                if match[0] == '!':
+                    return match[1:]
+                if itype in wiki.external_handlers:
+                    return wiki.external_handlers[itype](self, match, fullmatch)
+                else:
+                    return getattr(self, '_' + itype + '_formatter')(match, fullmatch)
+
+    def tag_open_p(self, tag):
+        """Do we currently have any open tag with @tag as end-tag"""
+        return tag in self._open_tags
+
+    def close_tag(self, tag):
+        tmp =  ''
+        for i in xrange(len(self._open_tags)-1, -1, -1):
+            tmp += self._open_tags[i][1]
+            if self._open_tags[i][1] == tag:
+                del self._open_tags[i]
+                for j in xrange(i, len(self._open_tags)):
+                    tmp += self._open_tags[j][0]
+                break
+        return tmp
+
+    def open_tag(self, open, close):
+        self._open_tags.append((open, close))
+
+    def simple_tag_handler(self, open_tag, close_tag):
+        """Generic handler for simple binary style tags"""
+        if self.tag_open_p((open_tag, close_tag)):
+            return self.close_tag(close_tag)
+        else:
+            self.open_tag(open_tag, close_tag)
+        return open_tag
+
+    def _bolditalic_formatter(self, match, fullmatch):
+        italic = ('<i>', '</i>')
+        italic_open = self.tag_open_p(italic)
+        tmp = ''
+        if italic_open:
+            tmp += italic[1]
+            self.close_tag(italic[1])
+        tmp += self._bold_formatter(match, fullmatch)
+        if not italic_open:
+            tmp += italic[0]
+            self.open_tag(*italic)
+        return tmp
+
+    def _unquote(self, text):
+        if text and text[0] in "'\"" and text[0] == text[-1]:
+            return text[1:-1]
+        else:
+            return text
+
+    def _shref_formatter(self, match, fullmatch):
+        ns = fullmatch.group('sns')
+        target = self._unquote(fullmatch.group('stgt'))
+        return self._make_link(ns, target, match, match)
+
+    def _lhref_formatter(self, match, fullmatch):
+        ns = fullmatch.group('lns')
+        target = self._unquote(fullmatch.group('ltgt'))
+        label = fullmatch.group('label')
+        if not label: # e.g. `[http://target]` or `[wiki:target]`
+            if target:
+                if target.startswith('//'): # for `[http://target]`
+                    label = ns+':'+target   # use `http://target`
+                else:                       # for `wiki:target`
+                    label = target          # use only `target`
+            else: # e.g. `[search:]` 
+                label = ns
+        label = self._unquote(label)
+        rel = fullmatch.group('rel')
+        if rel:
+            return self._make_relative_link(rel, label or rel)
+        else:
+            return self._make_link(ns, target, match, label)
+
+    def _make_link(self, ns, target, match, label):
+        # check first for an alias defined in trac.ini
+        ns = self.env.config.get('intertrac', ns.upper()) or ns
+        if ns in self.link_resolvers:
+            return self.link_resolvers[ns](self, ns, target,
+                                           util.escape(label, False))
+        elif target.startswith('//') or ns == "mailto":
+            return self._make_ext_link(ns+':'+target, label)
+        else:
+            return self._make_intertrac_link(ns, target, label) or \
+                   self._make_interwiki_link(ns, target, label) or \
+                   match
+
+    def _make_intertrac_link(self, ns, target, label):
+        url = self.env.config.get('intertrac', ns.upper() + '.url')
+        if url:
+            name = self.env.config.get('intertrac', ns.upper() + '.title',
+                                       'Trac project %s' % ns)
+            sep = target.find(':')
+            if sep != -1:
+                url = '%s/%s/%s' % (url, target[:sep], target[sep + 1:])
+            else: 
+                url = '%s/search?q=%s' % (url, urllib.quote_plus(target))
+            return self._make_ext_link(url, label, '%s in %s' % (target, name))
+        else:
+            return None
+
+    def shorthand_intertrac_helper(self, ns, target, label, fullmatch):
+        if fullmatch: # short form
+            it_group = fullmatch.group('it_%s' % ns)
+            if it_group:
+                alias = it_group.strip()
+                intertrac = self.env.config.get('intertrac', alias.upper()) or \
+                            alias
+                target = '%s:%s' % (ns, target[len(it_group):])
+                return self._make_intertrac_link(intertrac, target, label) or \
+                       label
+        return None
+
+    def _make_interwiki_link(self, ns, target, label):
+        interwiki = InterWikiMap(self.env)
+        if interwiki.has_key(ns):
+            url, title = interwiki.url(ns, target)
+            return self._make_ext_link(url, label, title)
+        else:
+            return None
+
+    def _make_ext_link(self, url, text, title=''):
+        url = util.escape(url)
+        text, title = util.escape(text), util.escape(title)
+        title_attr = title and ' title="%s"' % title or ''
+        if Formatter.img_re.search(url) and self.flavor != 'oneliner':
+            return '<img src="%s" alt="%s" />' % (url, title or text)
+        if not url.startswith(self._local):
+            return '<a class="ext-link" href="%s"%s><span class="icon">' \
+                   '</span>%s</a>' % (url, title_attr, text)
+        else:
+            return '<a href="%s"%s>%s</a>' % (url, title_attr, text)
+
+    def _make_relative_link(self, url, text):
+        url, text = util.escape(url), util.escape(text)
+        if Formatter.img_re.search(url) and self.flavor != 'oneliner':
+            return '<img src="%s" alt="%s" />' % (url, text)
+        if url.startswith('//'): # only the protocol will be kept
+            return '<a class="ext-link" href="%s">%s</a>' % (url, text)
+        else:
+            return '<a href="%s">%s</a>' % (url, text)
+
+    def _bold_formatter(self, match, fullmatch):
+        return self.simple_tag_handler('<strong>', '</strong>')
+
+    def _italic_formatter(self, match, fullmatch):
+        return self.simple_tag_handler('<i>', '</i>')
+
+    def _underline_formatter(self, match, fullmatch):
+        if match[0] == '!':
+            return match[1:]
+        else:
+            return self.simple_tag_handler('<span class="underline">',
+                                           '</span>')
+
+    def _strike_formatter(self, match, fullmatch):
+        if match[0] == '!':
+            return match[1:]
+        else:
+            return self.simple_tag_handler('<del>', '</del>')
+
+    def _subscript_formatter(self, match, fullmatch):
+        if match[0] == '!':
+            return match[1:]
+        else:
+            return self.simple_tag_handler('<sub>', '</sub>')
+
+    def _superscript_formatter(self, match, fullmatch):
+        if match[0] == '!':
+            return match[1:]
+        else:
+            return self.simple_tag_handler('<sup>', '</sup>')
+
+    def _inlinecode_formatter(self, match, fullmatch):
+        return '<tt>%s</tt>' % util.escape(fullmatch.group('inline'))
+
+    def _inlinecode2_formatter(self, match, fullmatch):
+        return '<tt>%s</tt>' % util.escape(fullmatch.group('inline2'))
+
+    def _htmlescape_formatter(self, match, fullmatch):
+        return match == "&" and "&amp;" or match == "<" and "&lt;" or "&gt;"
+
+    def _macro_formatter(self, match, fullmatch):
+        name = fullmatch.group('macroname')
+        if name in ['br', 'BR']:
+            return '<br />'
+        args = fullmatch.group('macroargs')
+        try:
+            macro = WikiProcessor(self.env, name)
+            return macro.process(self.req, args, 1)
+        except Exception, e:
+            self.env.log.error('Macro %s(%s) failed' % (name, args),
+                               exc_info=True)
+            return system_message('Error: Macro %s(%s) failed' % (name, args), e)
+
+    def _heading_formatter(self, match, fullmatch):
+        match = match.strip()
+        self.close_table()
+        self.close_paragraph()
+        self.close_indentation()
+        self.close_list()
+        self.close_def_list()
+
+        depth = min(len(fullmatch.group('hdepth')), 5)
+        heading = match[depth + 1:len(match) - depth - 1]
+
+        text = wiki_to_oneliner(heading, self.env, self.db, self._absurls)
+        sans_markup = re.sub(r'</?\w+(?: .*?)?>', '', text)
+
+        anchor = self._anchor_re.sub('', sans_markup.decode('utf-8'))
+        if not anchor or not anchor[0].isalpha():
+            # an ID must start with a letter in HTML
+            anchor = 'a' + anchor
+        i = 1
+        anchor = anchor_base = anchor.encode('utf-8')
+        while anchor in self._anchors:
+            anchor = anchor_base + str(i)
+            i += 1
+        self._anchors.append(anchor)
+        self.out.write('<h%d id="%s">%s</h%d>' % (depth, anchor, text, depth))
+
+    def _indent_formatter(self, match, fullmatch):
+        depth = int((len(fullmatch.group('idepth')) + 1) / 2)
+        list_depth = len(self._list_stack)
+        if list_depth > 0 and depth == list_depth + 1:
+            self.in_list_item = 1
+        else:
+            self.open_indentation(depth)
+        return ''
+
+    def _last_table_cell_formatter(self, match, fullmatch):
+        return ''
+
+    def _table_cell_formatter(self, match, fullmatch):
+        self.open_table()
+        self.open_table_row()
+        if self.in_table_cell:
+            return '</td><td>'
+        else:
+            self.in_table_cell = 1
+            return '<td>'
+
+    def close_indentation(self):
+        self.out.write(('</blockquote>' + os.linesep) * self.indent_level)
+        self.indent_level = 0
+
+    def open_indentation(self, depth):
+        if self.in_def_list:
+            return
+        diff = depth - self.indent_level
+        if diff != 0:
+            self.close_paragraph()
+            self.close_indentation()
+            self.close_list()
+            self.indent_level = depth
+            self.out.write(('<blockquote>' + os.linesep) * depth)
+
+    def _list_formatter(self, match, fullmatch):
+        ldepth = len(fullmatch.group('ldepth'))
+        depth = int((len(fullmatch.group('ldepth')) + 1) / 2)
+        self.in_list_item = depth > 0
+        type_ = ['ol', 'ul'][match[ldepth] == '*']
+        self._set_list_depth(depth, type_)
+        return ''
+
+    def _definition_formatter(self, match, fullmatch):
+        tmp = self.in_def_list and '</dd>' or '<dl>'
+        tmp += '<dt>%s</dt><dd>' % wiki_to_oneliner(match[:-2], self.env,
+                                                    self.db)
+        self.in_def_list = True
+        return tmp
+
+    def close_def_list(self):
+        if self.in_def_list:
+            self.out.write('</dd></dl>\n')
+        self.in_def_list = False
+
+    def _set_list_depth(self, depth, type_):
+        current_depth = len(self._list_stack)
+        diff = depth - current_depth
+        self.close_table()
+        self.close_paragraph()
+        self.close_indentation()
+        if diff > 0:
+            for i in range(diff):
+                self._list_stack.append(type_)
+                self.out.write('<%s><li>' % type_)
+        elif diff < 0:
+            for i in range(-diff):
+                tmp = self._list_stack.pop()
+                self.out.write('</li></%s>' % tmp)
+            if self._list_stack != [] and type_ != self._list_stack[-1]:
+                tmp = self._list_stack.pop()
+                self._list_stack.append(type_)
+                self.out.write('</li></%s><%s><li>' % (tmp, type_))
+            if depth > 0:
+                self.out.write('</li><li>')
+        # diff == 0
+        elif self._list_stack != [] and type_ != self._list_stack[-1]:
+            tmp = self._list_stack.pop()
+            self._list_stack.append(type_)
+            self.out.write('</li></%s><%s><li>' % (tmp, type_))
+        elif depth > 0:
+            self.out.write('</li><li>')
+
+    def close_list(self):
+        if self._list_stack != []:
+            self._set_list_depth(0, None)
+
+    def open_paragraph(self):
+        if not self.paragraph_open:
+            self.out.write('<p>' + os.linesep)
+            self.paragraph_open = 1
+
+    def close_paragraph(self):
+        if self.paragraph_open:
+            while self._open_tags != []:
+                self.out.write(self._open_tags.pop()[1])
+            self.out.write('</p>' + os.linesep)
+            self.paragraph_open = 0
+
+    def open_table(self):
+        if not self.in_table:
+            self.close_paragraph()
+            self.close_indentation()
+            self.close_list()
+            self.close_def_list()
+            self.in_table = 1
+            self.out.write('<table class="wiki">' + os.linesep)
+
+    def open_table_row(self):
+        if not self.in_table_row:
+            self.open_table()
+            self.in_table_row = 1
+            self.out.write('<tr>')
+
+    def close_table_row(self):
+        if self.in_table_row:
+            self.in_table_row = 0
+            if self.in_table_cell:
+                self.in_table_cell = 0
+                self.out.write('</td>')
+
+            self.out.write('</tr>')
+
+    def close_table(self):
+        if self.in_table:
+            self.close_table_row()
+            self.out.write('</table>' + os.linesep)
+            self.in_table = 0
+
+    def handle_code_block(self, line):
+        if line.strip() == '{{{':
+            self.in_code_block += 1
+            if self.in_code_block == 1:
+                self.code_processor = None
+                self.code_text = ''
+            else:
+                self.code_text += line + os.linesep
+                if not self.code_processor:
+                    self.code_processor = WikiProcessor(self.env, 'default')
+        elif line.strip() == '}}}':
+            self.in_code_block -= 1
+            if self.in_code_block == 0 and self.code_processor:
+                self.close_paragraph()
+                self.close_table()
+                self.out.write(self.code_processor.process(self.req, self.code_text))
+            else:
+                self.code_text += line + os.linesep
+        elif not self.code_processor:
+            match = Formatter._processor_re.search(line)
+            if match:
+                name = match.group(1)
+                self.code_processor = WikiProcessor(self.env, name)
+            else:
+                self.code_text += line + os.linesep 
+                self.code_processor = WikiProcessor(self.env, 'default')
+        else:
+            self.code_text += line + os.linesep
+
+    def format(self, text, out, escape_newlines=False):
+        self.out = out
+        self._open_tags = []
+        self._list_stack = []
+
+        self.in_code_block = 0
+        self.in_table = 0
+        self.in_def_list = 0
+        self.in_table_row = 0
+        self.in_table_cell = 0
+        self.indent_level = 0
+        self.paragraph_open = 0
+
+        for line in text.splitlines():
+            # Handle code block
+            if self.in_code_block or line.strip() == '{{{':
+                self.handle_code_block(line)
+                continue
+            # Handle Horizontal ruler
+            elif line[0:4] == '----':
+                self.close_paragraph()
+                self.close_indentation()
+                self.close_list()
+                self.close_def_list()
+                self.close_table()
+                self.out.write('<hr />' + os.linesep)
+                continue
+            # Handle new paragraph
+            elif line == '':
+                self.close_paragraph()
+                self.close_indentation()
+                self.close_list()
+                self.close_def_list()
+                continue
+
+            if escape_newlines:
+                line += ' [[BR]]'
+            self.in_list_item = False
+            # Throw a bunch of regexps on the problem
+            result = re.sub(self.rules, self.replace, line)
+
+            if not self.in_list_item:
+                self.close_list()
+
+            if self.in_def_list and not line.startswith(' '):
+                self.close_def_list()
+
+            if self.in_table and line[0:2] != '||':
+                self.close_table()
+
+            if len(result) and not self.in_list_item and not self.in_def_list \
+                    and not self.in_table:
+                self.open_paragraph()
+            out.write(result + os.linesep)
+            self.close_table_row()
+
+        self.close_table()
+        self.close_paragraph()
+        self.close_indentation()
+        self.close_list()
+        self.close_def_list()
+
+
+class OneLinerFormatter(Formatter):
+    """
+    A special version of the wiki formatter that only implement a
+    subset of the wiki formatting functions. This version is useful
+    for rendering short wiki-formatted messages on a single line
+    """
+    flavor = 'oneliner'
+
+    def __init__(self, env, absurls=0, db=None):
+        Formatter.__init__(self, env, None, absurls, db)
+
+    # Override a few formatters to disable some wiki syntax in "oneliner"-mode
+    def _list_formatter(self, match, fullmatch): return match
+    def _indent_formatter(self, match, fullmatch): return match
+    def _heading_formatter(self, match, fullmatch):
+        return util.escape(match, False)
+    def _definition_formatter(self, match, fullmatch):
+        return util.escape(match, False)
+    def _table_cell_formatter(self, match, fullmatch): return match
+    def _last_table_cell_formatter(self, match, fullmatch): return match
+
+    def _macro_formatter(self, match, fullmatch):
+        name = fullmatch.group('macroname')
+        if name.lower() == 'br':
+            return ' '
+        elif name == 'comment':
+            return ''
+        else:
+            args = fullmatch.group('macroargs')
+            return '[[%s%s]]' % (name,  args and '(...)' or '')
+
+    def format(self, text, out, shorten=False):
+        if not text:
+            return
+        self.out = out
+        self._open_tags = []
+
+        # Simplify code blocks
+        in_code_block = 0
+        processor = None
+        buf = StringIO()
+        for line in text.strip().splitlines():
+            if line.strip() == '{{{':
+                in_code_block += 1
+            elif line.strip() == '}}}':
+                if in_code_block:
+                    in_code_block -= 1
+                    if in_code_block == 0:
+                        if processor != 'comment':
+                            print>>buf, ' ![...]'
+                        processor = None
+            elif in_code_block:
+                if not processor:
+                    if line.startswith('#!'):
+                        processor = line[2:].strip()
+            else:
+                print>>buf, line
+        result = buf.getvalue()[:-1]
+
+        if shorten:
+            result = util.shorten_line(result)
+
+        result = re.sub(self.rules, self.replace, result)
+        result = result.replace('[...]', '[&hellip;]')
+        if result.endswith('...'):
+            result = result[:-3] + '&hellip;'
+
+        # Close all open 'one line'-tags
+        result += self.close_tag(None)
+        out.write(result)
+
+
+class OutlineFormatter(Formatter):
+    """Special formatter that generates an outline of all the headings in wiki
+    text."""
+    flavor = 'outline'
+    
+    def __init__(self, env, absurls=0, db=None):
+        Formatter.__init__(self, env, None, absurls, db)
+
+    # Override a few formatters to disable some wiki syntax in "outline"-mode
+    def _macro_formatter(self, match, fullmatch):
+        return match
+
+    def format(self, text, out, max_depth=6, min_depth=1):
+        self.outline = []
+        class NullOut(object):
+            def write(self, data): pass
+        Formatter.format(self, text, NullOut())
+
+        if min_depth > max_depth:
+            min_depth, max_depth = max_depth, min_depth
+        max_depth = min(6, max_depth)
+        min_depth = max(1, min_depth)
+
+        curr_depth = min_depth - 1
+        for depth, link in self.outline:
+            if depth < min_depth or depth > max_depth:
+                continue
+            if depth < curr_depth:
+                out.write('</li></ol><li>' * (curr_depth - depth))
+            elif depth > curr_depth:
+                out.write('<ol><li>' * (depth - curr_depth))
+            else:
+                out.write("</li><li>\n")
+            curr_depth = depth
+            out.write(link)
+        out.write('</li></ol>' * curr_depth)
+
+    def _heading_formatter(self, match, fullmatch):
+        Formatter._heading_formatter(self, match, fullmatch)
+        depth = min(len(fullmatch.group('hdepth')), 5)
+        heading = match[depth + 1:len(match) - depth - 1]
+        anchor = self._anchors[-1]
+        text = wiki_to_oneliner(heading, self.env, self.db, self._absurls)
+        text = re.sub(r'</?a(?: .*?)?>', '', text) # Strip out link tags
+        self.outline.append((depth, '<a href="#%s">%s</a>' % (anchor, text)))
+
+
+def wiki_to_html(wikitext, env, req, db=None, absurls=0, escape_newlines=False):
+    out = StringIO()
+    Formatter(env, req, absurls, db).format(wikitext, out, escape_newlines)
+    return util.Markup(out.getvalue())
+
+def wiki_to_oneliner(wikitext, env, db=None, shorten=False, absurls=0):
+    out = StringIO()
+    OneLinerFormatter(env, absurls, db).format(wikitext, out, shorten)
+    return util.Markup(out.getvalue())
+
+def wiki_to_outline(wikitext, env, db=None, absurls=0, max_depth=None,
+                    min_depth=None):
+    out = StringIO()
+    OutlineFormatter(env, absurls, db).format(wikitext, out, max_depth,
+                                              min_depth)
+    return util.Markup(out.getvalue())
+
+
+# -- InterWiki support
+
+class InterWikiMap(Component):
+
+    implements(IWikiChangeListener, IWikiMacroProvider)
+
+    _page_name = 'InterMapTxt'
+    _interwiki_re = re.compile(r"(%s)[ \t]+([^ \t]+)(?:[ \t]+#(.*))?" %
+                               Formatter.LINK_SCHEME, re.UNICODE)
+    _argspec_re = re.compile(r"\$\d")
+
+    def __init__(self):
+        self._interwiki_map = None
+        # This dictionary maps upper-cased namespaces
+        # to (namespace, prefix, title) values
+
+    def _expand(self, txt, args):
+        def setarg(match):
+            num = int(match.group()[1:])
+            return 0 < num <= len(args) and args[num-1] or ''
+        return re.sub(InterWikiMap._argspec_re, setarg, txt)
+
+    def _expand_or_append(self, txt, args):
+        if not args:
+            return txt
+        expanded = self._expand(txt, args)
+        return expanded == txt and txt + args[0] or expanded
+
+    def has_key(self, ns):
+        if not self._interwiki_map:
+            self._update()
+        return self._interwiki_map.has_key(ns.upper())
+
+    def url(self, ns, target):
+        ns, url, title = self._interwiki_map[ns.upper()]
+        args = target.split(':')
+        expanded_url = self._expand_or_append(url, args)
+        expanded_title = self._expand(title, args)
+        if expanded_title == title:
+            expanded_title = target+' in '+title
+        return expanded_url, expanded_title
+
+    # IWikiChangeListener methods
+
+    def wiki_page_added(self, page):
+        if page.name == InterWikiMap._page_name:
+            self._update()
+
+    def wiki_page_changed(self, page, version, t, comment, author, ipnr):
+        if page.name == InterWikiMap._page_name:
+            self._update()
+
+    def wiki_page_deleted(self, page):
+        if page.name == InterWikiMap._page_name:
+            self._interwiki_map.clear()
+
+    def _update(self):
+        from trac.wiki.model import WikiPage
+        self._interwiki_map = {}
+        content = WikiPage(self.env, InterWikiMap._page_name).text
+        in_map = False
+        for line in content.split('\n'):
+            if in_map:
+                if line.startswith('----'):
+                    in_map = False
+                else:
+                    m = re.match(InterWikiMap._interwiki_re, line)
+                    if m:
+                        prefix, url, title = m.groups()
+                        url = url.strip()
+                        title = title and title.strip() or prefix
+                        self._interwiki_map[prefix.upper()] = (prefix, url,
+                                                               title)
+            elif line.startswith('----'):
+                in_map = True
+
+    # IWikiMacroProvider
+
+    def get_macros(self):
+        yield 'InterWiki'
+
+    def get_macro_description(self, name): 
+        return "Provide a description list for the known InterWiki prefixes."
+
+    def render_macro(self, req, name, content):
+        if not self._interwiki_map:
+            self._update()
+        keys = self._interwiki_map.keys()
+        keys.sort()
+        buf = StringIO()
+        buf.write('<table><tr><th>Prefix</th><td>Site</td></tr>\n')
+        for k in keys:
+            prefix, url, title = self._interwiki_map[k]
+            rc_url = self._expand_or_append(url, ['RecentChanges'])
+            description = title == prefix and url or title
+            buf.write('<tr>\n' +
+                      '<td><a href="%s">%s</a></td>' % (rc_url, prefix) +
+                      '<td><a href="%s">%s</a></td>\n' % (url, description) +
+                      '</tr>\n')
+        buf.write('</table>\n')
+        return buf.getvalue()
diff -urN trac-trunk/build/lib/trac/wiki/macros.py aw-trac/build/lib/trac/wiki/macros.py
--- trac-trunk/build/lib/trac/wiki/macros.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/wiki/macros.py	2006-02-14 05:45:31.000000000 -0800
@@ -0,0 +1,451 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2005 Edgewall Software
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Christopher Lenz <cmlenz@gmx.de>
+
+import imp
+import inspect
+import os
+import re
+
+try:
+    from cStringIO import StringIO
+except ImportError:
+    from StringIO import StringIO
+
+from trac.config import default_dir
+from trac.core import *
+from trac.util import escape, format_date
+from trac.wiki.api import IWikiMacroProvider, WikiSystem
+from trac.wiki.model import WikiPage
+
+
+class TitleIndexMacro(Component):
+    """
+    Inserts an alphabetic list of all wiki pages into the output.
+
+    Accepts a prefix string as parameter: if provided, only pages with names
+    that start with the prefix are included in the resulting list. If this
+    parameter is omitted, all pages are listed.
+    """
+    implements(IWikiMacroProvider)
+
+    def get_macros(self):
+        yield 'TitleIndex'
+
+    def get_macro_description(self, name):
+        return inspect.getdoc(TitleIndexMacro)
+
+    def render_macro(self, req, name, content):
+        prefix = content or None
+
+        wiki = WikiSystem(self.env)
+        pages = list(wiki.get_pages(prefix))
+        pages.sort()
+
+        buf = StringIO()
+        buf.write('<ul>')
+        for page in pages:
+            buf.write('<li><a href="%s">' % escape(self.env.href.wiki(page)))
+            buf.write(escape(page))
+            buf.write('</a></li>\n')
+        buf.write('</ul>')
+
+        return buf.getvalue()
+
+
+class RecentChangesMacro(Component):
+    """
+    Lists all pages that have recently been modified, grouping them by the day
+    they were last modified.
+
+    This macro accepts two parameters. The first is a prefix string: if
+    provided, only pages with names that start with the prefix are included in
+    the resulting list. If this parameter is omitted, all pages are listed.
+
+    The second parameter is a number for limiting the number of pages returned.
+    For example, specifying a limit of 5 will result in only the five most
+    recently changed pages to be included in the list.
+    """
+    implements(IWikiMacroProvider)
+
+    def get_macros(self):
+        yield 'RecentChanges'
+
+    def get_macro_description(self, name):
+        return inspect.getdoc(RecentChangesMacro)
+
+    def render_macro(self, req, name, content):
+        prefix = limit = None
+        if content:
+            argv = [arg.strip() for arg in content.split(',')]
+            if len(argv) > 0:
+                prefix = argv[0]
+                if len(argv) > 1:
+                    limit = int(argv[1])
+
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+
+        sql = 'SELECT name, max(time) FROM wiki'
+        args = []
+        if prefix:
+            sql += ' WHERE name LIKE %s'
+            args.append(prefix + '%')
+        sql += ' GROUP BY name ORDER BY max(time) DESC'
+        if limit:
+            sql += ' LIMIT %s'
+            args.append(limit)
+        cursor.execute(sql, args)
+
+        buf = StringIO()
+        prevdate = None
+
+        for name, time in cursor:
+            date = format_date(time)
+            if date != prevdate:
+                if prevdate:
+                    buf.write('</ul>')
+                buf.write('<h3>%s</h3><ul>' % date)
+                prevdate = date
+            buf.write('<li><a href="%s">%s</a></li>\n'
+                      % (escape(self.env.href.wiki(name)), escape(name)))
+        if prevdate:
+            buf.write('</ul>')
+
+        return buf.getvalue()
+
+
+class PageOutlineMacro(Component):
+    """
+    Displays a structural outline of the current wiki page, each item in the
+    outline being a link to the corresponding heading.
+
+    This macro accepts three optional parameters:
+    
+     * The first is a number or range that allows configuring the minimum and
+       maximum level of headings that should be included in the outline. For
+       example, specifying "1" here will result in only the top-level headings
+       being included in the outline. Specifying "2-3" will make the outline
+       include all headings of level 2 and 3, as a nested list. The default is
+       to include all heading levels.
+     * The second parameter can be used to specify a custom title (the default
+       is no title).
+     * The third parameter selects the style of the outline. This can be
+       either `inline` or `pullout` (the latter being the default). The `inline`
+       style renders the outline as normal part of the content, while `pullout`
+       causes the outline to be rendered in a box that is by default floated to
+       the right side of the other content.
+    """
+    implements(IWikiMacroProvider)
+
+    def get_macros(self):
+        yield 'PageOutline'
+
+    def get_macro_description(self, name):
+        return inspect.getdoc(PageOutlineMacro)
+
+    def render_macro(self, req, name, content):
+        from trac.wiki.formatter import wiki_to_outline
+        min_depth, max_depth = 1, 6
+        title = None
+        inline = 0
+        if content:
+            argv = [arg.strip() for arg in content.split(',')]
+            if len(argv) > 0:
+                depth = argv[0]
+                if depth.find('-') >= 0:
+                    min_depth, max_depth = [int(d) for d in depth.split('-', 1)]
+                else:
+                    min_depth, max_depth = int(depth), int(depth)
+                if len(argv) > 1:
+                    title = argv[1].strip()
+                    if len(argv) > 2:
+                        inline = argv[2].strip().lower() == 'inline'
+
+        db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        pagename = req.args.get('page') or 'WikiStart'
+        page = WikiPage(self.env, pagename)
+
+        buf = StringIO()
+        if not inline:
+            buf.write('<div class="wiki-toc">')
+        if title:
+            buf.write('<h4>%s</h4>' % escape(title))
+        buf.write(wiki_to_outline(page.text, self.env, db=db,
+                                  max_depth=max_depth, min_depth=min_depth))
+        if not inline:
+            buf.write('</div>')
+        return buf.getvalue()
+
+
+class ImageMacro(Component):
+    """
+    Embed an image in wiki-formatted text.
+    
+    The first argument is the file specification. The file specification may
+    reference attachments or files in three ways:
+     * `module:id:file`, where module can be either '''wiki''' or '''ticket''',
+       to refer to the attachment named ''file'' of the specified wiki page or
+       ticket.
+     * `id:file`: same as above, but id is either a ticket shorthand or a Wiki
+       page name.
+     * `file` to refer to a local attachment named 'file'. This only works from
+       within that wiki page or a ticket.
+    
+    Also, the file specification may refer to repository files, using the
+    `source:file` syntax (`source:file@rev` works also).
+    
+    The remaining arguments are optional and allow configuring the attributes
+    and style of the rendered `<img>` element:
+     * digits and unit are interpreted as the size (ex. 120, 25%)
+       for the image
+     * `right`, `left`, `top` or `bottom` are interpreted as the alignment for
+       the image
+     * `nolink` means without link to image source.
+     * `key=value` style are interpreted as HTML attributes for the image
+     * `key:value` style are interpreted as CSS style indications for the image
+    
+    Examples:
+    {{{
+        [[Image(photo.jpg)]]                           # simplest
+        [[Image(photo.jpg, 120px)]]                    # with size
+        [[Image(photo.jpg, right)]]                    # aligned by keyword
+        [[Image(photo.jpg, nolink)]]                   # without link to source
+        [[Image(photo.jpg, align=right)]]              # aligned by attribute
+        [[Image(photo.jpg, float:right)]]              # aligned by style
+        [[Image(photo.jpg, float:right, border:solid 5px green)]] # 2 style specs
+    }}}
+    
+    You can use image from other page, other ticket or other module.
+    {{{
+        [[Image(OtherPage:foo.bmp)]]    # if current module is wiki
+        [[Image(base/sub:bar.bmp)]]     # from hierarchical wiki page
+        [[Image(#3:baz.bmp)]]           # if in a ticket, point to #3
+        [[Image(ticket:36:boo.jpg)]]
+        [[Image(source:/images/bee.jpg)]] # straight from the repository!
+        [[Image(htdocs:foo/bar.png)]]   # image file in project htdocs dir.
+    }}}
+    
+    ''Adapted from the Image.py macro created by Shun-ichi Goto
+    <gotoh@taiyo.co.jp>''
+    """
+    implements(IWikiMacroProvider)
+
+    def get_macros(self):
+        yield 'Image'
+
+    def get_macro_description(self, name):
+        return inspect.getdoc(ImageMacro)
+
+    def render_macro(self, req, name, content):
+        # args will be null if the macro is called without parenthesis.
+        if not content:
+            return ''
+        # parse arguments
+        # we expect the 1st argument to be a filename (filespec)
+        args = content.split(',')
+        if len(args) == 0:
+            raise Exception("No argument.")
+        filespec = args[0]
+        size_re = re.compile('^[0-9]+%?$')
+        align_re = re.compile('^(?:left|right|top|bottom)$')
+        keyval_re = re.compile('^([-a-z0-9]+)([=:])(.*)')
+        quoted_re = re.compile("^(?:[\"'])(.*)(?:[\"'])$")
+        attr = {}
+        style = {}
+        nolink = False
+        for arg in args[1:]:
+            arg = arg.strip()
+            if size_re.search(arg):
+                # 'width' keyword
+                attr['width'] = arg
+                continue
+            if align_re.search(arg):
+                # 'align' keyword
+                attr['align'] = arg
+                continue
+            if arg == 'nolink':
+                nolink = True
+                continue
+            match = keyval_re.search(arg)
+            if match:
+                key = match.group(1)
+                sep = match.group(2)
+                val = match.group(3)
+                m = quoted_re.search(val) # unquote "..." and '...'
+                if m:
+                    val = m.group(1)
+                if sep == '=':
+                    attr[key] = val;
+                elif sep == ':':
+                    style[key] = val
+
+        # parse filespec argument to get module and id if contained.
+        parts = filespec.split(':')
+        url = None
+        if len(parts) == 3:                 # module:id:attachment
+            if parts[0] in ['wiki', 'ticket']:
+                module, id, file = parts
+            else:
+                raise Exception("%s module can't have attachments" % parts[0])
+        elif len(parts) == 2:
+            from trac.versioncontrol.web_ui import BrowserModule
+            try:
+                browser_links = [link for link,_ in 
+                                 BrowserModule(self.env).get_link_resolvers()]
+            except Exception:
+                browser_links = []
+            if parts[0] in browser_links:   # source:path
+                module, file = parts
+                rev = None
+                if '@' in file:
+                    file, rev = file.split('@')
+                url = self.env.href.browser(file, rev=rev)
+                raw_url = self.env.href.browser(file, rev=rev, format='raw')
+                desc = filespec
+            else: # #ticket:attachment or WikiPage:attachment
+                # FIXME: do something generic about shorthand forms...
+                id, file = parts
+                if id and id[0] == '#':
+                    module = 'ticket'
+                    id = id[1:]
+                elif id == 'htdocs':
+                    raw_url = url = self.env.href.chrome('site', file)
+                    desc = os.path.basename(file)
+                else:
+                    module = 'wiki'
+        elif len(parts) == 1:               # attachment
+            # determine current object
+            # FIXME: should be retrieved from the formatter...
+            # ...and the formatter should be provided to the macro
+            file = filespec
+            module, id = 'wiki', 'WikiStart'
+            path_info = req.path_info.split('/',2)
+            if len(path_info) > 1:
+                module = path_info[1]
+            if len(path_info) > 2:
+                id = path_info[2]
+            if module not in ['wiki', 'ticket']:
+                raise Exception('Cannot reference local attachment from here')
+        else:
+            raise Exception('No filespec given')
+        if not url: # this is an attachment
+            from trac.attachment import Attachment
+            attachment = Attachment(self.env, module, id, file)
+            url = attachment.href()
+            raw_url = attachment.href(format='raw')
+            desc = attachment.description
+        for key in ['title', 'alt']:
+            if desc and not attr.has_key(key):
+                attr[key] = desc
+        a_style = 'padding:0; border:none' # style of anchor
+        img_attr = ' '.join(['%s="%s"' % x for x in attr.iteritems()])
+        img_style = '; '.join(['%s:%s' % x for x in style.iteritems()])
+        result = '<img src="%s" %s style="%s" />' \
+                 % (raw_url, img_attr, img_style)
+        if not nolink:
+            result = '<a href="%s" style="%s">%s</a>' % (url, a_style, result)
+        return result
+
+
+class MacroListMacro(Component):
+    """Displays a list of all installed Wiki macros, including documentation if
+    available.
+    
+    Optionally, the name of a specific macro can be provided as an argument. In
+    that case, only the documentation for that macro will be rendered.
+    
+    Note that this macro will not be able to display the documentation of
+    macros if the `PythonOptimize` option is enabled for mod_python!
+    """
+    implements(IWikiMacroProvider)
+
+    def get_macros(self):
+        yield 'MacroList'
+
+    def get_macro_description(self, name):
+        return inspect.getdoc(MacroListMacro)
+
+    def render_macro(self, req, name, content):
+        from trac.wiki.formatter import wiki_to_html
+        from trac.wiki import WikiSystem
+        buf = StringIO()
+        buf.write("<dl>")
+
+        wiki = WikiSystem(self.env)
+        for macro_provider in wiki.macro_providers:
+            for macro_name in macro_provider.get_macros():
+                if content and macro_name != content:
+                    continue
+                buf.write("<dt><code>[[%s]]</code></dt>" % escape(macro_name))
+                description = macro_provider.get_macro_description(macro_name)
+                if description:
+                    buf.write("<dd>%s</dd>" % wiki_to_html(description,
+                                                           self.env, req))
+
+        buf.write("</dl>")
+        return buf.getvalue()
+
+
+class UserMacroProvider(Component):
+    """Adds macros that are provided as Python source files in the
+    `wiki-macros` directory of the environment, or the global macros
+    directory.
+    """
+    implements(IWikiMacroProvider)
+
+    def __init__(self):
+        self.env_macros = os.path.join(self.env.path, 'wiki-macros')
+        self.site_macros = default_dir('macros')
+
+    # IWikiMacroProvider methods
+
+    def get_macros(self):
+        found = []
+        for path in (self.env_macros, self.site_macros):
+            if not os.path.exists(path):
+                continue
+            for filename in [filename for filename in os.listdir(path)
+                             if filename.lower().endswith('.py')
+                             and not filename.startswith('__')]:
+                try:
+                    module = self._load_macro(filename[:-3])
+                    name = module.__name__
+                    if name in found:
+                        continue
+                    found.append(name)
+                    yield name
+                except Exception, e:
+                    self.log.error('Failed to load wiki macro %s (%s)',
+                                   filename, e, exc_info=True)
+
+    def get_macro_description(self, name):
+        return inspect.getdoc(self._load_macro(name))
+
+    def render_macro(self, req, name, content):
+        module = self._load_macro(name)
+        try:
+            return module.execute(req and req.hdf, content, self.env)
+        except Exception, e:
+            self.log.error('Wiki macro %s failed (%s)', name, e, exc_info=True)
+            raise
+
+    def _load_macro(self, name):
+        for path in (self.env_macros, self.site_macros):
+            macro_file = os.path.join(path, name + '.py')
+            if os.path.isfile(macro_file):
+                return imp.load_source(name, macro_file)
+        raise TracError, 'Macro %s not found' % name
diff -urN trac-trunk/build/lib/trac/wiki/model.py aw-trac/build/lib/trac/wiki/model.py
--- trac-trunk/build/lib/trac/wiki/model.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/wiki/model.py	2006-03-08 07:36:24.000000000 -0800
@@ -0,0 +1,147 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2005 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import time
+
+from trac.core import *
+from trac.wiki.api import WikiSystem
+
+
+class WikiPage(object):
+    """Represents a wiki page (new or existing)."""
+
+    def __init__(self, env, name=None, version=None, db=None):
+        self.env = env
+        self.name = name
+        if name:
+            self._fetch(name, version, db)
+        else:
+            self.version = 0
+            self.text = ''
+            self.readonly = 0
+        self.old_text = self.text
+        self.old_readonly = self.readonly
+
+    def _fetch(self, name, version=None, db=None):
+        if not db:
+            db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        if version:
+            cursor.execute("SELECT version,text,readonly FROM wiki "
+                           "WHERE name=%s AND version=%s",
+                           (name, int(version)))
+        else:
+            cursor.execute("SELECT version,text,readonly FROM wiki "
+                           "WHERE name=%s ORDER BY version DESC LIMIT 1",
+                           (name,))
+        row = cursor.fetchone()
+        if row:
+            version,text,readonly = row
+            self.version = int(version)
+            self.text = text
+            self.readonly = readonly and int(readonly) or 0
+        else:
+            self.version = 0
+            self.text = ''
+            self.readonly = 0
+
+    exists = property(fget=lambda self: self.version > 0)
+
+    def delete(self, version=None, db=None):
+        assert self.exists, 'Cannot delete non-existent page'
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        page_deleted = False
+        cursor = db.cursor()
+        if version is None:
+            # Delete a wiki page completely
+            cursor.execute("DELETE FROM wiki WHERE name=%s", (self.name,))
+            self.env.log.info('Deleted page %s' % self.name)
+        else:
+            # Delete only a specific page version
+            cursor.execute("DELETE FROM wiki WHERE name=%s and version=%s",
+                           (self.name, version))
+            self.env.log.info('Deleted version %d of page %s'
+                              % (version, self.name))
+
+        if version is None or version == self.version:
+            self._fetch(self.name, None, db)
+
+        if not self.exists:
+            from trac.attachment import Attachment
+            # Delete orphaned attachments
+            for attachment in Attachment.select(self.env, 'wiki', self.name, db):
+                attachment.delete(db)
+
+            # Let change listeners know about the deletion
+            for listener in WikiSystem(self.env).change_listeners:
+                listener.wiki_page_deleted(self)
+
+        if handle_ta:
+            db.commit()
+
+    def save(self, author, comment, remote_addr, t=None, db=None):
+        if not db:
+            db = self.env.get_db_cnx()
+            handle_ta = True
+        else:
+            handle_ta = False
+
+        if t is None:
+            t = time.time()
+
+        if self.text != self.old_text:
+            cursor = db.cursor()
+            cursor.execute("INSERT INTO wiki (name,version,time,author,ipnr,"
+                           "text,comment,readonly) VALUES (%s,%s,%s,%s,%s,%s,"
+                           "%s,%s)", (self.name, self.version + 1, t, author,
+                           remote_addr, self.text, comment, self.readonly))
+            self.version += 1
+        elif self.readonly != self.old_readonly:
+            cursor = db.cursor()
+            cursor.execute("UPDATE wiki SET readonly=%s WHERE name=%s",
+                           (self.readonly, self.name))
+        else:
+            raise TracError('Page not modified')
+
+        if handle_ta:
+            db.commit()
+
+        for listener in WikiSystem(self.env).change_listeners:
+            if self.version == 1:
+                listener.wiki_page_added(self)
+            else:
+                listener.wiki_page_changed(self, self.version, t, comment,
+                                           author, remote_addr)
+
+        self.old_readonly = self.readonly
+        self.old_text = self.text
+
+    def get_history(self, db=None):
+        if not db:
+            db = self.env.get_db_cnx()
+        cursor = db.cursor()
+        cursor.execute("SELECT version,time,author,comment,ipnr FROM wiki "
+                       "WHERE name=%s AND version<=%s "
+                       "ORDER BY version DESC", (self.name, self.version))
+        for version,time,author,comment,ipnr in cursor:
+            yield version,time,author,comment,ipnr
diff -urN trac-trunk/build/lib/trac/wiki/web_ui.py aw-trac/build/lib/trac/wiki/web_ui.py
--- trac-trunk/build/lib/trac/wiki/web_ui.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/lib/trac/wiki/web_ui.py	2006-03-08 07:36:24.000000000 -0800
@@ -0,0 +1,407 @@
+# -*- coding: iso-8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+#         Christopher Lenz <cmlenz@gmx.de>
+
+import re
+import StringIO
+
+from trac.attachment import attachment_to_hdf, Attachment
+from trac.core import *
+from trac.perm import IPermissionRequestor
+from trac.Search import ISearchSource, search_to_sql, shorten_result
+from trac.Timeline import ITimelineEventProvider
+from trac.util import format_datetime, get_reporter_id, pretty_timedelta, \
+                      shorten_line, Markup
+from trac.versioncontrol.diff import get_diff_options, hdf_diff
+from trac.web.chrome import add_link, add_stylesheet, INavigationContributor
+from trac.web import HTTPNotFound, IRequestHandler
+from trac.wiki.model import WikiPage
+from trac.wiki.formatter import wiki_to_html, wiki_to_oneliner
+
+
+class WikiModule(Component):
+
+    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
+               ITimelineEventProvider, ISearchSource)
+
+    # INavigationContributor methods
+
+    def get_active_navigation_item(self, req):
+        return 'wiki'
+
+    def get_navigation_items(self, req):
+        if not req.perm.has_permission('WIKI_VIEW'):
+            return
+        yield ('metanav', 'help',
+               Markup('<a href="%s" accesskey="6">Help/Guide</a>',
+                      self.env.href.wiki('TracGuide')))
+        yield ('mainnav', 'wiki',
+               Markup('<a href="%s" accesskey="1">Wiki</a>',
+                      self.env.href.wiki()))
+
+    # IPermissionRequestor methods
+
+    def get_permission_actions(self):
+        actions = ['WIKI_CREATE', 'WIKI_DELETE', 'WIKI_MODIFY', 'WIKI_VIEW']
+        return actions + [('WIKI_ADMIN', actions)]
+
+    # IRequestHandler methods
+
+    def match_request(self, req):
+        match = re.match(r'^/wiki(?:/(.*))?', req.path_info)
+        if match:
+            if match.group(1):
+                req.args['page'] = match.group(1)
+            return 1
+
+    def process_request(self, req):
+        action = req.args.get('action', 'view')
+        pagename = req.args.get('page', 'WikiStart')
+        version = req.args.get('version')
+
+        if pagename.endswith('/'):
+            req.redirect(self.env.href.wiki(pagename.strip('/')))
+
+        db = self.env.get_db_cnx()
+        page = WikiPage(self.env, pagename, version, db)
+
+        add_stylesheet(req, 'common/css/wiki.css')
+
+        if req.method == 'POST':
+            if action == 'edit':
+                latest_version = WikiPage(self.env, pagename, None, db).version
+                if req.args.has_key('cancel'):
+                    req.redirect(self.env.href.wiki(page.name))
+                elif int(version) != latest_version:
+                    action = 'collision'
+                    self._render_editor(req, db, page)
+                elif req.args.has_key('preview'):
+                    action = 'preview'
+                    self._render_editor(req, db, page, preview=True)
+                else:
+                    self._do_save(req, db, page)
+            elif action == 'delete':
+                self._do_delete(req, db, page)
+            elif action == 'diff':
+                get_diff_options(req)
+                req.redirect(self.env.href.wiki(page.name, version=page.version,
+                                                action='diff'))
+        elif action == 'delete':
+            self._render_confirm(req, db, page)
+        elif action == 'edit':
+            self._render_editor(req, db, page)
+        elif action == 'diff':
+            self._render_diff(req, db, page)
+        elif action == 'history':
+            self._render_history(req, db, page)
+        else:
+            if req.args.get('format') == 'txt':
+                req.send_response(200)
+                req.send_header('Content-Type', 'text/plain;charset=utf-8')
+                req.end_headers()
+                req.write(page.text)
+                return
+            self._render_view(req, db, page)
+
+        req.hdf['wiki.action'] = action
+        req.hdf['wiki.page_name'] = page.name
+        req.hdf['wiki.current_href'] = self.env.href.wiki(page.name)
+        return 'wiki.cs', None
+
+    # ITimelineEventProvider methods
+
+    def get_timeline_filters(self, req):
+        if req.perm.has_permission('WIKI_VIEW'):
+            yield ('wiki', 'Wiki changes')
+
+    def get_timeline_events(self, req, start, stop, filters):
+        if 'wiki' in filters:
+            format = req.args.get('format')
+            db = self.env.get_db_cnx()
+            cursor = db.cursor()
+            cursor.execute("SELECT time,name,comment,author "
+                           "FROM wiki WHERE time>=%s AND time<=%s",
+                           (start, stop))
+            for t,name,comment,author in cursor:
+                title = Markup('<em>%s</em> edited by %s', name, author)
+                if format == 'rss':
+                    href = self.env.abs_href.wiki(name)
+                    comment = wiki_to_html(comment or '--', self.env, req, db,
+                                           absurls=True)
+                else:
+                    href = self.env.href.wiki(name)
+                    comment = wiki_to_oneliner(comment, self.env, db,
+                                               shorten=True)
+                yield 'wiki', href, title, t, author, comment
+
+    # Internal methods
+
+    def _do_delete(self, req, db, page):
+        if page.readonly:
+            req.perm.assert_permission('WIKI_ADMIN')
+        else:
+            req.perm.assert_permission('WIKI_DELETE')
+
+        if req.args.has_key('cancel'):
+            req.redirect(self.env.href.wiki(page.name))
+
+        version = None
+        if req.args.has_key('version'):
+            version = int(req.args.get('version', 0))
+
+        page.delete(version, db)
+        db.commit()
+
+        if not page.exists:
+            req.redirect(self.env.href.wiki())
+        else:
+            req.redirect(self.env.href.wiki(page.name))
+
+    def _do_save(self, req, db, page):
+        if page.readonly:
+            req.perm.assert_permission('WIKI_ADMIN')
+        elif not page.exists:
+            req.perm.assert_permission('WIKI_CREATE')
+        else:
+            req.perm.assert_permission('WIKI_MODIFY')
+
+        page.text = req.args.get('text')
+        if req.perm.has_permission('WIKI_ADMIN'):
+            # Modify the read-only flag if it has been changed and the user is
+            # WIKI_ADMIN
+            page.readonly = int(req.args.has_key('readonly'))
+
+        page.save(req.args.get('author'), req.args.get('comment'),
+                  req.remote_addr)
+        req.redirect(self.env.href.wiki(page.name))
+
+    def _render_confirm(self, req, db, page):
+        if page.readonly:
+            req.perm.assert_permission('WIKI_ADMIN')
+        else:
+            req.perm.assert_permission('WIKI_DELETE')
+
+        version = None
+        if req.args.has_key('delete_version'):
+            version = int(req.args.get('version', 0))
+
+        req.hdf['title'] = page.name + ' (delete)'
+        req.hdf['wiki'] = {'page_name': page.name, 'mode': 'delete'}
+        if version is not None:
+            req.hdf['wiki.version'] = version
+            num_versions = 0
+            for change in page.get_history():
+                num_versions += 1;
+                if num_versions > 1:
+                    break
+            req.hdf['wiki.only_version'] = num_versions == 1
+
+    def _render_diff(self, req, db, page):
+        req.perm.assert_permission('WIKI_VIEW')
+
+        if not page.exists:
+            raise TracError, "Version %s of page %s does not exist" \
+                             % (req.args.get('version'), page.name)
+
+        add_stylesheet(req, 'common/css/diff.css')
+
+        req.hdf['title'] = page.name + ' (diff)'
+
+        # Ask web spiders to not index old versions
+        req.hdf['html.norobots'] = 1
+
+        old_version = req.args.get('old_version')
+        if old_version:
+            old_version = int(old_version)
+            if old_version == page.version:
+                old_version = None
+            elif old_version > page.version:
+                old_version, page = page.version, \
+                                    WikiPage(self.env, page.name, old_version)
+
+        info = {
+            'version': page.version,
+            'history_href': self.env.href.wiki(page.name, action='history')
+        }
+
+        num_changes = 0
+        old_page = None
+        for version,t,author,comment,ipnr in page.get_history():
+            if version == page.version:
+                if t:
+                    info['time'] = format_datetime(t)
+                    info['time_delta'] = pretty_timedelta(t)
+                info['author'] = author or 'anonymous'
+                info['comment'] = comment or '--'
+                info['ipnr'] = ipnr or ''
+            else:
+                num_changes += 1
+                if version < page.version:
+                    if (old_version and version == old_version) or \
+                            not old_version:
+                        old_page = WikiPage(self.env, page.name, version)
+                        info['num_changes'] = num_changes
+                        info['old_version'] = version
+                        break
+
+        req.hdf['wiki'] = info
+
+        diff_style, diff_options = get_diff_options(req)
+
+        oldtext = old_page and old_page.text.splitlines() or []
+        newtext = page.text.splitlines()
+        context = 3
+        for option in diff_options:
+            if option.startswith('-U'):
+                context = int(option[2:])
+                break
+        if context < 0:
+            context = None
+        changes = hdf_diff(oldtext, newtext, context=context,
+                           ignore_blank_lines='-B' in diff_options,
+                           ignore_case='-i' in diff_options,
+                           ignore_space_changes='-b' in diff_options)
+        req.hdf['wiki.diff'] = changes
+
+    def _render_editor(self, req, db, page, preview=False):
+        req.perm.assert_permission('WIKI_MODIFY')
+
+        if req.args.has_key('text'):
+            page.text = req.args.get('text')
+        if preview:
+            page.readonly = req.args.has_key('readonly')
+
+        author = req.args.get('author', get_reporter_id(req))
+        comment = req.args.get('comment', '')
+        editrows = req.args.get('editrows')
+        if editrows:
+            pref = req.session.get('wiki_editrows', '20')
+            if editrows != pref:
+                req.session['wiki_editrows'] = editrows
+        else:
+            editrows = req.session.get('wiki_editrows', '20')
+
+        req.hdf['title'] = page.name + ' (edit)'
+        info = {
+            'page_name': page.name,
+            'page_source': page.text,
+            'version': page.version,
+            'author': author,
+            'comment': comment,
+            'readonly': page.readonly,
+            'edit_rows': editrows,
+            'scroll_bar_pos': req.args.get('scroll_bar_pos', '')
+        }
+        if page.exists:
+            info['history_href'] = self.env.href.wiki(page.name,
+                                                      action='history')
+        if preview:
+            info['page_html'] = wiki_to_html(page.text, self.env, req, db)
+            info['readonly'] = int(req.args.has_key('readonly'))
+        req.hdf['wiki'] = info
+
+    def _render_history(self, req, db, page):
+        """Extract the complete history for a given page and stores it in the
+        HDF.
+
+        This information is used to present a changelog/history for a given
+        page.
+        """
+        req.perm.assert_permission('WIKI_VIEW')
+
+        if not page.exists:
+            raise TracError, "Page %s does not exist" % page.name
+
+        req.hdf['title'] = page.name + ' (history)'
+
+        history = []
+        for version, t, author, comment, ipnr in page.get_history():
+            history.append({
+                'url': self.env.href.wiki(page.name, version=version),
+                'diff_url': self.env.href.wiki(page.name,
+                                               version=version,
+                                               action='diff'),
+                'version': version,
+                'time': format_datetime(t),
+                'time_delta': pretty_timedelta(t),
+                'author': author,
+                'comment': wiki_to_oneliner(comment or '', self.env, db),
+                'ipaddr': ipnr
+            })
+        req.hdf['wiki.history'] = history
+
+    def _render_view(self, req, db, page):
+        req.perm.assert_permission('WIKI_VIEW')
+
+        if page.name == 'WikiStart':
+            req.hdf['title'] = ''
+        else:
+            req.hdf['title'] = page.name
+
+        version = req.args.get('version')
+        if version:
+            # Ask web spiders to not index old versions
+            req.hdf['html.norobots'] = 1
+
+        txt_href = self.env.href.wiki(page.name, version=version, format='txt')
+        add_link(req, 'alternate', txt_href, 'Plain Text', 'text/plain')
+
+        req.hdf['wiki'] = {'page_name': page.name, 'exists': page.exists,
+                           'version': page.version, 'readonly': page.readonly}
+        if page.exists:
+            req.hdf['wiki.page_html'] = wiki_to_html(page.text, self.env, req)
+            history_href = self.env.href.wiki(page.name, action='history')
+            req.hdf['wiki.history_href'] = history_href
+        else:
+            if not req.perm.has_permission('WIKI_CREATE'):
+                raise HTTPNotFound('Page %s not found', page.name)
+            req.hdf['wiki.page_html'] = Markup('<p>Describe "%s" here</p>',
+                                               page.name)
+
+        # Show attachments
+        attachments = []
+        for attachment in Attachment.select(self.env, 'wiki', page.name, db):
+            attachments.append(attachment_to_hdf(self.env, db, req, attachment))
+        req.hdf['wiki.attachments'] = attachments
+        if req.perm.has_permission('WIKI_MODIFY'):
+            attach_href = self.env.href.attachment('wiki', page.name)
+            req.hdf['wiki.attach_href'] = attach_href
+
+    # ISearchSource methods
+
+    def get_search_filters(self, req):
+        if req.perm.has_permission('WIKI_VIEW'):
+            yield ('wiki', 'Wiki')
+
+    def get_search_results(self, req, terms, filters):
+        if not 'wiki' in filters:
+            return
+        db = self.env.get_db_cnx()
+        sql_query, args = search_to_sql(db, ['w1.name', 'w1.author', 'w1.text'], terms)
+        cursor = db.cursor()
+        cursor.execute("SELECT w1.name,w1.time,w1.author,w1.text "
+                       "FROM wiki w1,"
+                       "(SELECT name,max(version) AS ver "
+                       "FROM wiki GROUP BY name) w2 "
+                       "WHERE w1.version = w2.ver AND w1.name = w2.name "
+                       "AND " + sql_query, args)
+
+        for name, date, author, text in cursor:
+            yield (self.env.href.wiki(name),
+                   '%s: %s' % (name, shorten_line(text)),
+                   date, author,
+                   shorten_result(text, terms))
diff -urN trac-trunk/build/scripts-2.4/trac-admin aw-trac/build/scripts-2.4/trac-admin
--- trac-trunk/build/scripts-2.4/trac-admin	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/scripts-2.4/trac-admin	2006-03-08 16:15:07.276593548 -0800
@@ -0,0 +1,22 @@
+#!/usr/bin/python
+# -*- coding: iso8859-1 -*-
+__author__ = 'Daniel Lundin <daniel@edgewall.com>, Jonas Borgström <jonas@edgewall.com>'
+__copyright__ = 'Copyright (c) 2005 Edgewall Software'
+__license__ = """
+ Copyright (C) 2003, 2004, 2005 Edgewall Software
+ Copyright (C) 2003, 2004 Jonas Borgström <jonas@edgewall.com>
+ Copyright (C) 2003, 2004 Daniel Lundin <daniel@edgewall.com>
+ All rights reserved.
+
+ This software is licensed as described in the file COPYING, which
+ you should have received as part of this distribution. The terms
+ are also available at http://trac.edgewall.com/license.html.
+
+ This software consists of voluntary contributions made by many
+ individuals. For the exact contribution history, see the revision
+ history and logs, available at http://projects.edgewall.com/trac/."""
+
+import sys
+
+from trac.scripts.admin import run
+sys.exit(run(sys.argv[1:]))
diff -urN trac-trunk/build/scripts-2.4/trac-postinstall.py aw-trac/build/scripts-2.4/trac-postinstall.py
--- trac-trunk/build/scripts-2.4/trac-postinstall.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/scripts-2.4/trac-postinstall.py	2005-10-08 14:13:05.000000000 -0700
@@ -0,0 +1,51 @@
+# Post installation script for the Windows installer
+# This script is needed to create the trac/siteconfig.py file containing various
+# global default directories
+
+import os.path
+import sys
+from distutils import sysconfig
+import trac
+
+def install():
+    print 'Setting up default directories...'
+    site_packages = os.path.join(sysconfig.get_config_var('BINLIBDEST'),
+                                 'site-packages')
+    prefix = sysconfig.get_config_var('prefix')
+
+    conf_dir = os.path.join(prefix, 'share', 'trac', 'conf')
+    templates_dir = os.path.join(prefix, 'share', 'trac', 'templates')
+    htdocs_dir = os.path.join(prefix, 'share', 'trac', 'htdocs')
+    wiki_dir = os.path.join(prefix, 'share', 'trac', 'wiki-default')
+    macros_dir = os.path.join(prefix, 'share', 'trac', 'wiki-macros')
+
+    siteconfig = os.path.join(site_packages, 'trac', 'siteconfig.py')
+    fd = open(siteconfig, 'w')
+    fd.write("""
+# PLEASE DO NOT EDIT THIS FILE!
+# This file was autogenerated when installing Trac %(version)s.
+#
+__default_conf_dir__ = %(conf)r
+__default_templates_dir__ = %(templates)r
+__default_htdocs_dir__ = %(htdocs)r
+__default_wiki_dir__ = %(wiki)r
+__default_macros_dir__ = %(macros)r
+
+""" % {'version': trac.__version__, 'conf': conf_dir,
+       'templates': templates_dir, 'htdocs': htdocs_dir,
+       'wiki': wiki_dir, 'macros': macros_dir})
+    fd.close()
+
+    file_created(siteconfig)
+    print 'Done.'
+
+def remove():
+    pass
+
+
+if __name__ == '__main__':
+    mode = sys.argv[1]
+    if mode == '-install':
+        install()
+    elif mode == '-remove':
+        remove()
diff -urN trac-trunk/build/scripts-2.4/trac.cgi aw-trac/build/scripts-2.4/trac.cgi
--- trac-trunk/build/scripts-2.4/trac.cgi	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/scripts-2.4/trac.cgi	2006-03-08 16:15:07.288594880 -0800
@@ -0,0 +1,36 @@
+#!/usr/bin/python
+# -*- coding: iso8859-1 -*-
+#
+# Copyright (C) 2003-2004 Edgewall Software
+# Copyright (C) 2003-2004 Jonas Borgström <jonas@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+try:
+    from trac.web import cgi_frontend
+    cgi_frontend.run()
+
+except Exception, e:
+    import sys
+    import traceback
+
+    print>>sys.stderr, e
+    traceback.print_exc(file=sys.stderr)
+
+    print 'Status: 500 Internal Server Error'
+    print 'Content-Type: text/plain'
+    print
+    print 'Oops...'
+    print
+    print 'Trac detected an internal error:', e
+    print
+    traceback.print_exc(file=sys.stdout)
diff -urN trac-trunk/build/scripts-2.4/trac.fcgi aw-trac/build/scripts-2.4/trac.fcgi
--- trac-trunk/build/scripts-2.4/trac.fcgi	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/scripts-2.4/trac.fcgi	2006-03-08 16:15:07.288594880 -0800
@@ -0,0 +1,33 @@
+#!/usr/bin/python
+# -*- coding: iso8859-1 -*-
+#
+# Copyright (C) 2003-2004 Edgewall Software
+# Copyright (C) 2003-2004 Jonas Borgström <jonas@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+try:
+    from trac.web import fcgi_frontend
+    fcgi_frontend.run()
+except Exception, e:
+    print 'Content-Type: text/plain\r\n\r\n',
+    print 'Oops...'
+    print
+    print 'Trac detected an internal error:'
+    print
+    print e
+    print
+    import traceback
+    import StringIO
+    tb = StringIO.StringIO()
+    traceback.print_exc(file=tb)
+    print tb.getvalue()
diff -urN trac-trunk/build/scripts-2.4/tracd aw-trac/build/scripts-2.4/tracd
--- trac-trunk/build/scripts-2.4/tracd	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/scripts-2.4/tracd	2006-03-08 16:15:07.284594436 -0800
@@ -0,0 +1,20 @@
+#!/usr/bin/python
+# -*- coding: iso8859-1 -*-
+#
+# Copyright (C) 2003-2006 Edgewall Software
+# Copyright (C) 2003-2005 Jonas Borgström <jonas@edgewall.com>
+# All rights reserved.
+#
+# This software is licensed as described in the file COPYING, which
+# you should have received as part of this distribution. The terms
+# are also available at http://trac.edgewall.com/license.html.
+#
+# This software consists of voluntary contributions made by many
+# individuals. For the exact contribution history, see the revision
+# history and logs, available at http://projects.edgewall.com/trac/.
+#
+# Author: Jonas Borgström <jonas@edgewall.com>
+
+if __name__ == '__main__':
+    from trac.web.standalone import main
+    main()
diff -urN trac-trunk/build/scripts-2.4/tracdb2env aw-trac/build/scripts-2.4/tracdb2env
--- trac-trunk/build/scripts-2.4/tracdb2env	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/build/scripts-2.4/tracdb2env	2006-03-08 16:15:07.284594436 -0800
@@ -0,0 +1,105 @@
+#!/usr/bin/python
+import os
+import sys
+import sqlite
+import ConfigParser
+from trac.env import Environment
+
+additional_config = \
+(('notification', 'smtp_enabled', 'false'),
+ ('notification', 'smtp_server', 'localhost'),
+ ('notification', 'smtp_replyto', 'trac@localhost'),
+ ('logging', 'log_type', 'none'),
+ ('logging', 'log_file', 'trac.log'),
+ ('logging', 'log_level', 'DEBUG'),
+ ('attachment', 'max_size', '262144'),
+ ('trac', 'default_charset', 'iso-8859-15'),
+ ('trac', 'database', 'sqlite:db/trac.db'))
+
+def db2env(db_path, env_path):
+    env = Environment(env_path, create=1)
+    # Open the databases
+    old_cnx = sqlite.connect(db_path)
+    new_cnx = env.get_db_cnx()
+    old_cursor = old_cnx.cursor()
+    new_cursor = new_cnx.cursor()
+    convert_config(env, old_cursor)
+    convert_db(old_cursor, new_cursor)
+    new_cursor.execute("INSERT INTO system VALUES('database_version', '7')")
+    new_cnx.commit()
+
+def convert_config(env, old_cursor):
+    old_cursor.execute('SELECT section, name, value FROM config')
+    while 1:
+        row = old_cursor.fetchone()
+        if not row:
+            break
+        row = [row[0], row[1], row[2]]
+        if row[0] == 'general':
+            row[0] = 'trac'
+        if row[1] == 'database_version':
+            continue
+        env.set_config(row[0], row[1], row[2])
+    for v in additional_config:
+        env.set_config(*v)
+    env.save_config()
+
+def to_utf8(row):
+    x = []
+    for v in row:
+        if type(v) == type(''):
+            try:
+                u = unicode(v, 'utf-8')
+                x.append(v)
+            except UnicodeError:
+                u = unicode(v, 'iso-8859-15')
+                x.append(u.encode('utf-8'))
+        else:
+            x.append(v)
+    return x
+
+def copy_tuples(table, from_cursor, to_cursor, fields='*'):
+    from_cursor.execute('SELECT %s FROM %s' % (fields, table))
+    while 1:
+        row = from_cursor.fetchone()
+        if not row:
+            break
+        row = to_utf8(row)
+        if fields == '*':
+            to_cursor.execute('INSERT INTO %s VALUES(%s)' \
+                              % (table, ', '.join(['%s'] * len(row))), *row)
+        else:
+            to_cursor.execute('INSERT INTO %s (%s) VALUES(%s)' \
+                              % (table, fields,
+                                 ', '.join(['%s'] * len(row))), *row)
+
+def convert_db(old_cursor, new_cursor):
+    copy_tuples('revision', old_cursor, new_cursor)
+    copy_tuples('node_change', old_cursor, new_cursor)
+    copy_tuples('auth_cookie', old_cursor, new_cursor)
+    copy_tuples('enum', old_cursor, new_cursor)
+    copy_tuples('ticket_change', old_cursor, new_cursor)
+    copy_tuples('permission', old_cursor, new_cursor)
+    copy_tuples('component', old_cursor, new_cursor)
+    copy_tuples('milestone', old_cursor, new_cursor, "name, time")
+    new_cursor.execute("UPDATE milestone SET descr=''")
+    copy_tuples('version', old_cursor, new_cursor)
+    copy_tuples('report', old_cursor, new_cursor,
+                'id,author,title,sql')
+    copy_tuples('ticket', old_cursor, new_cursor,
+                'id,time,changetime,component,severity,priority,'
+                'owner,reporter,cc,url,version,milestone,status,'
+                'resolution,summary,description')
+    copy_tuples('wiki', old_cursor, new_cursor,
+                'name,version,time,author,ipnr,text')
+
+if __name__ == '__main__':
+    if len(sys.argv) != 3:
+        print >> sys.stderr, 'Usage: %s <db-file> <env-dir>\n' % sys.argv[0]
+        print >> sys.stderr, \
+              'Creates a new Trac environment and initializes it with ' \
+              'information\nfrom an existing pre 0.7 trac database.'
+        print >> sys.stderr
+        sys.exit(1)
+    db2env(sys.argv[1], sys.argv[2])
+    print >> sys.stderr, 'Environment successfully created.'
Files trac-trunk/trac/__init__.pyc and aw-trac/trac/__init__.pyc differ
diff -urN trac-trunk/trac/db/postgres_backend.py aw-trac/trac/db/postgres_backend.py
--- trac-trunk/trac/db/postgres_backend.py	2005-12-29 02:34:53.463747000 -0800
+++ aw-trac/trac/db/postgres_backend.py	2006-03-08 16:14:58.079572641 -0800
@@ -20,6 +20,7 @@
 
 psycopg = None
 PgSQL = None
+PGSchemaError = None
 
 
 class PostgreSQLConnector(Component):
@@ -38,6 +39,9 @@
                 params={}):
         cnx = self.get_connection(path, user, password, host, port, params)
         cursor = cnx.cursor()
+        if cnx.schema:
+            cursor.execute('CREATE SCHEMA %s' % cnx.schema) 
+            cursor.execute('SET search_path TO %s, public', (cnx.schema,)) 
         from trac.db_default import schema
         for table in schema:
             for stmt in self.to_sql(table):
@@ -76,14 +80,18 @@
         # We support both psycopg and PgSQL but prefer psycopg
         global psycopg
         global PgSQL
+        global PGSchemaError
         if not psycopg and not PgSQL:
             try:
                 try:
+                    from psycopg2 import ProgrammingError as PGSchemaError
                     import psycopg2 as psycopg
                 except ImportError:
                     import psycopg
+                    from psycopg import ProgrammingError as PGSchemaError
             except ImportError:
                 from pyPgSQL import PgSQL
+                from pyPgSQL.libpq import OperationalError as PGSchemaError
         if psycopg:
             dsn = []
             if path:
@@ -99,6 +107,13 @@
             cnx = psycopg.connect(' '.join(dsn))
         else:
             cnx = PgSQL.connect('', user, password, host, path, port)
+        try: 
+            self.schema = None
+            if 'schema' in params:
+                self.schema = params['schema'] 
+            cnx.cursor().execute('SET search_path TO %s, public', (self.schema,)) 
+        except PGSchemaError: 
+            cnx.rollback() 
         ConnectionWrapper.__init__(self, cnx)
 
     def cast(self, column, type):
@@ -113,3 +128,14 @@
     def get_last_id(self, cursor, table, column='id'):
         cursor.execute("SELECT CURRVAL('%s_%s_seq')" % (table, column))
         return cursor.fetchone()[0]
+
+    def cursor(self):
+        cursor = self.cnx.cursor()
+        if self.schema:
+            try:
+                cursor.execute("SET search_path TO %s, public", (self.schema,))
+                self.cnx.commit()
+            except PGSchemaError:
+                self.cnx.rollback()
+        return cursor
+
diff -urN trac-trunk/trac/siteconfig.py aw-trac/trac/siteconfig.py
--- trac-trunk/trac/siteconfig.py	1969-12-31 16:00:00.000000000 -0800
+++ aw-trac/trac/siteconfig.py	2006-03-08 16:15:06.932555359 -0800
@@ -0,0 +1,10 @@
+
+# PLEASE DO NOT EDIT THIS FILE!
+# This file was autogenerated when installing Trac 0.10dev.
+#
+__default_conf_dir__ = '/usr/share/trac/conf'
+__default_templates_dir__ = '/usr/share/trac/templates'
+__default_htdocs_dir__ = '/usr/share/trac/htdocs'
+__default_wiki_dir__ = '/usr/share/trac/wiki-default'
+__default_macros_dir__ = '/usr/share/trac/wiki-macros'
+
